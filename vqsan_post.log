Command Line Args: Namespace(config_file='configs/san_clip_vit_res4_coco.yaml', resume=True, eval_only=True, num_gpus=2, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50155', opts=['SOLVER.IMS_PER_BATCH', '2', 'OUTPUT_DIR', 'output/vqsan_post', 'WANDB.NAME', 'vqsan_post'])
Loading config configs/Base-coco-stuff-10K-171.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.
Loading config configs/Base-coco-stuff-10K-171.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.
[12/13 00:27:46 detectron2]: Rank of current process: 0. World size: 2
[12/13 00:27:46 detectron2]: Environment info:
-------------------------------  -------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.9.18 (main, Sep 11 2023, 13:41:44) [GCC 11.2.0]
numpy                            1.22.4
detectron2                       0.6 @/home/zjy/.conda/envs/san/lib/python3.9/site-packages/detectron2
Compiler                         GCC 9.3
CUDA compiler                    CUDA 11.3
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.12.1+cu113 @/home/zjy/.conda/envs/san/lib/python3.9/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3080 (arch=8.6)
Driver version                   515.48.07
CUDA_HOME                        /usr/local/cuda
Pillow                           9.3.0
torchvision                      0.13.1+cu113 @/home/zjy/.conda/envs/san/lib/python3.9/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.8.1
-------------------------------  -------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/13 00:27:46 detectron2]: Command line arguments: Namespace(config_file='configs/san_clip_vit_res4_coco.yaml', resume=True, eval_only=True, num_gpus=2, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50155', opts=['SOLVER.IMS_PER_BATCH', '2', 'OUTPUT_DIR', 'output/vqsan_post', 'WANDB.NAME', 'vqsan_post'])
[12/13 00:27:46 detectron2]: Contents of args.config_file=configs/san_clip_vit_res4_coco.yaml:
_BASE_: Base-coco-stuff-10K-171.yaml
MODEL:
  META_ARCHITECTURE: "SAN"
SOLVER:
  BACKBONE_MULTIPLIER: 1.0
[12/13 00:27:46 detectron2]: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_2017_test_stuff_sem_seg
  - voc_sem_seg_val
  - pcontext_sem_seg_val
  - pcontext_full_sem_seg_val
  - ade20k_sem_seg_val
  - ade20k_full_sem_seg_val
  TRAIN:
  - coco_2017_train_stuff_10k_sem_seg
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 640
    - 640
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_semantic
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 2560
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 320
  - 384
  - 448
  - 512
  - 576
  - 640
  - 704
  - 768
  - 832
  - 896
  - 960
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: 640
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FLASH: false
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: SAN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 1.0
  - 1.0
  - 1.0
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SAN:
    ASYMETRIC_INPUT: true
    CLASS_WEIGHT: 2.0
    CLIP_DEEPER_FROZEN_EXCLUDE: []
    CLIP_FROZEN_EXCLUDE:
    - positional_embedding
    CLIP_MODEL_NAME: ViT-B/16
    CLIP_PRETRAINED_NAME: openai
    CLIP_RESOLUTION: 0.5
    CLIP_TEMPLATE_SET: vild
    DICE_WEIGHT: 5.0
    FEATURE_LAST_LAYER_IDX: 9
    IMPORTANCE_SAMPLE_RATIO: 0.75
    MASK_WEIGHT: 5.0
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 171
    OVERSAMPLE_RATIO: 3.0
    PERCEPT_WEIGHT:
    - 0.5
    - 1.0
    - 2.0
    REC_CROSS_ATTN: false
    REC_DOWNSAMPLE_METHOD: max
    SEM_SEG_POSTPROCESS_BEFORE_INFERENCE: true
    SIZE_DIVISIBILITY: 32
    SLS_TOKEN_FORMAT: query_token
    TRAIN_NUM_POINTS: 12544
    VQ_WEIGHT: 0.0
  SEM_SEG_HEAD:
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    USE_DEPTHWISE_SEPARABLE_CONV: false
  SIDE_ADAPTER:
    ATTN_BIAS:
      EMBED_CHANNELS: 256
      MLP_CHANNELS: 256
      MLP_NUM_LAYERS: 3
      NUM_HEADS: 12
      NUM_LAYERS: 1
      RESCALE_ATTN_BIAS: true
    DEEP_SUPERVISION_IDXS:
    - 8
    DROP_PATH_RATE: 0.0
    FUSION_MAP:
    - 0->0
    - 3->1
    - 6->2
    - 9->3
    FUSION_TYPE: add
    IMAGE_SIZE: 640
    NAME: RegionwiseSideAdapterNetwork
    NUM_QUERIES: 100
    PRETRAINED: false
    VIT_NAME: vit_w240n6d8_patch16
  WEIGHTS: ''
OUTPUT_DIR: output/vqsan_post
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 1.0
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  CLIP_MULTIPLIER: 1.0
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupPolyLR
  MAX_ITER: 60000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  TEST_IMS_PER_BATCH: 1
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 0
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_EMBED_GROUP:
  - absolute_pos_embed
  - positional_embedding
  - pos_embed
  - query_embed
  - relative_position_bias_table
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4480
    MIN_SIZES:
    - 320
    - 480
    - 640
    - 800
    - 960
    - 1120
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 60000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
WANDB:
  NAME: vqsan_post
  PROJECT: oseg_1111

[12/13 00:27:46 detectron2]: Full config saved to output/vqsan_post/config.yaml
[12/13 00:27:46 d2.utils.env]: Using a generated random seed 50132496
/home/zjy/.conda/envs/san/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/home/zjy/.conda/envs/san/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/home/zjy/.conda/envs/san/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/home/zjy/.conda/envs/san/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
WARNING:timm.models._builder:No pretrained configuration specified for vit_tiny_patch16_224_in21k model. Using a default. Please add a config to the model pretrained_cfg registry or pass explicitly.
WARNING:timm.models._builder:No pretrained configuration specified for vit_tiny_patch16_224_in21k model. Using a default. Please add a config to the model pretrained_cfg registry or pass explicitly.
loaded pretrained LPIPS loss from resources/models/lpips/vgg.pth
[12/13 00:27:52 d2.engine.defaults]: Model:
SAN(
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_vq': 0.0, 'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_percept_layer1': 0.5, 'loss_percept_layer2': 1.0, 'loss_percept_layer3': 2.0}
      num_classes: 171
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
  (query_proj): Linear(in_features=240, out_features=768, bias=False)
  (side_adapter_network): RegionwiseSideAdapterNetwork(
    (vit_model): VisionTransformer(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 240, kernel_size=(16, 16), stride=(16, 16))
        (norm): Identity()
      )
      (pos_drop): Dropout(p=0.0, inplace=False)
      (patch_drop): Identity()
      (norm_pre): Identity()
      (blocks): Sequential(
        (0): Block(
          (norm1): LayerNorm((240,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=240, out_features=720, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=240, out_features=240, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): Identity()
          (drop_path1): Identity()
          (norm2): LayerNorm((240,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=240, out_features=960, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=960, out_features=240, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): Identity()
          (drop_path2): Identity()
        )
        (1): Block(
          (norm1): LayerNorm((240,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=240, out_features=720, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=240, out_features=240, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): Identity()
          (drop_path1): Identity()
          (norm2): LayerNorm((240,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=240, out_features=960, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=960, out_features=240, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): Identity()
          (drop_path2): Identity()
        )
        (2): Block(
          (norm1): LayerNorm((240,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=240, out_features=720, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=240, out_features=240, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): Identity()
          (drop_path1): Identity()
          (norm2): LayerNorm((240,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=240, out_features=960, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=960, out_features=240, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): Identity()
          (drop_path2): Identity()
        )
        (3): Block(
          (norm1): LayerNorm((240,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=240, out_features=720, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=240, out_features=240, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): Identity()
          (drop_path1): Identity()
          (norm2): LayerNorm((240,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=240, out_features=960, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=960, out_features=240, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): Identity()
          (drop_path2): Identity()
        )
        (4): Block(
          (norm1): LayerNorm((240,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=240, out_features=720, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=240, out_features=240, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): Identity()
          (drop_path1): Identity()
          (norm2): LayerNorm((240,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=240, out_features=960, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=960, out_features=240, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): Identity()
          (drop_path2): Identity()
        )
        (5): Block(
          (norm1): LayerNorm((240,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=240, out_features=720, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=240, out_features=240, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): Identity()
          (drop_path1): Identity()
          (norm2): LayerNorm((240,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=240, out_features=960, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=960, out_features=240, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): Identity()
          (drop_path2): Identity()
        )
        (6): Block(
          (norm1): LayerNorm((240,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=240, out_features=720, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=240, out_features=240, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): Identity()
          (drop_path1): Identity()
          (norm2): LayerNorm((240,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=240, out_features=960, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=960, out_features=240, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): Identity()
          (drop_path2): Identity()
        )
        (7): Block(
          (norm1): LayerNorm((240,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=240, out_features=720, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=240, out_features=240, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): Identity()
          (drop_path1): Identity()
          (norm2): LayerNorm((240,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=240, out_features=960, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=960, out_features=240, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): Identity()
          (drop_path2): Identity()
        )
      )
      (fc_norm): Identity()
      (head_drop): Dropout(p=0.0, inplace=False)
      (head): Identity()
      (norm): Identity()
    )
    (fusion_layers): ModuleDict(
      (layer_0): AddFusion(
        (input_proj): Sequential(
          (0): LayerNorm()
          (1): Conv2d(768, 240, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (layer_1): AddFusion(
        (input_proj): Sequential(
          (0): LayerNorm()
          (1): Conv2d(768, 240, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (layer_2): AddFusion(
        (input_proj): Sequential(
          (0): LayerNorm()
          (1): Conv2d(768, 240, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (layer_3): AddFusion(
        (input_proj): Sequential(
          (0): LayerNorm()
          (1): Conv2d(768, 240, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
    (mask_decoder): MLPMaskDecoder(
      (query_mlp): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=240, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
      (pix_mlp): MLP(
        (layers): ModuleList(
          (0): Conv2d(240, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
          (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (attn_mlp): MLP(
        (layers): ModuleList(
          (0): Conv2d(240, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
          (2): Conv2d(256, 3072, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (bias_scaling): Linear(in_features=1, out_features=1, bias=True)
    )
  )
  (clip_visual_extractor): FeatureExtractor(
    (patchnorm_pre_ln): Identity()
    (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
    (patch_dropout): Identity()
    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (resblocks): ModuleList(
      (0): ResidualAttentionBlock(
        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
        )
        (ls_1): Identity()
        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=768, out_features=3072, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=3072, out_features=768, bias=True)
        )
        (ls_2): Identity()
      )
      (1): ResidualAttentionBlock(
        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
        )
        (ls_1): Identity()
        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=768, out_features=3072, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=3072, out_features=768, bias=True)
        )
        (ls_2): Identity()
      )
      (2): ResidualAttentionBlock(
        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
        )
        (ls_1): Identity()
        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=768, out_features=3072, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=3072, out_features=768, bias=True)
        )
        (ls_2): Identity()
      )
      (3): ResidualAttentionBlock(
        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
        )
        (ls_1): Identity()
        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=768, out_features=3072, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=3072, out_features=768, bias=True)
        )
        (ls_2): Identity()
      )
      (4): ResidualAttentionBlock(
        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
        )
        (ls_1): Identity()
        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=768, out_features=3072, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=3072, out_features=768, bias=True)
        )
        (ls_2): Identity()
      )
      (5): ResidualAttentionBlock(
        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
        )
        (ls_1): Identity()
        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=768, out_features=3072, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=3072, out_features=768, bias=True)
        )
        (ls_2): Identity()
      )
      (6): ResidualAttentionBlock(
        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
        )
        (ls_1): Identity()
        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=768, out_features=3072, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=3072, out_features=768, bias=True)
        )
        (ls_2): Identity()
      )
      (7): ResidualAttentionBlock(
        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
        )
        (ls_1): Identity()
        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=768, out_features=3072, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=3072, out_features=768, bias=True)
        )
        (ls_2): Identity()
      )
      (8): ResidualAttentionBlock(
        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
        )
        (ls_1): Identity()
        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=768, out_features=3072, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=3072, out_features=768, bias=True)
        )
        (ls_2): Identity()
      )
    )
  )
  (clip_rec_head): RecWithAttnbiasHead(
    (resblocks): ModuleList(
      (0): ResidualAttentionBlock(
        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
        )
        (ls_1): Identity()
        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=768, out_features=3072, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=3072, out_features=768, bias=True)
        )
        (ls_2): Identity()
      )
      (1): ResidualAttentionBlock(
        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
        )
        (ls_1): Identity()
        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=768, out_features=3072, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=3072, out_features=768, bias=True)
        )
        (ls_2): Identity()
      )
      (2): ResidualAttentionBlock(
        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
        )
        (ls_1): Identity()
        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=768, out_features=3072, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=3072, out_features=768, bias=True)
        )
        (ls_2): Identity()
      )
    )
    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (decoder): ModuleList(
      (0): SLSTransformerDecoder(
        (layers): ModuleList(
          (0): ModuleList(
            (0): LayerNormBlock(
              (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (fn): Attention(
                (attn_prob): Softmax(dim=-1)
                (query): Linear(in_features=768, out_features=768, bias=False)
                (key): Linear(in_features=768, out_features=768, bias=False)
                (value): Linear(in_features=768, out_features=768, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=768, out_features=768, bias=True)
                  (1): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (1): LayerNormBlock(
              (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=768, out_features=3072, bias=True)
                  (1): GELU(approximate=none)
                  (2): Dropout(p=0.0, inplace=False)
                  (3): Linear(in_features=3072, out_features=768, bias=True)
                  (4): Dropout(p=0.0, inplace=False)
                )
              )
            )
          )
          (1): ModuleList(
            (0): LayerNormBlock(
              (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (fn): Attention(
                (attn_prob): Softmax(dim=-1)
                (query): Linear(in_features=768, out_features=768, bias=False)
                (key): Linear(in_features=768, out_features=768, bias=False)
                (value): Linear(in_features=768, out_features=768, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=768, out_features=768, bias=True)
                  (1): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (1): LayerNormBlock(
              (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=768, out_features=3072, bias=True)
                  (1): GELU(approximate=none)
                  (2): Dropout(p=0.0, inplace=False)
                  (3): Linear(in_features=3072, out_features=768, bias=True)
                  (4): Dropout(p=0.0, inplace=False)
                )
              )
            )
          )
          (2): ModuleList(
            (0): LayerNormBlock(
              (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (fn): Attention(
                (attn_prob): Softmax(dim=-1)
                (query): Linear(in_features=768, out_features=768, bias=False)
                (key): Linear(in_features=768, out_features=768, bias=False)
                (value): Linear(in_features=768, out_features=768, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=768, out_features=768, bias=True)
                  (1): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (1): LayerNormBlock(
              (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=768, out_features=3072, bias=True)
                  (1): GELU(approximate=none)
                  (2): Dropout(p=0.0, inplace=False)
                  (3): Linear(in_features=3072, out_features=768, bias=True)
                  (4): Dropout(p=0.0, inplace=False)
                )
              )
            )
          )
          (3): ModuleList(
            (0): LayerNormBlock(
              (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (fn): Attention(
                (attn_prob): Softmax(dim=-1)
                (query): Linear(in_features=768, out_features=768, bias=False)
                (key): Linear(in_features=768, out_features=768, bias=False)
                (value): Linear(in_features=768, out_features=768, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=768, out_features=768, bias=True)
                  (1): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (1): LayerNormBlock(
              (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=768, out_features=3072, bias=True)
                  (1): GELU(approximate=none)
                  (2): Dropout(p=0.0, inplace=False)
                  (3): Linear(in_features=3072, out_features=768, bias=True)
                  (4): Dropout(p=0.0, inplace=False)
                )
              )
            )
          )
          (4): ModuleList(
            (0): LayerNormBlock(
              (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (fn): Attention(
                (attn_prob): Softmax(dim=-1)
                (query): Linear(in_features=768, out_features=768, bias=False)
                (key): Linear(in_features=768, out_features=768, bias=False)
                (value): Linear(in_features=768, out_features=768, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=768, out_features=768, bias=True)
                  (1): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (1): LayerNormBlock(
              (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=768, out_features=3072, bias=True)
                  (1): GELU(approximate=none)
                  (2): Dropout(p=0.0, inplace=False)
                  (3): Linear(in_features=3072, out_features=768, bias=True)
                  (4): Dropout(p=0.0, inplace=False)
                )
              )
            )
          )
          (5): ModuleList(
            (0): LayerNormBlock(
              (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (fn): Attention(
                (attn_prob): Softmax(dim=-1)
                (query): Linear(in_features=768, out_features=768, bias=False)
                (key): Linear(in_features=768, out_features=768, bias=False)
                (value): Linear(in_features=768, out_features=768, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=768, out_features=768, bias=True)
                  (1): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (1): LayerNormBlock(
              (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=768, out_features=3072, bias=True)
                  (1): GELU(approximate=none)
                  (2): Dropout(p=0.0, inplace=False)
                  (3): Linear(in_features=3072, out_features=768, bias=True)
                  (4): Dropout(p=0.0, inplace=False)
                )
              )
            )
          )
          (6): ModuleList(
            (0): LayerNormBlock(
              (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (fn): Attention(
                (attn_prob): Softmax(dim=-1)
                (query): Linear(in_features=768, out_features=768, bias=False)
                (key): Linear(in_features=768, out_features=768, bias=False)
                (value): Linear(in_features=768, out_features=768, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=768, out_features=768, bias=True)
                  (1): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (1): LayerNormBlock(
              (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=768, out_features=3072, bias=True)
                  (1): GELU(approximate=none)
                  (2): Dropout(p=0.0, inplace=False)
                  (3): Linear(in_features=3072, out_features=768, bias=True)
                  (4): Dropout(p=0.0, inplace=False)
                )
              )
            )
          )
          (7): ModuleList(
            (0): LayerNormBlock(
              (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (fn): Attention(
                (attn_prob): Softmax(dim=-1)
                (query): Linear(in_features=768, out_features=768, bias=False)
                (key): Linear(in_features=768, out_features=768, bias=False)
                (value): Linear(in_features=768, out_features=768, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=768, out_features=768, bias=True)
                  (1): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (1): LayerNormBlock(
              (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=768, out_features=3072, bias=True)
                  (1): GELU(approximate=none)
                  (2): Dropout(p=0.0, inplace=False)
                  (3): Linear(in_features=3072, out_features=768, bias=True)
                  (4): Dropout(p=0.0, inplace=False)
                )
              )
            )
          )
        )
        (unpatch_conv): ConvTranspose2d(768, 3, kernel_size=(32, 32), stride=(32, 32))
      )
      (1): SLSTransformerDecoder(
        (layers): ModuleList(
          (0): ModuleList(
            (0): LayerNormBlock(
              (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (fn): Attention(
                (attn_prob): Softmax(dim=-1)
                (query): Linear(in_features=768, out_features=768, bias=False)
                (key): Linear(in_features=768, out_features=768, bias=False)
                (value): Linear(in_features=768, out_features=768, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=768, out_features=768, bias=True)
                  (1): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (1): LayerNormBlock(
              (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=768, out_features=3072, bias=True)
                  (1): GELU(approximate=none)
                  (2): Dropout(p=0.0, inplace=False)
                  (3): Linear(in_features=3072, out_features=768, bias=True)
                  (4): Dropout(p=0.0, inplace=False)
                )
              )
            )
          )
          (1): ModuleList(
            (0): LayerNormBlock(
              (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (fn): Attention(
                (attn_prob): Softmax(dim=-1)
                (query): Linear(in_features=768, out_features=768, bias=False)
                (key): Linear(in_features=768, out_features=768, bias=False)
                (value): Linear(in_features=768, out_features=768, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=768, out_features=768, bias=True)
                  (1): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (1): LayerNormBlock(
              (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=768, out_features=3072, bias=True)
                  (1): GELU(approximate=none)
                  (2): Dropout(p=0.0, inplace=False)
                  (3): Linear(in_features=3072, out_features=768, bias=True)
                  (4): Dropout(p=0.0, inplace=False)
                )
              )
            )
          )
          (2): ModuleList(
            (0): LayerNormBlock(
              (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (fn): Attention(
                (attn_prob): Softmax(dim=-1)
                (query): Linear(in_features=768, out_features=768, bias=False)
                (key): Linear(in_features=768, out_features=768, bias=False)
                (value): Linear(in_features=768, out_features=768, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=768, out_features=768, bias=True)
                  (1): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (1): LayerNormBlock(
              (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=768, out_features=3072, bias=True)
                  (1): GELU(approximate=none)
                  (2): Dropout(p=0.0, inplace=False)
                  (3): Linear(in_features=3072, out_features=768, bias=True)
                  (4): Dropout(p=0.0, inplace=False)
                )
              )
            )
          )
          (3): ModuleList(
            (0): LayerNormBlock(
              (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (fn): Attention(
                (attn_prob): Softmax(dim=-1)
                (query): Linear(in_features=768, out_features=768, bias=False)
                (key): Linear(in_features=768, out_features=768, bias=False)
                (value): Linear(in_features=768, out_features=768, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=768, out_features=768, bias=True)
                  (1): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (1): LayerNormBlock(
              (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=768, out_features=3072, bias=True)
                  (1): GELU(approximate=none)
                  (2): Dropout(p=0.0, inplace=False)
                  (3): Linear(in_features=3072, out_features=768, bias=True)
                  (4): Dropout(p=0.0, inplace=False)
                )
              )
            )
          )
          (4): ModuleList(
            (0): LayerNormBlock(
              (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (fn): Attention(
                (attn_prob): Softmax(dim=-1)
                (query): Linear(in_features=768, out_features=768, bias=False)
                (key): Linear(in_features=768, out_features=768, bias=False)
                (value): Linear(in_features=768, out_features=768, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=768, out_features=768, bias=True)
                  (1): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (1): LayerNormBlock(
              (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=768, out_features=3072, bias=True)
                  (1): GELU(approximate=none)
                  (2): Dropout(p=0.0, inplace=False)
                  (3): Linear(in_features=3072, out_features=768, bias=True)
                  (4): Dropout(p=0.0, inplace=False)
                )
              )
            )
          )
          (5): ModuleList(
            (0): LayerNormBlock(
              (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (fn): Attention(
                (attn_prob): Softmax(dim=-1)
                (query): Linear(in_features=768, out_features=768, bias=False)
                (key): Linear(in_features=768, out_features=768, bias=False)
                (value): Linear(in_features=768, out_features=768, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=768, out_features=768, bias=True)
                  (1): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (1): LayerNormBlock(
              (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=768, out_features=3072, bias=True)
                  (1): GELU(approximate=none)
                  (2): Dropout(p=0.0, inplace=False)
                  (3): Linear(in_features=3072, out_features=768, bias=True)
                  (4): Dropout(p=0.0, inplace=False)
                )
              )
            )
          )
          (6): ModuleList(
            (0): LayerNormBlock(
              (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (fn): Attention(
                (attn_prob): Softmax(dim=-1)
                (query): Linear(in_features=768, out_features=768, bias=False)
                (key): Linear(in_features=768, out_features=768, bias=False)
                (value): Linear(in_features=768, out_features=768, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=768, out_features=768, bias=True)
                  (1): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (1): LayerNormBlock(
              (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=768, out_features=3072, bias=True)
                  (1): GELU(approximate=none)
                  (2): Dropout(p=0.0, inplace=False)
                  (3): Linear(in_features=3072, out_features=768, bias=True)
                  (4): Dropout(p=0.0, inplace=False)
                )
              )
            )
          )
          (7): ModuleList(
            (0): LayerNormBlock(
              (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (fn): Attention(
                (attn_prob): Softmax(dim=-1)
                (query): Linear(in_features=768, out_features=768, bias=False)
                (key): Linear(in_features=768, out_features=768, bias=False)
                (value): Linear(in_features=768, out_features=768, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=768, out_features=768, bias=True)
                  (1): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (1): LayerNormBlock(
              (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=768, out_features=3072, bias=True)
                  (1): GELU(approximate=none)
                  (2): Dropout(p=0.0, inplace=False)
                  (3): Linear(in_features=3072, out_features=768, bias=True)
                  (4): Dropout(p=0.0, inplace=False)
                )
              )
            )
          )
        )
        (unpatch_conv): ConvTranspose2d(768, 3, kernel_size=(32, 32), stride=(32, 32))
      )
      (2): SLSTransformerDecoder(
        (layers): ModuleList(
          (0): ModuleList(
            (0): LayerNormBlock(
              (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (fn): Attention(
                (attn_prob): Softmax(dim=-1)
                (query): Linear(in_features=768, out_features=768, bias=False)
                (key): Linear(in_features=768, out_features=768, bias=False)
                (value): Linear(in_features=768, out_features=768, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=768, out_features=768, bias=True)
                  (1): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (1): LayerNormBlock(
              (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=768, out_features=3072, bias=True)
                  (1): GELU(approximate=none)
                  (2): Dropout(p=0.0, inplace=False)
                  (3): Linear(in_features=3072, out_features=768, bias=True)
                  (4): Dropout(p=0.0, inplace=False)
                )
              )
            )
          )
          (1): ModuleList(
            (0): LayerNormBlock(
              (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (fn): Attention(
                (attn_prob): Softmax(dim=-1)
                (query): Linear(in_features=768, out_features=768, bias=False)
                (key): Linear(in_features=768, out_features=768, bias=False)
                (value): Linear(in_features=768, out_features=768, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=768, out_features=768, bias=True)
                  (1): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (1): LayerNormBlock(
              (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=768, out_features=3072, bias=True)
                  (1): GELU(approximate=none)
                  (2): Dropout(p=0.0, inplace=False)
                  (3): Linear(in_features=3072, out_features=768, bias=True)
                  (4): Dropout(p=0.0, inplace=False)
                )
              )
            )
          )
          (2): ModuleList(
            (0): LayerNormBlock(
              (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (fn): Attention(
                (attn_prob): Softmax(dim=-1)
                (query): Linear(in_features=768, out_features=768, bias=False)
                (key): Linear(in_features=768, out_features=768, bias=False)
                (value): Linear(in_features=768, out_features=768, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=768, out_features=768, bias=True)
                  (1): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (1): LayerNormBlock(
              (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=768, out_features=3072, bias=True)
                  (1): GELU(approximate=none)
                  (2): Dropout(p=0.0, inplace=False)
                  (3): Linear(in_features=3072, out_features=768, bias=True)
                  (4): Dropout(p=0.0, inplace=False)
                )
              )
            )
          )
          (3): ModuleList(
            (0): LayerNormBlock(
              (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (fn): Attention(
                (attn_prob): Softmax(dim=-1)
                (query): Linear(in_features=768, out_features=768, bias=False)
                (key): Linear(in_features=768, out_features=768, bias=False)
                (value): Linear(in_features=768, out_features=768, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=768, out_features=768, bias=True)
                  (1): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (1): LayerNormBlock(
              (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=768, out_features=3072, bias=True)
                  (1): GELU(approximate=none)
                  (2): Dropout(p=0.0, inplace=False)
                  (3): Linear(in_features=3072, out_features=768, bias=True)
                  (4): Dropout(p=0.0, inplace=False)
                )
              )
            )
          )
          (4): ModuleList(
            (0): LayerNormBlock(
              (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (fn): Attention(
                (attn_prob): Softmax(dim=-1)
                (query): Linear(in_features=768, out_features=768, bias=False)
                (key): Linear(in_features=768, out_features=768, bias=False)
                (value): Linear(in_features=768, out_features=768, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=768, out_features=768, bias=True)
                  (1): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (1): LayerNormBlock(
              (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=768, out_features=3072, bias=True)
                  (1): GELU(approximate=none)
                  (2): Dropout(p=0.0, inplace=False)
                  (3): Linear(in_features=3072, out_features=768, bias=True)
                  (4): Dropout(p=0.0, inplace=False)
                )
              )
            )
          )
          (5): ModuleList(
            (0): LayerNormBlock(
              (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (fn): Attention(
                (attn_prob): Softmax(dim=-1)
                (query): Linear(in_features=768, out_features=768, bias=False)
                (key): Linear(in_features=768, out_features=768, bias=False)
                (value): Linear(in_features=768, out_features=768, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=768, out_features=768, bias=True)
                  (1): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (1): LayerNormBlock(
              (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=768, out_features=3072, bias=True)
                  (1): GELU(approximate=none)
                  (2): Dropout(p=0.0, inplace=False)
                  (3): Linear(in_features=3072, out_features=768, bias=True)
                  (4): Dropout(p=0.0, inplace=False)
                )
              )
            )
          )
          (6): ModuleList(
            (0): LayerNormBlock(
              (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (fn): Attention(
                (attn_prob): Softmax(dim=-1)
                (query): Linear(in_features=768, out_features=768, bias=False)
                (key): Linear(in_features=768, out_features=768, bias=False)
                (value): Linear(in_features=768, out_features=768, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=768, out_features=768, bias=True)
                  (1): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (1): LayerNormBlock(
              (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=768, out_features=3072, bias=True)
                  (1): GELU(approximate=none)
                  (2): Dropout(p=0.0, inplace=False)
                  (3): Linear(in_features=3072, out_features=768, bias=True)
                  (4): Dropout(p=0.0, inplace=False)
                )
              )
            )
          )
          (7): ModuleList(
            (0): LayerNormBlock(
              (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (fn): Attention(
                (attn_prob): Softmax(dim=-1)
                (query): Linear(in_features=768, out_features=768, bias=False)
                (key): Linear(in_features=768, out_features=768, bias=False)
                (value): Linear(in_features=768, out_features=768, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=768, out_features=768, bias=True)
                  (1): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (1): LayerNormBlock(
              (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=768, out_features=3072, bias=True)
                  (1): GELU(approximate=none)
                  (2): Dropout(p=0.0, inplace=False)
                  (3): Linear(in_features=3072, out_features=768, bias=True)
                  (4): Dropout(p=0.0, inplace=False)
                )
              )
            )
          )
        )
        (unpatch_conv): ConvTranspose2d(768, 3, kernel_size=(32, 32), stride=(32, 32))
      )
    )
    (decoder_act): Tanh()
    (lpips): LPIPS(
      (scaling_layer): ScalingLayer()
      (net): vgg16(
        (slice1): Sequential(
          (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU(inplace=True)
          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): ReLU(inplace=True)
        )
        (slice2): Sequential(
          (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
          (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (6): ReLU(inplace=True)
          (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (8): ReLU(inplace=True)
        )
        (slice3): Sequential(
          (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
          (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (11): ReLU(inplace=True)
          (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (13): ReLU(inplace=True)
          (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (15): ReLU(inplace=True)
        )
        (slice4): Sequential(
          (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
          (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (18): ReLU(inplace=True)
          (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (20): ReLU(inplace=True)
          (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (22): ReLU(inplace=True)
        )
        (slice5): Sequential(
          (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
          (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (25): ReLU(inplace=True)
          (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (27): ReLU(inplace=True)
          (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (29): ReLU(inplace=True)
        )
      )
      (lin0): NetLinLayer(
        (model): Sequential(
          (0): Dropout(p=0.5, inplace=False)
          (1): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
      )
      (lin1): NetLinLayer(
        (model): Sequential(
          (0): Dropout(p=0.5, inplace=False)
          (1): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
      )
      (lin2): NetLinLayer(
        (model): Sequential(
          (0): Dropout(p=0.5, inplace=False)
          (1): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
      )
      (lin3): NetLinLayer(
        (model): Sequential(
          (0): Dropout(p=0.5, inplace=False)
          (1): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
      )
      (lin4): NetLinLayer(
        (model): Sequential(
          (0): Dropout(p=0.5, inplace=False)
          (1): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
      )
    )
  )
  (ov_classifier): LearnableBgOvClassifier(
    (transformer): Transformer(
      (resblocks): ModuleList(
        (0): ResidualAttentionBlock(
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ls_1): Identity()
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ls_2): Identity()
        )
        (1): ResidualAttentionBlock(
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ls_1): Identity()
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ls_2): Identity()
        )
        (2): ResidualAttentionBlock(
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ls_1): Identity()
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ls_2): Identity()
        )
        (3): ResidualAttentionBlock(
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ls_1): Identity()
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ls_2): Identity()
        )
        (4): ResidualAttentionBlock(
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ls_1): Identity()
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ls_2): Identity()
        )
        (5): ResidualAttentionBlock(
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ls_1): Identity()
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ls_2): Identity()
        )
        (6): ResidualAttentionBlock(
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ls_1): Identity()
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ls_2): Identity()
        )
        (7): ResidualAttentionBlock(
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ls_1): Identity()
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ls_2): Identity()
        )
        (8): ResidualAttentionBlock(
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ls_1): Identity()
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ls_2): Identity()
        )
        (9): ResidualAttentionBlock(
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ls_1): Identity()
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ls_2): Identity()
        )
        (10): ResidualAttentionBlock(
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ls_1): Identity()
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ls_2): Identity()
        )
        (11): ResidualAttentionBlock(
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ls_1): Identity()
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ls_2): Identity()
        )
      )
    )
    (token_embedding): Embedding(49408, 512)
    (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
)
[12/13 00:27:52 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from output/vqsan_post/model_final.pth ...
[12/13 00:27:52 fvcore.common.checkpoint]: [Checkpointer] Loading from output/vqsan_post/model_final.pth ...
loaded pretrained LPIPS loss from resources/models/lpips/vgg.pth
[12/13 00:27:53 d2.data.datasets.coco]: Loaded 5000 images with semantic segmentation from datasets/coco/val2017
[12/13 00:27:53 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=2560, sample_style='choice')]
[12/13 00:27:53 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[12/13 00:27:53 d2.data.common]: Serializing 5000 elements to byte tensors and concatenating them all ...
[12/13 00:27:54 d2.data.common]: Serialized dataset takes 1.01 MiB
[12/13 00:27:54 d2.data.datasets.coco]: Loaded 5000 images with semantic segmentation from datasets/coco/val2017
[12/13 00:27:54 d2.evaluation.evaluator]: Start inference on 2500 batches
[12/13 00:28:01 san.model.side_adapter.side_adapter]: fuse clip 0 to 0
[12/13 00:28:01 san.model.side_adapter.side_adapter]: fuse clip 3 to 1
[12/13 00:28:01 san.model.side_adapter.side_adapter]: fuse clip 6 to 2
[12/13 00:28:01 san.model.side_adapter.side_adapter]: fuse clip 9 to 3
[12/13 00:28:02 d2.evaluation.evaluator]: Inference done 11/2500. Dataloading: 0.0012 s/iter. Inference: 0.0758 s/iter. Eval: 0.0173 s/iter. Total: 0.0943 s/iter. ETA=0:03:54
[12/13 00:28:07 d2.evaluation.evaluator]: Inference done 64/2500. Dataloading: 0.0018 s/iter. Inference: 0.0801 s/iter. Eval: 0.0139 s/iter. Total: 0.0958 s/iter. ETA=0:03:53
[12/13 00:28:12 d2.evaluation.evaluator]: Inference done 121/2500. Dataloading: 0.0018 s/iter. Inference: 0.0751 s/iter. Eval: 0.0149 s/iter. Total: 0.0919 s/iter. ETA=0:03:38
[12/13 00:28:17 d2.evaluation.evaluator]: Inference done 181/2500. Dataloading: 0.0018 s/iter. Inference: 0.0720 s/iter. Eval: 0.0151 s/iter. Total: 0.0890 s/iter. ETA=0:03:26
[12/13 00:28:22 d2.evaluation.evaluator]: Inference done 243/2500. Dataloading: 0.0018 s/iter. Inference: 0.0701 s/iter. Eval: 0.0148 s/iter. Total: 0.0868 s/iter. ETA=0:03:15
[12/13 00:28:27 d2.evaluation.evaluator]: Inference done 303/2500. Dataloading: 0.0019 s/iter. Inference: 0.0696 s/iter. Eval: 0.0148 s/iter. Total: 0.0864 s/iter. ETA=0:03:09
[12/13 00:28:32 d2.evaluation.evaluator]: Inference done 364/2500. Dataloading: 0.0019 s/iter. Inference: 0.0690 s/iter. Eval: 0.0149 s/iter. Total: 0.0858 s/iter. ETA=0:03:03
[12/13 00:28:37 d2.evaluation.evaluator]: Inference done 424/2500. Dataloading: 0.0019 s/iter. Inference: 0.0688 s/iter. Eval: 0.0148 s/iter. Total: 0.0855 s/iter. ETA=0:02:57
[12/13 00:28:42 d2.evaluation.evaluator]: Inference done 485/2500. Dataloading: 0.0019 s/iter. Inference: 0.0685 s/iter. Eval: 0.0147 s/iter. Total: 0.0851 s/iter. ETA=0:02:51
[12/13 00:28:47 d2.evaluation.evaluator]: Inference done 546/2500. Dataloading: 0.0019 s/iter. Inference: 0.0682 s/iter. Eval: 0.0147 s/iter. Total: 0.0848 s/iter. ETA=0:02:45
[12/13 00:28:52 d2.evaluation.evaluator]: Inference done 606/2500. Dataloading: 0.0019 s/iter. Inference: 0.0682 s/iter. Eval: 0.0147 s/iter. Total: 0.0848 s/iter. ETA=0:02:40
[12/13 00:28:57 d2.evaluation.evaluator]: Inference done 664/2500. Dataloading: 0.0019 s/iter. Inference: 0.0682 s/iter. Eval: 0.0148 s/iter. Total: 0.0849 s/iter. ETA=0:02:35
[12/13 00:29:02 d2.evaluation.evaluator]: Inference done 724/2500. Dataloading: 0.0019 s/iter. Inference: 0.0681 s/iter. Eval: 0.0148 s/iter. Total: 0.0848 s/iter. ETA=0:02:30
[12/13 00:29:07 d2.evaluation.evaluator]: Inference done 786/2500. Dataloading: 0.0019 s/iter. Inference: 0.0678 s/iter. Eval: 0.0148 s/iter. Total: 0.0845 s/iter. ETA=0:02:24
[12/13 00:29:12 d2.evaluation.evaluator]: Inference done 847/2500. Dataloading: 0.0019 s/iter. Inference: 0.0677 s/iter. Eval: 0.0148 s/iter. Total: 0.0844 s/iter. ETA=0:02:19
[12/13 00:29:17 d2.evaluation.evaluator]: Inference done 906/2500. Dataloading: 0.0019 s/iter. Inference: 0.0678 s/iter. Eval: 0.0148 s/iter. Total: 0.0845 s/iter. ETA=0:02:14
[12/13 00:29:22 d2.evaluation.evaluator]: Inference done 966/2500. Dataloading: 0.0019 s/iter. Inference: 0.0677 s/iter. Eval: 0.0148 s/iter. Total: 0.0844 s/iter. ETA=0:02:09
[12/13 00:29:44 d2.evaluation.evaluator]: Inference done 1000/2500. Dataloading: 0.0019 s/iter. Inference: 0.0865 s/iter. Eval: 0.0148 s/iter. Total: 0.1032 s/iter. ETA=0:02:34
[12/13 00:29:49 d2.evaluation.evaluator]: Inference done 1061/2500. Dataloading: 0.0019 s/iter. Inference: 0.0853 s/iter. Eval: 0.0148 s/iter. Total: 0.1020 s/iter. ETA=0:02:26
[12/13 00:29:54 d2.evaluation.evaluator]: Inference done 1119/2500. Dataloading: 0.0019 s/iter. Inference: 0.0845 s/iter. Eval: 0.0147 s/iter. Total: 0.1012 s/iter. ETA=0:02:19
[12/13 00:29:59 d2.evaluation.evaluator]: Inference done 1180/2500. Dataloading: 0.0019 s/iter. Inference: 0.0835 s/iter. Eval: 0.0148 s/iter. Total: 0.1002 s/iter. ETA=0:02:12
[12/13 00:30:04 d2.evaluation.evaluator]: Inference done 1240/2500. Dataloading: 0.0019 s/iter. Inference: 0.0827 s/iter. Eval: 0.0147 s/iter. Total: 0.0994 s/iter. ETA=0:02:05
[12/13 00:30:09 d2.evaluation.evaluator]: Inference done 1303/2500. Dataloading: 0.0019 s/iter. Inference: 0.0818 s/iter. Eval: 0.0147 s/iter. Total: 0.0985 s/iter. ETA=0:01:57
[12/13 00:30:14 d2.evaluation.evaluator]: Inference done 1361/2500. Dataloading: 0.0019 s/iter. Inference: 0.0813 s/iter. Eval: 0.0147 s/iter. Total: 0.0980 s/iter. ETA=0:01:51
[12/13 00:30:19 d2.evaluation.evaluator]: Inference done 1420/2500. Dataloading: 0.0019 s/iter. Inference: 0.0809 s/iter. Eval: 0.0147 s/iter. Total: 0.0975 s/iter. ETA=0:01:45
[12/13 00:30:24 d2.evaluation.evaluator]: Inference done 1481/2500. Dataloading: 0.0019 s/iter. Inference: 0.0803 s/iter. Eval: 0.0147 s/iter. Total: 0.0969 s/iter. ETA=0:01:38
[12/13 00:30:29 d2.evaluation.evaluator]: Inference done 1541/2500. Dataloading: 0.0019 s/iter. Inference: 0.0798 s/iter. Eval: 0.0147 s/iter. Total: 0.0964 s/iter. ETA=0:01:32
[12/13 00:30:34 d2.evaluation.evaluator]: Inference done 1604/2500. Dataloading: 0.0019 s/iter. Inference: 0.0791 s/iter. Eval: 0.0147 s/iter. Total: 0.0958 s/iter. ETA=0:01:25
[12/13 00:30:39 d2.evaluation.evaluator]: Inference done 1664/2500. Dataloading: 0.0019 s/iter. Inference: 0.0787 s/iter. Eval: 0.0147 s/iter. Total: 0.0953 s/iter. ETA=0:01:19
[12/13 00:30:44 d2.evaluation.evaluator]: Inference done 1723/2500. Dataloading: 0.0019 s/iter. Inference: 0.0783 s/iter. Eval: 0.0147 s/iter. Total: 0.0950 s/iter. ETA=0:01:13
[12/13 00:30:49 d2.evaluation.evaluator]: Inference done 1783/2500. Dataloading: 0.0019 s/iter. Inference: 0.0779 s/iter. Eval: 0.0147 s/iter. Total: 0.0946 s/iter. ETA=0:01:07
[12/13 00:30:55 d2.evaluation.evaluator]: Inference done 1838/2500. Dataloading: 0.0019 s/iter. Inference: 0.0778 s/iter. Eval: 0.0147 s/iter. Total: 0.0945 s/iter. ETA=0:01:02
[12/13 00:31:00 d2.evaluation.evaluator]: Inference done 1893/2500. Dataloading: 0.0019 s/iter. Inference: 0.0777 s/iter. Eval: 0.0148 s/iter. Total: 0.0945 s/iter. ETA=0:00:57
[12/13 00:31:05 d2.evaluation.evaluator]: Inference done 1949/2500. Dataloading: 0.0019 s/iter. Inference: 0.0776 s/iter. Eval: 0.0147 s/iter. Total: 0.0943 s/iter. ETA=0:00:51
[12/13 00:31:20 d2.evaluation.evaluator]: Inference done 2000/2500. Dataloading: 0.0019 s/iter. Inference: 0.0830 s/iter. Eval: 0.0147 s/iter. Total: 0.0997 s/iter. ETA=0:00:49
[12/13 00:31:25 d2.evaluation.evaluator]: Inference done 2054/2500. Dataloading: 0.0019 s/iter. Inference: 0.0828 s/iter. Eval: 0.0148 s/iter. Total: 0.0995 s/iter. ETA=0:00:44
[12/13 00:31:30 d2.evaluation.evaluator]: Inference done 2116/2500. Dataloading: 0.0019 s/iter. Inference: 0.0823 s/iter. Eval: 0.0148 s/iter. Total: 0.0990 s/iter. ETA=0:00:38
[12/13 00:31:35 d2.evaluation.evaluator]: Inference done 2175/2500. Dataloading: 0.0019 s/iter. Inference: 0.0819 s/iter. Eval: 0.0148 s/iter. Total: 0.0986 s/iter. ETA=0:00:32
[12/13 00:31:40 d2.evaluation.evaluator]: Inference done 2236/2500. Dataloading: 0.0019 s/iter. Inference: 0.0815 s/iter. Eval: 0.0147 s/iter. Total: 0.0982 s/iter. ETA=0:00:25
[12/13 00:31:45 d2.evaluation.evaluator]: Inference done 2296/2500. Dataloading: 0.0019 s/iter. Inference: 0.0812 s/iter. Eval: 0.0147 s/iter. Total: 0.0979 s/iter. ETA=0:00:19
[12/13 00:31:50 d2.evaluation.evaluator]: Inference done 2356/2500. Dataloading: 0.0019 s/iter. Inference: 0.0808 s/iter. Eval: 0.0147 s/iter. Total: 0.0975 s/iter. ETA=0:00:14
[12/13 00:31:56 d2.evaluation.evaluator]: Inference done 2418/2500. Dataloading: 0.0019 s/iter. Inference: 0.0804 s/iter. Eval: 0.0147 s/iter. Total: 0.0971 s/iter. ETA=0:00:07
[12/13 00:32:01 d2.evaluation.evaluator]: Inference done 2479/2500. Dataloading: 0.0019 s/iter. Inference: 0.0800 s/iter. Eval: 0.0147 s/iter. Total: 0.0967 s/iter. ETA=0:00:02
[12/13 00:32:03 d2.evaluation.evaluator]: Total inference time: 0:04:01.687937 (0.096869 s / iter per device, on 2 devices)
[12/13 00:32:03 d2.evaluation.evaluator]: Total inference pure compute time: 0:03:19 (0.079915 s / iter per device, on 2 devices)
[12/13 00:32:04 d2.evaluation.sem_seg_evaluation]: OrderedDict([('sem_seg', {'mIoU': 24.440312539865413, 'fwIoU': 37.65836090169871, 'IoU-person': 72.44850341981173, 'BoundaryIoU-person': 69.52582215927566, 'min(IoU, B-Iou)-person': 69.52582215927566, 'IoU-bicycle': 46.29232097263331, 'BoundaryIoU-bicycle': 0.6382384878167986, 'min(IoU, B-Iou)-bicycle': 0.6382384878167986, 'IoU-car': 38.35748375607354, 'BoundaryIoU-car': 0.0, 'min(IoU, B-Iou)-car': 0.0, 'IoU-motorcycle': 64.54258526781177, 'BoundaryIoU-motorcycle': 0.0, 'min(IoU, B-Iou)-motorcycle': 0.0, 'IoU-airplane': 56.96484365058334, 'BoundaryIoU-airplane': 0.0, 'min(IoU, B-Iou)-airplane': 0.0, 'IoU-bus': 63.572833726369424, 'BoundaryIoU-bus': 0.0, 'min(IoU, B-Iou)-bus': 0.0, 'IoU-train': 57.49608843781111, 'BoundaryIoU-train': 0.0, 'min(IoU, B-Iou)-train': 0.0, 'IoU-truck': 35.71385098680448, 'BoundaryIoU-truck': 0.0, 'min(IoU, B-Iou)-truck': 0.0, 'IoU-boat': 40.37232634400187, 'BoundaryIoU-boat': 0.0, 'min(IoU, B-Iou)-boat': 0.0, 'IoU-traffic light': 22.845352496473225, 'BoundaryIoU-traffic light': 0.0, 'min(IoU, B-Iou)-traffic light': 0.0, 'IoU-fire hydrant': 57.425690128543636, 'BoundaryIoU-fire hydrant': 0.0, 'min(IoU, B-Iou)-fire hydrant': 0.0, 'IoU-stop sign': 52.78796812739811, 'BoundaryIoU-stop sign': 0.0, 'min(IoU, B-Iou)-stop sign': 0.0, 'IoU-parking meter': 17.622887269344083, 'BoundaryIoU-parking meter': 0.0, 'min(IoU, B-Iou)-parking meter': 0.0, 'IoU-bench': 29.027452067072744, 'BoundaryIoU-bench': 0.0, 'min(IoU, B-Iou)-bench': 0.0, 'IoU-bird': 43.82395512649969, 'BoundaryIoU-bird': 0.0, 'min(IoU, B-Iou)-bird': 0.0, 'IoU-cat': 61.49489863608093, 'BoundaryIoU-cat': 0.0, 'min(IoU, B-Iou)-cat': 0.0, 'IoU-dog': 46.0201605734264, 'BoundaryIoU-dog': 0.0, 'min(IoU, B-Iou)-dog': 0.0, 'IoU-horse': 58.26686934990818, 'BoundaryIoU-horse': 0.0, 'min(IoU, B-Iou)-horse': 0.0, 'IoU-sheep': 66.24897459988989, 'BoundaryIoU-sheep': 0.0, 'min(IoU, B-Iou)-sheep': 0.0, 'IoU-cow': 46.65195780686559, 'BoundaryIoU-cow': 0.0, 'min(IoU, B-Iou)-cow': 0.0, 'IoU-elephant': 76.70373574730922, 'BoundaryIoU-elephant': 0.0, 'min(IoU, B-Iou)-elephant': 0.0, 'IoU-bear': 66.48170195603505, 'BoundaryIoU-bear': 0.0, 'min(IoU, B-Iou)-bear': 0.0, 'IoU-zebra': 85.1827337735623, 'BoundaryIoU-zebra': 0.0, 'min(IoU, B-Iou)-zebra': 0.0, 'IoU-giraffe': 70.59198259232616, 'BoundaryIoU-giraffe': 0.0, 'min(IoU, B-Iou)-giraffe': 0.0, 'IoU-backpack': 8.954479070420977, 'BoundaryIoU-backpack': 0.0, 'min(IoU, B-Iou)-backpack': 0.0, 'IoU-umbrella': 44.91051920460116, 'BoundaryIoU-umbrella': 0.0, 'min(IoU, B-Iou)-umbrella': 0.0, 'IoU-handbag': 7.733605302444505, 'BoundaryIoU-handbag': 0.0, 'min(IoU, B-Iou)-handbag': 0.0, 'IoU-tie': 0.0, 'BoundaryIoU-tie': 0.0, 'min(IoU, B-Iou)-tie': 0.0, 'IoU-suitcase': 42.556950478812325, 'BoundaryIoU-suitcase': 0.0, 'min(IoU, B-Iou)-suitcase': 0.0, 'IoU-frisbee': 30.681930305487278, 'BoundaryIoU-frisbee': 0.0, 'min(IoU, B-Iou)-frisbee': 0.0, 'IoU-skis': 15.69567217195357, 'BoundaryIoU-skis': 0.0, 'min(IoU, B-Iou)-skis': 0.0, 'IoU-snowboard': 10.41987694695416, 'BoundaryIoU-snowboard': 0.0, 'min(IoU, B-Iou)-snowboard': 0.0, 'IoU-sports ball': 30.77730861669735, 'BoundaryIoU-sports ball': 0.0, 'min(IoU, B-Iou)-sports ball': 0.0, 'IoU-kite': 32.292724400125294, 'BoundaryIoU-kite': 0.0, 'min(IoU, B-Iou)-kite': 0.0, 'IoU-baseball bat': 17.396594111866616, 'BoundaryIoU-baseball bat': 0.0, 'min(IoU, B-Iou)-baseball bat': 0.0, 'IoU-baseball glove': 48.14549810599929, 'BoundaryIoU-baseball glove': 0.0, 'min(IoU, B-Iou)-baseball glove': 0.0, 'IoU-skateboard': 22.594172265838253, 'BoundaryIoU-skateboard': 0.0, 'min(IoU, B-Iou)-skateboard': 0.0, 'IoU-surfboard': 43.70004833740955, 'BoundaryIoU-surfboard': 0.0, 'min(IoU, B-Iou)-surfboard': 0.0, 'IoU-tennis racket': 27.696758181972434, 'BoundaryIoU-tennis racket': 0.0, 'min(IoU, B-Iou)-tennis racket': 0.0, 'IoU-bottle': 21.489569056366395, 'BoundaryIoU-bottle': 0.0, 'min(IoU, B-Iou)-bottle': 0.0, 'IoU-wine glass': 27.361847877497407, 'BoundaryIoU-wine glass': 0.0, 'min(IoU, B-Iou)-wine glass': 0.0, 'IoU-cup': 22.394856872175065, 'BoundaryIoU-cup': 0.0, 'min(IoU, B-Iou)-cup': 0.0, 'IoU-fork': 13.919344763609582, 'BoundaryIoU-fork': 0.0, 'min(IoU, B-Iou)-fork': 0.0, 'IoU-knife': 4.721273803850398, 'BoundaryIoU-knife': 0.0, 'min(IoU, B-Iou)-knife': 0.0, 'IoU-spoon': 15.539864394679265, 'BoundaryIoU-spoon': 0.0, 'min(IoU, B-Iou)-spoon': 0.0, 'IoU-bowl': 22.000400866731507, 'BoundaryIoU-bowl': 0.0, 'min(IoU, B-Iou)-bowl': 0.0, 'IoU-banana': 34.75053262713932, 'BoundaryIoU-banana': 0.0, 'min(IoU, B-Iou)-banana': 0.0, 'IoU-apple': 24.07389439965676, 'BoundaryIoU-apple': 0.0, 'min(IoU, B-Iou)-apple': 0.0, 'IoU-sandwich': 32.70548705808689, 'BoundaryIoU-sandwich': 0.0, 'min(IoU, B-Iou)-sandwich': 0.0, 'IoU-orange': 31.938377253170202, 'BoundaryIoU-orange': 0.0, 'min(IoU, B-Iou)-orange': 0.0, 'IoU-broccoli': 25.30426143287826, 'BoundaryIoU-broccoli': 0.0, 'min(IoU, B-Iou)-broccoli': 0.0, 'IoU-carrot': 32.36834853715788, 'BoundaryIoU-carrot': 0.0, 'min(IoU, B-Iou)-carrot': 0.0, 'IoU-hot dog': 24.89158733668382, 'BoundaryIoU-hot dog': 0.0, 'min(IoU, B-Iou)-hot dog': 0.0, 'IoU-pizza': 64.57783646603545, 'BoundaryIoU-pizza': 0.0, 'min(IoU, B-Iou)-pizza': 0.0, 'IoU-donut': 50.13283322932891, 'BoundaryIoU-donut': 0.0, 'min(IoU, B-Iou)-donut': 0.0, 'IoU-cake': 49.94683038208378, 'BoundaryIoU-cake': 0.0, 'min(IoU, B-Iou)-cake': 0.0, 'IoU-chair': 13.288453162091852, 'BoundaryIoU-chair': 0.0, 'min(IoU, B-Iou)-chair': 0.0, 'IoU-couch': 28.592841119505184, 'BoundaryIoU-couch': 0.0, 'min(IoU, B-Iou)-couch': 0.0, 'IoU-potted plant': 17.84897474553689, 'BoundaryIoU-potted plant': 0.0, 'min(IoU, B-Iou)-potted plant': 0.0, 'IoU-bed': 41.01228281150994, 'BoundaryIoU-bed': 0.0, 'min(IoU, B-Iou)-bed': 0.0, 'IoU-dining table': 30.411102923121913, 'BoundaryIoU-dining table': 0.0, 'min(IoU, B-Iou)-dining table': 0.0, 'IoU-toilet': 44.41058739363292, 'BoundaryIoU-toilet': 0.0, 'min(IoU, B-Iou)-toilet': 0.0, 'IoU-tv': 26.082494924490852, 'BoundaryIoU-tv': 0.0, 'min(IoU, B-Iou)-tv': 0.0, 'IoU-laptop': 34.78669500025475, 'BoundaryIoU-laptop': 0.0, 'min(IoU, B-Iou)-laptop': 0.0, 'IoU-mouse': 22.34897116912376, 'BoundaryIoU-mouse': 0.0, 'min(IoU, B-Iou)-mouse': 0.0, 'IoU-remote': 18.54838866305549, 'BoundaryIoU-remote': 0.0, 'min(IoU, B-Iou)-remote': 0.0, 'IoU-keyboard': 28.283296677534263, 'BoundaryIoU-keyboard': 0.0, 'min(IoU, B-Iou)-keyboard': 0.0, 'IoU-cell phone': 53.52325005247348, 'BoundaryIoU-cell phone': 0.0, 'min(IoU, B-Iou)-cell phone': 0.0, 'IoU-microwave': 11.162993889167923, 'BoundaryIoU-microwave': 0.0, 'min(IoU, B-Iou)-microwave': 0.0, 'IoU-oven': 27.36820472303261, 'BoundaryIoU-oven': 0.0, 'min(IoU, B-Iou)-oven': 0.0, 'IoU-toaster': 34.679376083188906, 'BoundaryIoU-toaster': 0.0, 'min(IoU, B-Iou)-toaster': 0.0, 'IoU-sink': 20.206347455061838, 'BoundaryIoU-sink': 0.0, 'min(IoU, B-Iou)-sink': 0.0, 'IoU-refrigerator': 21.059028014365833, 'BoundaryIoU-refrigerator': 0.0, 'min(IoU, B-Iou)-refrigerator': 0.0, 'IoU-book': 23.06900986667918, 'BoundaryIoU-book': 0.0, 'min(IoU, B-Iou)-book': 0.0, 'IoU-clock': 53.62861412968507, 'BoundaryIoU-clock': 0.0, 'min(IoU, B-Iou)-clock': 0.0, 'IoU-vase': 32.75725167950723, 'BoundaryIoU-vase': 0.0, 'min(IoU, B-Iou)-vase': 0.0, 'IoU-scissors': 20.3086166188004, 'BoundaryIoU-scissors': 0.0, 'min(IoU, B-Iou)-scissors': 0.0, 'IoU-teddy bear': 55.59639728040745, 'BoundaryIoU-teddy bear': 0.0, 'min(IoU, B-Iou)-teddy bear': 0.0, 'IoU-hair drier': 0.0, 'BoundaryIoU-hair drier': 0.0, 'min(IoU, B-Iou)-hair drier': 0.0, 'IoU-toothbrush': 3.1521867495965044, 'BoundaryIoU-toothbrush': 0.0, 'min(IoU, B-Iou)-toothbrush': 0.0, 'IoU-banner': 17.74853376168239, 'BoundaryIoU-banner': 0.0, 'min(IoU, B-Iou)-banner': 0.0, 'IoU-blanket': 0.0, 'BoundaryIoU-blanket': 0.0, 'min(IoU, B-Iou)-blanket': 0.0, 'IoU-branch': 0.0, 'BoundaryIoU-branch': 0.0, 'min(IoU, B-Iou)-branch': 0.0, 'IoU-bridge': 12.72730663873552, 'BoundaryIoU-bridge': 0.0, 'min(IoU, B-Iou)-bridge': 0.0, 'IoU-building-other': 39.98887003984798, 'BoundaryIoU-building-other': 0.0, 'min(IoU, B-Iou)-building-other': 0.0, 'IoU-bush': 20.346144329249988, 'BoundaryIoU-bush': 0.0, 'min(IoU, B-Iou)-bush': 0.0, 'IoU-cabinet': 7.720746564731776, 'BoundaryIoU-cabinet': 0.0, 'min(IoU, B-Iou)-cabinet': 0.0, 'IoU-cage': 4.987729735300208, 'BoundaryIoU-cage': 0.0, 'min(IoU, B-Iou)-cage': 0.0, 'IoU-cardboard': 5.449711678271656, 'BoundaryIoU-cardboard': 0.0, 'min(IoU, B-Iou)-cardboard': 0.0, 'IoU-carpet': 28.011397830616986, 'BoundaryIoU-carpet': 0.0, 'min(IoU, B-Iou)-carpet': 0.0, 'IoU-ceiling-other': 37.53897249525958, 'BoundaryIoU-ceiling-other': 0.0, 'min(IoU, B-Iou)-ceiling-other': 0.0, 'IoU-ceiling-tile': 0.0, 'BoundaryIoU-ceiling-tile': 0.0, 'min(IoU, B-Iou)-ceiling-tile': 0.0, 'IoU-cloth': 0.0, 'BoundaryIoU-cloth': 0.0, 'min(IoU, B-Iou)-cloth': 0.0, 'IoU-clothes': 0.20070288336358078, 'BoundaryIoU-clothes': 0.0, 'min(IoU, B-Iou)-clothes': 0.0, 'IoU-clouds': 38.447944444559255, 'BoundaryIoU-clouds': 0.0, 'min(IoU, B-Iou)-clouds': 0.0, 'IoU-counter': 4.875195115991989, 'BoundaryIoU-counter': 0.0, 'min(IoU, B-Iou)-counter': 0.0, 'IoU-cupboard': 1.7612399908273624, 'BoundaryIoU-cupboard': 0.0, 'min(IoU, B-Iou)-cupboard': 0.0, 'IoU-curtain': 27.597678371456947, 'BoundaryIoU-curtain': 0.0, 'min(IoU, B-Iou)-curtain': 0.0, 'IoU-desk-stuff': 24.214810190514523, 'BoundaryIoU-desk-stuff': 0.0, 'min(IoU, B-Iou)-desk-stuff': 0.0, 'IoU-dirt': 30.26387970343926, 'BoundaryIoU-dirt': 0.0, 'min(IoU, B-Iou)-dirt': 0.0, 'IoU-door-stuff': 8.604471507770608, 'BoundaryIoU-door-stuff': 0.0, 'min(IoU, B-Iou)-door-stuff': 0.0, 'IoU-fence': 24.4005544833297, 'BoundaryIoU-fence': 0.0, 'min(IoU, B-Iou)-fence': 0.0, 'IoU-floor-marble': 0.0, 'BoundaryIoU-floor-marble': 0.0, 'min(IoU, B-Iou)-floor-marble': 0.0, 'IoU-floor-other': 7.697222311432685, 'BoundaryIoU-floor-other': 0.0, 'min(IoU, B-Iou)-floor-other': 0.0, 'IoU-floor-stone': 0.3310327996322173, 'BoundaryIoU-floor-stone': 0.0, 'min(IoU, B-Iou)-floor-stone': 0.0, 'IoU-floor-tile': 26.887137686309842, 'BoundaryIoU-floor-tile': 0.0, 'min(IoU, B-Iou)-floor-tile': 0.0, 'IoU-floor-wood': 33.748903581842775, 'BoundaryIoU-floor-wood': 0.0, 'min(IoU, B-Iou)-floor-wood': 0.0, 'IoU-flower': 29.929843681990015, 'BoundaryIoU-flower': 0.0, 'min(IoU, B-Iou)-flower': 0.0, 'IoU-fog': 0.0, 'BoundaryIoU-fog': 0.0, 'min(IoU, B-Iou)-fog': 0.0, 'IoU-food-other': 12.081618428240493, 'BoundaryIoU-food-other': 0.0, 'min(IoU, B-Iou)-food-other': 0.0, 'IoU-fruit': 6.780300886172887, 'BoundaryIoU-fruit': 0.0, 'min(IoU, B-Iou)-fruit': 0.0, 'IoU-furniture-other': 2.914305198810689, 'BoundaryIoU-furniture-other': 0.0, 'min(IoU, B-Iou)-furniture-other': 0.0, 'IoU-grass': 62.56354913947732, 'BoundaryIoU-grass': 0.0, 'min(IoU, B-Iou)-grass': 0.0, 'IoU-gravel': 14.974813001938807, 'BoundaryIoU-gravel': 0.0, 'min(IoU, B-Iou)-gravel': 0.0, 'IoU-ground-other': 3.650224664371838, 'BoundaryIoU-ground-other': 0.0, 'min(IoU, B-Iou)-ground-other': 0.0, 'IoU-hill': 8.294793136435917, 'BoundaryIoU-hill': 0.0, 'min(IoU, B-Iou)-hill': 0.0, 'IoU-house': 9.445681535587271, 'BoundaryIoU-house': 0.0, 'min(IoU, B-Iou)-house': 0.0, 'IoU-leaves': 4.601539210274143, 'BoundaryIoU-leaves': 0.0, 'min(IoU, B-Iou)-leaves': 0.0, 'IoU-light': 9.692783225638928, 'BoundaryIoU-light': 0.0, 'min(IoU, B-Iou)-light': 0.0, 'IoU-mat': 0.0, 'BoundaryIoU-mat': 0.0, 'min(IoU, B-Iou)-mat': 0.0, 'IoU-metal': 0.22827646935191376, 'BoundaryIoU-metal': 0.0, 'min(IoU, B-Iou)-metal': 0.0, 'IoU-mirror-stuff': 7.849813326294469, 'BoundaryIoU-mirror-stuff': 0.0, 'min(IoU, B-Iou)-mirror-stuff': 0.0, 'IoU-moss': 0.0, 'BoundaryIoU-moss': 0.0, 'min(IoU, B-Iou)-moss': 0.0, 'IoU-mountain': 31.018500355958896, 'BoundaryIoU-mountain': 0.0, 'min(IoU, B-Iou)-mountain': 0.0, 'IoU-mud': 0.0, 'BoundaryIoU-mud': 0.0, 'min(IoU, B-Iou)-mud': 0.0, 'IoU-napkin': 0.0, 'BoundaryIoU-napkin': 0.0, 'min(IoU, B-Iou)-napkin': 0.0, 'IoU-net': 13.21004330269749, 'BoundaryIoU-net': 0.0, 'min(IoU, B-Iou)-net': 0.0, 'IoU-paper': 3.1640244110786044, 'BoundaryIoU-paper': 0.0, 'min(IoU, B-Iou)-paper': 0.0, 'IoU-pavement': 31.763398753994547, 'BoundaryIoU-pavement': 0.0, 'min(IoU, B-Iou)-pavement': 0.0, 'IoU-pillow': 0.0, 'BoundaryIoU-pillow': 0.0, 'min(IoU, B-Iou)-pillow': 0.0, 'IoU-plant-other': 16.83889247012091, 'BoundaryIoU-plant-other': 0.0, 'min(IoU, B-Iou)-plant-other': 0.0, 'IoU-plastic': 0.0, 'BoundaryIoU-plastic': 0.0, 'min(IoU, B-Iou)-plastic': 0.0, 'IoU-platform': 9.574699987635606, 'BoundaryIoU-platform': 0.0, 'min(IoU, B-Iou)-platform': 0.0, 'IoU-playingfield': 60.943221537600245, 'BoundaryIoU-playingfield': 0.0, 'min(IoU, B-Iou)-playingfield': 0.0, 'IoU-railing': 4.301239486604085, 'BoundaryIoU-railing': 0.0, 'min(IoU, B-Iou)-railing': 0.0, 'IoU-railroad': 36.810569526827955, 'BoundaryIoU-railroad': 0.0, 'min(IoU, B-Iou)-railroad': 0.0, 'IoU-river': 15.02077097863289, 'BoundaryIoU-river': 0.0, 'min(IoU, B-Iou)-river': 0.0, 'IoU-road': 45.687670845226855, 'BoundaryIoU-road': 0.0, 'min(IoU, B-Iou)-road': 0.0, 'IoU-rock': 30.288653615661204, 'BoundaryIoU-rock': 0.0, 'min(IoU, B-Iou)-rock': 0.0, 'IoU-roof': 0.14916330766339972, 'BoundaryIoU-roof': 0.0, 'min(IoU, B-Iou)-roof': 0.0, 'IoU-rug': 8.290755924104712, 'BoundaryIoU-rug': 0.0, 'min(IoU, B-Iou)-rug': 0.0, 'IoU-salad': 0.0, 'BoundaryIoU-salad': 0.0, 'min(IoU, B-Iou)-salad': 0.0, 'IoU-sand': 37.15148976943634, 'BoundaryIoU-sand': 0.0, 'min(IoU, B-Iou)-sand': 0.0, 'IoU-sea': 70.15221350390814, 'BoundaryIoU-sea': 0.0, 'min(IoU, B-Iou)-sea': 0.0, 'IoU-shelf': 7.3138885796228195, 'BoundaryIoU-shelf': 0.0, 'min(IoU, B-Iou)-shelf': 0.0, 'IoU-sky-other': 56.443364873346184, 'BoundaryIoU-sky-other': 0.0, 'min(IoU, B-Iou)-sky-other': 0.0, 'IoU-skyscraper': 0.0, 'BoundaryIoU-skyscraper': 0.0, 'min(IoU, B-Iou)-skyscraper': 0.0, 'IoU-snow': 72.64481303424323, 'BoundaryIoU-snow': 0.0, 'min(IoU, B-Iou)-snow': 0.0, 'IoU-solid-other': 0.0, 'BoundaryIoU-solid-other': 0.0, 'min(IoU, B-Iou)-solid-other': 0.0, 'IoU-stairs': 2.940566848589245, 'BoundaryIoU-stairs': 0.0, 'min(IoU, B-Iou)-stairs': 0.0, 'IoU-stone': 0.43872109328431075, 'BoundaryIoU-stone': 0.0, 'min(IoU, B-Iou)-stone': 0.0, 'IoU-straw': 0.17773429510799849, 'BoundaryIoU-straw': 0.0, 'min(IoU, B-Iou)-straw': 0.0, 'IoU-structural-other': 0.22305394184757182, 'BoundaryIoU-structural-other': 0.0, 'min(IoU, B-Iou)-structural-other': 0.0, 'IoU-table': 1.4918979887406278, 'BoundaryIoU-table': 0.0, 'min(IoU, B-Iou)-table': 0.0, 'IoU-tent': 3.2468990391797043, 'BoundaryIoU-tent': 0.0, 'min(IoU, B-Iou)-tent': 0.0, 'IoU-textile-other': 2.6314270168704543, 'BoundaryIoU-textile-other': 0.0, 'min(IoU, B-Iou)-textile-other': 0.0, 'IoU-towel': 2.0734873634871076, 'BoundaryIoU-towel': 0.0, 'min(IoU, B-Iou)-towel': 0.0, 'IoU-tree': 63.96108614158585, 'BoundaryIoU-tree': 0.0, 'min(IoU, B-Iou)-tree': 0.0, 'IoU-vegetable': 12.23848924124177, 'BoundaryIoU-vegetable': 0.0, 'min(IoU, B-Iou)-vegetable': 0.0, 'IoU-wall-brick': 23.755818421380095, 'BoundaryIoU-wall-brick': 0.0, 'min(IoU, B-Iou)-wall-brick': 0.0, 'IoU-wall-concrete': 0.3959875969323655, 'BoundaryIoU-wall-concrete': 0.0, 'min(IoU, B-Iou)-wall-concrete': 0.0, 'IoU-wall-other': 9.225656260981614, 'BoundaryIoU-wall-other': 0.0, 'min(IoU, B-Iou)-wall-other': 0.0, 'IoU-wall-panel': 0.0, 'BoundaryIoU-wall-panel': 0.0, 'min(IoU, B-Iou)-wall-panel': 0.0, 'IoU-wall-stone': 16.19217883087729, 'BoundaryIoU-wall-stone': 0.0, 'min(IoU, B-Iou)-wall-stone': 0.0, 'IoU-wall-tile': 28.04324990941319, 'BoundaryIoU-wall-tile': 0.0, 'min(IoU, B-Iou)-wall-tile': 0.0, 'IoU-wall-wood': 10.389397686982695, 'BoundaryIoU-wall-wood': 0.0, 'min(IoU, B-Iou)-wall-wood': 0.0, 'IoU-water-other': 18.29025598600695, 'BoundaryIoU-water-other': 0.0, 'min(IoU, B-Iou)-water-other': 0.0, 'IoU-waterdrops': 0.0, 'BoundaryIoU-waterdrops': 0.0, 'min(IoU, B-Iou)-waterdrops': 0.0, 'IoU-window-blind': 8.222591249961173, 'BoundaryIoU-window-blind': 0.0, 'min(IoU, B-Iou)-window-blind': 0.0, 'IoU-window-other': 23.34653867971524, 'BoundaryIoU-window-other': 0.0, 'min(IoU, B-Iou)-window-other': 0.0, 'IoU-wood': 3.9474986095114217, 'BoundaryIoU-wood': 0.0, 'min(IoU, B-Iou)-wood': 0.0, 'mACC': 36.14988720928885, 'pACC': 52.771640274064566, 'ACC-person': 88.70927217752072, 'ACC-bicycle': 66.3848598834338, 'ACC-car': 67.68260792694095, 'ACC-motorcycle': 84.30522645009923, 'ACC-airplane': 75.6179477405941, 'ACC-bus': 79.16467590038368, 'ACC-train': 75.6892823788523, 'ACC-truck': 49.313113340541726, 'ACC-boat': 69.22765966690058, 'ACC-traffic light': 45.485098767402974, 'ACC-fire hydrant': 75.87436236619574, 'ACC-stop sign': 89.86070548739332, 'ACC-parking meter': 23.271700377521835, 'ACC-bench': 54.31850304031176, 'ACC-bird': 67.12104077542742, 'ACC-cat': 87.38775561720577, 'ACC-dog': 66.98349195503084, 'ACC-horse': 75.60497321285595, 'ACC-sheep': 76.90279025183403, 'ACC-cow': 60.26979291806109, 'ACC-elephant': 87.6581066026834, 'ACC-bear': 69.15600403981611, 'ACC-zebra': 92.91252145599809, 'ACC-giraffe': 84.63534326683497, 'ACC-backpack': 13.534591389254652, 'ACC-umbrella': 64.7091080619544, 'ACC-handbag': 13.0548812250981, 'ACC-tie': 0.0, 'ACC-suitcase': 74.0477558035632, 'ACC-frisbee': 53.394028301922006, 'ACC-skis': 27.855004167138258, 'ACC-snowboard': 18.320517693379724, 'ACC-sports ball': 45.70498306787856, 'ACC-kite': 49.936658664722074, 'ACC-baseball bat': 26.036223373880812, 'ACC-baseball glove': 57.00403647779937, 'ACC-skateboard': 45.81206658670971, 'ACC-surfboard': 61.45660146616577, 'ACC-tennis racket': 33.919557436781005, 'ACC-bottle': 48.924030683863116, 'ACC-wine glass': 36.610369262040535, 'ACC-cup': 42.38190704471942, 'ACC-fork': 23.919125407286803, 'ACC-knife': 7.355723265322728, 'ACC-spoon': 21.076423454150824, 'ACC-bowl': 51.540916425919534, 'ACC-banana': 57.49032046627681, 'ACC-apple': 36.65161796995506, 'ACC-sandwich': 75.35758573490018, 'ACC-orange': 44.15989813376606, 'ACC-broccoli': 50.29242503836415, 'ACC-carrot': 36.072345023184624, 'ACC-hot dog': 29.08713395945003, 'ACC-pizza': 88.15748583505827, 'ACC-donut': 64.98187897403153, 'ACC-cake': 65.19577677847997, 'ACC-chair': 29.5843315056676, 'ACC-couch': 49.6723865803803, 'ACC-potted plant': 32.72072073497688, 'ACC-bed': 62.56255037225581, 'ACC-dining table': 68.11834793458999, 'ACC-toilet': 75.72647135134672, 'ACC-tv': 48.19847923500335, 'ACC-laptop': 68.86039822940006, 'ACC-mouse': 33.274498315511934, 'ACC-remote': 28.490179349187976, 'ACC-keyboard': 40.526554320806305, 'ACC-cell phone': 70.36439549950863, 'ACC-microwave': 15.257903732149114, 'ACC-oven': 48.349973480982904, 'ACC-toaster': 51.18318357709713, 'ACC-sink': 36.97579717058897, 'ACC-refrigerator': 32.233816959735556, 'ACC-book': 41.94553974746806, 'ACC-clock': 78.5577130645554, 'ACC-vase': 59.755229494593024, 'ACC-scissors': 27.16116209927611, 'ACC-teddy bear': 66.58493134764164, 'ACC-hair drier': 0.0, 'ACC-toothbrush': 3.707647964439917, 'ACC-banner': 45.0493301176337, 'ACC-blanket': 0.0, 'ACC-branch': 0.0, 'ACC-bridge': 16.46288969251242, 'ACC-building-other': 75.91559684381821, 'ACC-bush': 27.183523663640397, 'ACC-cabinet': 8.703689746028088, 'ACC-cage': 5.369201282095712, 'ACC-cardboard': 5.5525374436527555, 'ACC-carpet': 36.36412114368168, 'ACC-ceiling-other': 51.047401344248144, 'ACC-ceiling-tile': 0.0, 'ACC-cloth': 0.0, 'ACC-clothes': 0.20110999433470095, 'ACC-clouds': 75.47028092242256, 'ACC-counter': 7.144295589534863, 'ACC-cupboard': 28.78080769649914, 'ACC-curtain': 41.48749927368356, 'ACC-desk-stuff': 39.691324658569734, 'ACC-dirt': 46.065635940522284, 'ACC-door-stuff': 11.190658668414013, 'ACC-fence': 65.44317395373132, 'ACC-floor-marble': 0.0, 'ACC-floor-other': 11.055325264094941, 'ACC-floor-stone': 0.34858029729431916, 'ACC-floor-tile': 39.157254053676745, 'ACC-floor-wood': 54.93046393580235, 'ACC-flower': 43.84759255586491, 'ACC-fog': 0.0, 'ACC-food-other': 13.929007686440606, 'ACC-fruit': 8.379493577650674, 'ACC-furniture-other': 3.3674617401494995, 'ACC-grass': 79.63106214573723, 'ACC-gravel': 19.82088146696316, 'ACC-ground-other': 7.700707168315518, 'ACC-hill': 10.585465013874332, 'ACC-house': 10.254912115192532, 'ACC-leaves': 4.8579173379322205, 'ACC-light': 14.155509512689967, 'ACC-mat': 0.0, 'ACC-metal': 0.22925209145599848, 'ACC-mirror-stuff': 13.715022336216599, 'ACC-moss': 0.0, 'ACC-mountain': 37.04906407987099, 'ACC-mud': 0.0, 'ACC-napkin': 0.0, 'ACC-net': 18.43519497708695, 'ACC-paper': 3.3115968518363554, 'ACC-pavement': 43.76942092166017, 'ACC-pillow': 0.0, 'ACC-plant-other': 28.070624883601013, 'ACC-plastic': 0.0, 'ACC-platform': 11.81870228524495, 'ACC-playingfield': 86.7273986066025, 'ACC-railing': 11.933239322859771, 'ACC-railroad': 57.085239316755434, 'ACC-river': 16.345497403578594, 'ACC-road': 67.96304288316263, 'ACC-rock': 50.99694104054748, 'ACC-roof': 0.15218374506472393, 'ACC-rug': 12.706166184775347, 'ACC-salad': 0.0, 'ACC-sand': 42.182244561193365, 'ACC-sea': 86.16034506022456, 'ACC-shelf': 8.658949922148425, 'ACC-sky-other': 63.78507979750706, 'ACC-skyscraper': 0.0, 'ACC-snow': 86.46776755765254, 'ACC-solid-other': 0.0, 'ACC-stairs': 3.5206144136162942, 'ACC-stone': 0.4630959520870568, 'ACC-straw': 0.1830136664704532, 'ACC-structural-other': 0.7685500220361393, 'ACC-table': 1.5619643928838487, 'ACC-tent': 3.74977520900335, 'ACC-textile-other': 2.723771520823741, 'ACC-towel': 2.1214812728707106, 'ACC-tree': 81.60383265809806, 'ACC-vegetable': 13.146064183170564, 'ACC-wall-brick': 29.09886706947196, 'ACC-wall-concrete': 0.3969913959773123, 'ACC-wall-other': 48.164110433608414, 'ACC-wall-panel': 0.0, 'ACC-wall-stone': 24.196189751613723, 'ACC-wall-tile': 38.94921934546235, 'ACC-wall-wood': 12.039050830328545, 'ACC-water-other': 55.1531358590736, 'ACC-waterdrops': 0.0, 'ACC-window-blind': 8.380813337285286, 'ACC-window-other': 46.80939926909277, 'ACC-wood': 4.503061689649429})])
[12/13 00:32:04 d2.engine.defaults]: Evaluation results for coco_2017_test_stuff_sem_seg in csv format:
[12/13 00:32:04 d2.evaluation.testing]: copypaste: Task: sem_seg
[12/13 00:32:04 d2.evaluation.testing]: copypaste: mIoU,fwIoU,mACC,pACC
[12/13 00:32:04 d2.evaluation.testing]: copypaste: 24.4403,37.6584,36.1499,52.7716
WARNING [12/13 00:32:04 d2.data.datasets.coco]: Directory datasets/VOC2012/JPEGImages and datasets/VOC2012/annotations_detectron2/val has 17125 and 1449 files, respectively.
WARNING [12/13 00:32:04 d2.data.datasets.coco]: Will use their intersection of 1449 files.
[12/13 00:32:04 d2.data.datasets.coco]: Loaded 1449 images with semantic segmentation from datasets/VOC2012/JPEGImages
[12/13 00:32:04 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=2560, sample_style='choice')]
[12/13 00:32:04 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[12/13 00:32:04 d2.data.common]: Serializing 1449 elements to byte tensors and concatenating them all ...
[12/13 00:32:04 d2.data.common]: Serialized dataset takes 0.27 MiB
WARNING [12/13 00:32:04 d2.data.datasets.coco]: Directory datasets/VOC2012/JPEGImages and datasets/VOC2012/annotations_detectron2/val has 17125 and 1449 files, respectively.
WARNING [12/13 00:32:04 d2.data.datasets.coco]: Will use their intersection of 1449 files.
[12/13 00:32:04 d2.data.datasets.coco]: Loaded 1449 images with semantic segmentation from datasets/VOC2012/JPEGImages
[12/13 00:32:04 d2.evaluation.evaluator]: Start inference on 725 batches
[12/13 00:32:08 d2.evaluation.evaluator]: Inference done 11/725. Dataloading: 0.0009 s/iter. Inference: 0.0606 s/iter. Eval: 0.0081 s/iter. Total: 0.0696 s/iter. ETA=0:00:49
[12/13 00:32:14 d2.evaluation.evaluator]: Inference done 78/725. Dataloading: 0.0017 s/iter. Inference: 0.0643 s/iter. Eval: 0.0085 s/iter. Total: 0.0746 s/iter. ETA=0:00:48
[12/13 00:32:19 d2.evaluation.evaluator]: Inference done 148/725. Dataloading: 0.0017 s/iter. Inference: 0.0632 s/iter. Eval: 0.0084 s/iter. Total: 0.0735 s/iter. ETA=0:00:42
[12/13 00:32:24 d2.evaluation.evaluator]: Inference done 217/725. Dataloading: 0.0018 s/iter. Inference: 0.0631 s/iter. Eval: 0.0085 s/iter. Total: 0.0734 s/iter. ETA=0:00:37
[12/13 00:32:29 d2.evaluation.evaluator]: Inference done 287/725. Dataloading: 0.0018 s/iter. Inference: 0.0628 s/iter. Eval: 0.0085 s/iter. Total: 0.0731 s/iter. ETA=0:00:32
[12/13 00:32:34 d2.evaluation.evaluator]: Inference done 356/725. Dataloading: 0.0018 s/iter. Inference: 0.0629 s/iter. Eval: 0.0085 s/iter. Total: 0.0731 s/iter. ETA=0:00:26
[12/13 00:32:39 d2.evaluation.evaluator]: Inference done 425/725. Dataloading: 0.0018 s/iter. Inference: 0.0628 s/iter. Eval: 0.0084 s/iter. Total: 0.0731 s/iter. ETA=0:00:21
[12/13 00:32:44 d2.evaluation.evaluator]: Inference done 494/725. Dataloading: 0.0018 s/iter. Inference: 0.0628 s/iter. Eval: 0.0084 s/iter. Total: 0.0731 s/iter. ETA=0:00:16
[12/13 00:32:56 d2.evaluation.evaluator]: Inference done 500/725. Dataloading: 0.0018 s/iter. Inference: 0.0867 s/iter. Eval: 0.0084 s/iter. Total: 0.0969 s/iter. ETA=0:00:21
[12/13 00:33:01 d2.evaluation.evaluator]: Inference done 570/725. Dataloading: 0.0018 s/iter. Inference: 0.0836 s/iter. Eval: 0.0085 s/iter. Total: 0.0939 s/iter. ETA=0:00:14
[12/13 00:33:06 d2.evaluation.evaluator]: Inference done 635/725. Dataloading: 0.0018 s/iter. Inference: 0.0819 s/iter. Eval: 0.0085 s/iter. Total: 0.0922 s/iter. ETA=0:00:08
[12/13 00:33:11 d2.evaluation.evaluator]: Inference done 694/725. Dataloading: 0.0018 s/iter. Inference: 0.0812 s/iter. Eval: 0.0085 s/iter. Total: 0.0916 s/iter. ETA=0:00:02
[12/13 00:33:15 d2.evaluation.evaluator]: Total inference time: 0:01:06.500037 (0.092361 s / iter per device, on 2 devices)
[12/13 00:33:15 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:58 (0.080944 s / iter per device, on 2 devices)
[12/13 00:33:15 d2.evaluation.sem_seg_evaluation]: OrderedDict([('sem_seg', {'mIoU': 77.10517038349221, 'fwIoU': 77.88903350848254, 'IoU-aeroplane': 93.61515027471341, 'BoundaryIoU-aeroplane': 79.2458448901599, 'min(IoU, B-Iou)-aeroplane': 79.2458448901599, 'IoU-bicycle': 79.2935707074665, 'BoundaryIoU-bicycle': 1.0726347549408424, 'min(IoU, B-Iou)-bicycle': 1.0726347549408424, 'IoU-bird': 84.94035639884429, 'BoundaryIoU-bird': 0.9442320970042122, 'min(IoU, B-Iou)-bird': 0.9442320970042122, 'IoU-boat': 92.3290102437152, 'BoundaryIoU-boat': 1.7106892532520444, 'min(IoU, B-Iou)-boat': 1.7106892532520444, 'IoU-bottle': 68.48817616771719, 'BoundaryIoU-bottle': 2.585807332959286, 'min(IoU, B-Iou)-bottle': 2.585807332959286, 'IoU-bus': 90.2758769939247, 'BoundaryIoU-bus': 4.2228313190612115, 'min(IoU, B-Iou)-bus': 4.2228313190612115, 'IoU-car': 84.1334519164024, 'BoundaryIoU-car': 7.859520049289072, 'min(IoU, B-Iou)-car': 7.859520049289072, 'IoU-cat': 80.2365118089092, 'BoundaryIoU-cat': 6.882467146516618, 'min(IoU, B-Iou)-cat': 6.882467146516618, 'IoU-chair': 39.382566149463756, 'BoundaryIoU-chair': 3.8509563856374283, 'min(IoU, B-Iou)-chair': 3.8509563856374283, 'IoU-cow': 69.9842644799118, 'BoundaryIoU-cow': 2.5976162312773843, 'min(IoU, B-Iou)-cow': 2.5976162312773843, 'IoU-diningtable': 66.07153108847899, 'BoundaryIoU-diningtable': 9.518594013996532, 'min(IoU, B-Iou)-diningtable': 9.518594013996532, 'IoU-dog': 67.8137572172305, 'BoundaryIoU-dog': 2.8243745180024447, 'min(IoU, B-Iou)-dog': 2.8243745180024447, 'IoU-horse': 74.14171309883241, 'BoundaryIoU-horse': 0.0, 'min(IoU, B-Iou)-horse': 0.0, 'IoU-motorbike': 75.3252986137041, 'BoundaryIoU-motorbike': 0.0, 'min(IoU, B-Iou)-motorbike': 0.0, 'IoU-person': 84.3012215337851, 'BoundaryIoU-person': 0.0, 'min(IoU, B-Iou)-person': 0.0, 'IoU-pottedplant': 82.39961739138496, 'BoundaryIoU-pottedplant': 0.0, 'min(IoU, B-Iou)-pottedplant': 0.0, 'IoU-sheep': 76.23797251475843, 'BoundaryIoU-sheep': 0.0, 'min(IoU, B-Iou)-sheep': 0.0, 'IoU-sofa': 52.7444987369803, 'BoundaryIoU-sofa': 0.0, 'min(IoU, B-Iou)-sofa': 0.0, 'IoU-train': 90.34784923897588, 'BoundaryIoU-train': 0.0, 'min(IoU, B-Iou)-train': 0.0, 'IoU-tv': 90.04101309464471, 'BoundaryIoU-tv': 0.0, 'min(IoU, B-Iou)-tv': 0.0, 'mACC': 85.61774875838766, 'pACC': 86.91720112587171, 'ACC-aeroplane': 94.62530921664424, 'ACC-bicycle': 84.6471063694197, 'ACC-bird': 90.39948696143149, 'ACC-boat': 97.20624949486636, 'ACC-bottle': 78.91305807073348, 'ACC-bus': 95.38677526504645, 'ACC-car': 94.74461061697185, 'ACC-cat': 94.58624973365443, 'ACC-chair': 68.71539164116048, 'ACC-cow': 76.60294912708588, 'ACC-diningtable': 76.33032550833406, 'ACC-dog': 81.81983950783302, 'ACC-horse': 77.77059029038163, 'ACC-motorbike': 88.25785332220264, 'ACC-person': 92.57300000161544, 'ACC-pottedplant': 86.38496892015144, 'ACC-sheep': 82.41809184061506, 'ACC-sofa': 61.73650242079077, 'ACC-train': 93.60110538261624, 'ACC-tv': 95.63551147619816})])
[12/13 00:33:15 d2.engine.defaults]: Evaluation results for voc_sem_seg_val in csv format:
[12/13 00:33:15 d2.evaluation.testing]: copypaste: Task: sem_seg
[12/13 00:33:15 d2.evaluation.testing]: copypaste: mIoU,fwIoU,mACC,pACC
[12/13 00:33:15 d2.evaluation.testing]: copypaste: 77.1052,77.8890,85.6177,86.9172
[12/13 00:33:15 d2.data.datasets.coco]: Loaded 5104 images with semantic segmentation from datasets/pcontext-59/val/image
[12/13 00:33:15 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=2560, sample_style='choice')]
[12/13 00:33:15 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[12/13 00:33:15 d2.data.common]: Serializing 5104 elements to byte tensors and concatenating them all ...
[12/13 00:33:15 d2.data.common]: Serialized dataset takes 0.94 MiB
[12/13 00:33:15 d2.data.datasets.coco]: Loaded 5104 images with semantic segmentation from datasets/pcontext-59/val/image
[12/13 00:33:15 d2.evaluation.evaluator]: Start inference on 2552 batches
[12/13 00:33:20 d2.evaluation.evaluator]: Inference done 11/2552. Dataloading: 0.0014 s/iter. Inference: 0.0697 s/iter. Eval: 0.0098 s/iter. Total: 0.0808 s/iter. ETA=0:03:25
[12/13 00:33:25 d2.evaluation.evaluator]: Inference done 78/2552. Dataloading: 0.0018 s/iter. Inference: 0.0647 s/iter. Eval: 0.0092 s/iter. Total: 0.0757 s/iter. ETA=0:03:07
[12/13 00:33:30 d2.evaluation.evaluator]: Inference done 148/2552. Dataloading: 0.0018 s/iter. Inference: 0.0628 s/iter. Eval: 0.0091 s/iter. Total: 0.0737 s/iter. ETA=0:02:57
[12/13 00:33:35 d2.evaluation.evaluator]: Inference done 218/2552. Dataloading: 0.0018 s/iter. Inference: 0.0625 s/iter. Eval: 0.0089 s/iter. Total: 0.0732 s/iter. ETA=0:02:50
[12/13 00:33:40 d2.evaluation.evaluator]: Inference done 287/2552. Dataloading: 0.0018 s/iter. Inference: 0.0623 s/iter. Eval: 0.0089 s/iter. Total: 0.0730 s/iter. ETA=0:02:45
[12/13 00:33:45 d2.evaluation.evaluator]: Inference done 355/2552. Dataloading: 0.0018 s/iter. Inference: 0.0624 s/iter. Eval: 0.0089 s/iter. Total: 0.0732 s/iter. ETA=0:02:40
[12/13 00:33:50 d2.evaluation.evaluator]: Inference done 422/2552. Dataloading: 0.0018 s/iter. Inference: 0.0626 s/iter. Eval: 0.0089 s/iter. Total: 0.0734 s/iter. ETA=0:02:36
[12/13 00:33:55 d2.evaluation.evaluator]: Inference done 490/2552. Dataloading: 0.0018 s/iter. Inference: 0.0626 s/iter. Eval: 0.0090 s/iter. Total: 0.0735 s/iter. ETA=0:02:31
[12/13 00:34:00 d2.evaluation.evaluator]: Inference done 554/2552. Dataloading: 0.0018 s/iter. Inference: 0.0631 s/iter. Eval: 0.0090 s/iter. Total: 0.0740 s/iter. ETA=0:02:27
[12/13 00:34:05 d2.evaluation.evaluator]: Inference done 622/2552. Dataloading: 0.0018 s/iter. Inference: 0.0631 s/iter. Eval: 0.0091 s/iter. Total: 0.0740 s/iter. ETA=0:02:22
[12/13 00:34:10 d2.evaluation.evaluator]: Inference done 691/2552. Dataloading: 0.0018 s/iter. Inference: 0.0629 s/iter. Eval: 0.0091 s/iter. Total: 0.0739 s/iter. ETA=0:02:17
[12/13 00:34:15 d2.evaluation.evaluator]: Inference done 760/2552. Dataloading: 0.0018 s/iter. Inference: 0.0629 s/iter. Eval: 0.0091 s/iter. Total: 0.0738 s/iter. ETA=0:02:12
[12/13 00:34:29 d2.evaluation.evaluator]: Inference done 775/2552. Dataloading: 0.0018 s/iter. Inference: 0.0788 s/iter. Eval: 0.0091 s/iter. Total: 0.0898 s/iter. ETA=0:02:39
[12/13 00:34:34 d2.evaluation.evaluator]: Inference done 844/2552. Dataloading: 0.0018 s/iter. Inference: 0.0774 s/iter. Eval: 0.0091 s/iter. Total: 0.0884 s/iter. ETA=0:02:31
[12/13 00:34:39 d2.evaluation.evaluator]: Inference done 909/2552. Dataloading: 0.0018 s/iter. Inference: 0.0766 s/iter. Eval: 0.0091 s/iter. Total: 0.0876 s/iter. ETA=0:02:23
[12/13 00:34:44 d2.evaluation.evaluator]: Inference done 978/2552. Dataloading: 0.0018 s/iter. Inference: 0.0756 s/iter. Eval: 0.0091 s/iter. Total: 0.0866 s/iter. ETA=0:02:16
[12/13 00:34:49 d2.evaluation.evaluator]: Inference done 1048/2552. Dataloading: 0.0018 s/iter. Inference: 0.0746 s/iter. Eval: 0.0091 s/iter. Total: 0.0856 s/iter. ETA=0:02:08
[12/13 00:34:54 d2.evaluation.evaluator]: Inference done 1115/2552. Dataloading: 0.0018 s/iter. Inference: 0.0740 s/iter. Eval: 0.0091 s/iter. Total: 0.0850 s/iter. ETA=0:02:02
[12/13 00:34:59 d2.evaluation.evaluator]: Inference done 1185/2552. Dataloading: 0.0018 s/iter. Inference: 0.0732 s/iter. Eval: 0.0091 s/iter. Total: 0.0842 s/iter. ETA=0:01:55
[12/13 00:35:04 d2.evaluation.evaluator]: Inference done 1254/2552. Dataloading: 0.0018 s/iter. Inference: 0.0726 s/iter. Eval: 0.0091 s/iter. Total: 0.0836 s/iter. ETA=0:01:48
[12/13 00:35:09 d2.evaluation.evaluator]: Inference done 1324/2552. Dataloading: 0.0018 s/iter. Inference: 0.0720 s/iter. Eval: 0.0091 s/iter. Total: 0.0830 s/iter. ETA=0:01:41
[12/13 00:35:14 d2.evaluation.evaluator]: Inference done 1392/2552. Dataloading: 0.0018 s/iter. Inference: 0.0716 s/iter. Eval: 0.0091 s/iter. Total: 0.0825 s/iter. ETA=0:01:35
[12/13 00:35:19 d2.evaluation.evaluator]: Inference done 1462/2552. Dataloading: 0.0018 s/iter. Inference: 0.0711 s/iter. Eval: 0.0091 s/iter. Total: 0.0820 s/iter. ETA=0:01:29
[12/13 00:35:24 d2.evaluation.evaluator]: Inference done 1531/2552. Dataloading: 0.0018 s/iter. Inference: 0.0707 s/iter. Eval: 0.0090 s/iter. Total: 0.0816 s/iter. ETA=0:01:23
[12/13 00:35:29 d2.evaluation.evaluator]: Inference done 1600/2552. Dataloading: 0.0018 s/iter. Inference: 0.0703 s/iter. Eval: 0.0091 s/iter. Total: 0.0813 s/iter. ETA=0:01:17
[12/13 00:35:34 d2.evaluation.evaluator]: Inference done 1668/2552. Dataloading: 0.0018 s/iter. Inference: 0.0700 s/iter. Eval: 0.0090 s/iter. Total: 0.0810 s/iter. ETA=0:01:11
[12/13 00:35:39 d2.evaluation.evaluator]: Inference done 1730/2552. Dataloading: 0.0018 s/iter. Inference: 0.0700 s/iter. Eval: 0.0091 s/iter. Total: 0.0810 s/iter. ETA=0:01:06
[12/13 00:35:55 d2.evaluation.evaluator]: Inference done 1775/2552. Dataloading: 0.0019 s/iter. Inference: 0.0769 s/iter. Eval: 0.0091 s/iter. Total: 0.0878 s/iter. ETA=0:01:08
[12/13 00:36:00 d2.evaluation.evaluator]: Inference done 1840/2552. Dataloading: 0.0019 s/iter. Inference: 0.0765 s/iter. Eval: 0.0091 s/iter. Total: 0.0875 s/iter. ETA=0:01:02
[12/13 00:36:05 d2.evaluation.evaluator]: Inference done 1909/2552. Dataloading: 0.0019 s/iter. Inference: 0.0760 s/iter. Eval: 0.0091 s/iter. Total: 0.0869 s/iter. ETA=0:00:55
[12/13 00:36:10 d2.evaluation.evaluator]: Inference done 1978/2552. Dataloading: 0.0019 s/iter. Inference: 0.0755 s/iter. Eval: 0.0091 s/iter. Total: 0.0864 s/iter. ETA=0:00:49
[12/13 00:36:15 d2.evaluation.evaluator]: Inference done 2044/2552. Dataloading: 0.0019 s/iter. Inference: 0.0751 s/iter. Eval: 0.0091 s/iter. Total: 0.0861 s/iter. ETA=0:00:43
[12/13 00:36:20 d2.evaluation.evaluator]: Inference done 2111/2552. Dataloading: 0.0019 s/iter. Inference: 0.0747 s/iter. Eval: 0.0091 s/iter. Total: 0.0857 s/iter. ETA=0:00:37
[12/13 00:36:25 d2.evaluation.evaluator]: Inference done 2181/2552. Dataloading: 0.0019 s/iter. Inference: 0.0743 s/iter. Eval: 0.0091 s/iter. Total: 0.0853 s/iter. ETA=0:00:31
[12/13 00:36:30 d2.evaluation.evaluator]: Inference done 2250/2552. Dataloading: 0.0019 s/iter. Inference: 0.0739 s/iter. Eval: 0.0091 s/iter. Total: 0.0849 s/iter. ETA=0:00:25
[12/13 00:36:35 d2.evaluation.evaluator]: Inference done 2318/2552. Dataloading: 0.0019 s/iter. Inference: 0.0736 s/iter. Eval: 0.0091 s/iter. Total: 0.0846 s/iter. ETA=0:00:19
[12/13 00:36:40 d2.evaluation.evaluator]: Inference done 2380/2552. Dataloading: 0.0019 s/iter. Inference: 0.0735 s/iter. Eval: 0.0091 s/iter. Total: 0.0845 s/iter. ETA=0:00:14
[12/13 00:36:45 d2.evaluation.evaluator]: Inference done 2448/2552. Dataloading: 0.0019 s/iter. Inference: 0.0733 s/iter. Eval: 0.0091 s/iter. Total: 0.0842 s/iter. ETA=0:00:08
[12/13 00:36:50 d2.evaluation.evaluator]: Inference done 2514/2552. Dataloading: 0.0019 s/iter. Inference: 0.0730 s/iter. Eval: 0.0091 s/iter. Total: 0.0840 s/iter. ETA=0:00:03
[12/13 00:36:54 d2.evaluation.evaluator]: Total inference time: 0:03:34.295321 (0.084136 s / iter per device, on 2 devices)
[12/13 00:36:54 d2.evaluation.evaluator]: Total inference pure compute time: 0:03:05 (0.072906 s / iter per device, on 2 devices)
[12/13 00:36:54 d2.evaluation.sem_seg_evaluation]: OrderedDict([('sem_seg', {'mIoU': 37.00658829690041, 'fwIoU': 54.15933435222997, 'IoU-aeroplane': 69.36595459960103, 'BoundaryIoU-aeroplane': 82.4081346361949, 'min(IoU, B-Iou)-aeroplane': 69.36595459960103, 'IoU-bag': 11.384466117723333, 'BoundaryIoU-bag': 2.0948773527522984, 'min(IoU, B-Iou)-bag': 2.0948773527522984, 'IoU-bed': 7.6588367577238445, 'BoundaryIoU-bed': 1.5705081750596106, 'min(IoU, B-Iou)-bed': 1.5705081750596106, 'IoU-bedclothes': 17.08085193628864, 'BoundaryIoU-bedclothes': 3.9541494467950895, 'min(IoU, B-Iou)-bedclothes': 3.9541494467950895, 'IoU-bench': 10.491522659549855, 'BoundaryIoU-bench': 2.3661756159995577, 'min(IoU, B-Iou)-bench': 2.3661756159995577, 'IoU-bicycle': 60.18623259897215, 'BoundaryIoU-bicycle': 0.0, 'min(IoU, B-Iou)-bicycle': 0.0, 'IoU-bird': 70.92266218405348, 'BoundaryIoU-bird': 0.0, 'min(IoU, B-Iou)-bird': 0.0, 'IoU-boat': 60.74404412063416, 'BoundaryIoU-boat': 0.0, 'min(IoU, B-Iou)-boat': 0.0, 'IoU-book': 24.688909165443462, 'BoundaryIoU-book': 0.0, 'min(IoU, B-Iou)-book': 0.0, 'IoU-bottle': 52.80110605382158, 'BoundaryIoU-bottle': 0.0, 'min(IoU, B-Iou)-bottle': 0.0, 'IoU-building': 33.938153316120705, 'BoundaryIoU-building': 0.0, 'min(IoU, B-Iou)-building': 0.0, 'IoU-bus': 79.57430768796915, 'BoundaryIoU-bus': 0.0, 'min(IoU, B-Iou)-bus': 0.0, 'IoU-cabinet': 12.617294652941869, 'BoundaryIoU-cabinet': 0.0, 'min(IoU, B-Iou)-cabinet': 0.0, 'IoU-car': 69.30385349666983, 'BoundaryIoU-car': 0.0, 'min(IoU, B-Iou)-car': 0.0, 'IoU-cat': 70.63586819590412, 'BoundaryIoU-cat': 0.0, 'min(IoU, B-Iou)-cat': 0.0, 'IoU-ceiling': 36.16478094954487, 'BoundaryIoU-ceiling': 0.0, 'min(IoU, B-Iou)-ceiling': 0.0, 'IoU-chair': 26.123783552487545, 'BoundaryIoU-chair': 0.0, 'min(IoU, B-Iou)-chair': 0.0, 'IoU-cloth': 0.07112249441813562, 'BoundaryIoU-cloth': 0.0, 'min(IoU, B-Iou)-cloth': 0.0, 'IoU-computer': 0.0, 'BoundaryIoU-computer': 0.0, 'min(IoU, B-Iou)-computer': 0.0, 'IoU-cow': 60.35332846434941, 'BoundaryIoU-cow': 0.0, 'min(IoU, B-Iou)-cow': 0.0, 'IoU-cup': 13.169799516011652, 'BoundaryIoU-cup': 0.0, 'min(IoU, B-Iou)-cup': 0.0, 'IoU-curtain': 23.14434301093381, 'BoundaryIoU-curtain': 0.0, 'min(IoU, B-Iou)-curtain': 0.0, 'IoU-dog': 64.35805164182878, 'BoundaryIoU-dog': 0.0, 'min(IoU, B-Iou)-dog': 0.0, 'IoU-door': 6.760289637915095, 'BoundaryIoU-door': 0.0, 'min(IoU, B-Iou)-door': 0.0, 'IoU-fence': 23.373293597328384, 'BoundaryIoU-fence': 0.0, 'min(IoU, B-Iou)-fence': 0.0, 'IoU-floor': 44.26604228722697, 'BoundaryIoU-floor': 0.0, 'min(IoU, B-Iou)-floor': 0.0, 'IoU-flower': 17.163968981431598, 'BoundaryIoU-flower': 0.0, 'min(IoU, B-Iou)-flower': 0.0, 'IoU-food': 22.70313815958109, 'BoundaryIoU-food': 0.0, 'min(IoU, B-Iou)-food': 0.0, 'IoU-grass': 71.06568819653192, 'BoundaryIoU-grass': 0.0, 'min(IoU, B-Iou)-grass': 0.0, 'IoU-ground': 14.196404392516223, 'BoundaryIoU-ground': 0.0, 'min(IoU, B-Iou)-ground': 0.0, 'IoU-horse': 63.93999057538916, 'BoundaryIoU-horse': 0.0, 'min(IoU, B-Iou)-horse': 0.0, 'IoU-keyboard': 29.249336353634853, 'BoundaryIoU-keyboard': 0.0, 'min(IoU, B-Iou)-keyboard': 0.0, 'IoU-light': 18.97555050586072, 'BoundaryIoU-light': 0.0, 'min(IoU, B-Iou)-light': 0.0, 'IoU-motorbike': 67.13955134119229, 'BoundaryIoU-motorbike': 0.0, 'min(IoU, B-Iou)-motorbike': 0.0, 'IoU-mountain': 31.150813317827296, 'BoundaryIoU-mountain': 0.0, 'min(IoU, B-Iou)-mountain': 0.0, 'IoU-mouse': 4.609902531778234, 'BoundaryIoU-mouse': 0.0, 'min(IoU, B-Iou)-mouse': 0.0, 'IoU-person': 75.88176582088332, 'BoundaryIoU-person': 0.0, 'min(IoU, B-Iou)-person': 0.0, 'IoU-plate': 3.9945431046862288, 'BoundaryIoU-plate': 0.0, 'min(IoU, B-Iou)-plate': 0.0, 'IoU-platform': 18.68408968129715, 'BoundaryIoU-platform': 0.0, 'min(IoU, B-Iou)-platform': 0.0, 'IoU-pottedplant': 51.58378215942746, 'BoundaryIoU-pottedplant': 0.0, 'min(IoU, B-Iou)-pottedplant': 0.0, 'IoU-road': 38.78548295497601, 'BoundaryIoU-road': 0.0, 'min(IoU, B-Iou)-road': 0.0, 'IoU-rock': 26.685211228139178, 'BoundaryIoU-rock': 0.0, 'min(IoU, B-Iou)-rock': 0.0, 'IoU-sheep': 64.67393723497683, 'BoundaryIoU-sheep': 0.0, 'min(IoU, B-Iou)-sheep': 0.0, 'IoU-shelves': 8.186693770088322, 'BoundaryIoU-shelves': 0.0, 'min(IoU, B-Iou)-shelves': 0.0, 'IoU-sidewalk': 7.53252485511965, 'BoundaryIoU-sidewalk': 0.0, 'min(IoU, B-Iou)-sidewalk': 0.0, 'IoU-sign': 31.73562522335356, 'BoundaryIoU-sign': 0.0, 'min(IoU, B-Iou)-sign': 0.0, 'IoU-sky': 86.84188501579894, 'BoundaryIoU-sky': 0.0, 'min(IoU, B-Iou)-sky': 0.0, 'IoU-snow': 44.64032140502018, 'BoundaryIoU-snow': 0.0, 'min(IoU, B-Iou)-snow': 0.0, 'IoU-sofa': 28.876756575250983, 'BoundaryIoU-sofa': 0.0, 'min(IoU, B-Iou)-sofa': 0.0, 'IoU-diningtable': 36.81343938045087, 'BoundaryIoU-diningtable': 0.0, 'min(IoU, B-Iou)-diningtable': 0.0, 'IoU-track': 29.05203083222266, 'BoundaryIoU-track': 0.0, 'min(IoU, B-Iou)-track': 0.0, 'IoU-train': 64.23246387890823, 'BoundaryIoU-train': 0.0, 'min(IoU, B-Iou)-train': 0.0, 'IoU-tree': 68.47533181927886, 'BoundaryIoU-tree': 0.0, 'min(IoU, B-Iou)-tree': 0.0, 'IoU-truck': 7.251771158824368, 'BoundaryIoU-truck': 0.0, 'min(IoU, B-Iou)-truck': 0.0, 'IoU-tvmonitor': 50.010242275429526, 'BoundaryIoU-tvmonitor': 0.0, 'min(IoU, B-Iou)-tvmonitor': 0.0, 'IoU-wall': 51.69214144015051, 'BoundaryIoU-wall': 0.0, 'min(IoU, B-Iou)-wall': 0.0, 'IoU-water': 68.63389211090065, 'BoundaryIoU-water': 0.0, 'min(IoU, B-Iou)-water': 0.0, 'IoU-window': 19.68973673899225, 'BoundaryIoU-window': 0.0, 'min(IoU, B-Iou)-window': 0.0, 'IoU-wood': 10.061797801743351, 'BoundaryIoU-wood': 0.0, 'min(IoU, B-Iou)-wood': 0.0, 'mACC': 52.38308558349476, 'pACC': 67.27504376172297, 'ACC-aeroplane': 81.0365253348524, 'ACC-bag': 16.330010123541896, 'ACC-bed': 47.0263129229046, 'ACC-bedclothes': 23.42242950416479, 'ACC-bench': 34.425155041171465, 'ACC-bicycle': 74.71365738207109, 'ACC-bird': 83.9528917689411, 'ACC-boat': 81.48151014334334, 'ACC-book': 36.136299851932144, 'ACC-bottle': 70.05280426022176, 'ACC-building': 37.31581877702991, 'ACC-bus': 91.46856707377762, 'ACC-cabinet': 14.898606920733076, 'ACC-car': 81.7748349895912, 'ACC-cat': 92.69095040228007, 'ACC-ceiling': 50.953507435448756, 'ACC-chair': 55.87817018969926, 'ACC-cloth': 0.07139633219663513, 'ACC-computer': 0.0, 'ACC-cow': 75.61347057950796, 'ACC-cup': 36.440776786114725, 'ACC-curtain': 48.24513581524568, 'ACC-dog': 77.74161733789033, 'ACC-door': 20.754021688919597, 'ACC-fence': 55.03713167224392, 'ACC-floor': 51.83294922385381, 'ACC-flower': 30.2422953924963, 'ACC-food': 27.597917236647255, 'ACC-grass': 86.46061883131819, 'ACC-ground': 14.740972839583478, 'ACC-horse': 72.30023474308724, 'ACC-keyboard': 33.8007192161869, 'ACC-light': 32.72093320174043, 'ACC-motorbike': 89.68275690179239, 'ACC-mountain': 38.08302530445629, 'ACC-mouse': 7.691731201598801, 'ACC-person': 90.26085396462094, 'ACC-plate': 4.287092646730659, 'ACC-platform': 27.21823877874358, 'ACC-pottedplant': 66.37171299220171, 'ACC-road': 62.86622248393745, 'ACC-rock': 59.48088886243224, 'ACC-sheep': 72.31619298607959, 'ACC-shelves': 11.6306653482171, 'ACC-sidewalk': 78.22686268372178, 'ACC-sign': 36.59659358562646, 'ACC-sky': 92.78785716783572, 'ACC-snow': 73.70797207821916, 'ACC-sofa': 34.205101982686834, 'ACC-diningtable': 66.7479455952614, 'ACC-track': 57.00841015751571, 'ACC-train': 84.92974455212887, 'ACC-tree': 82.60787001725292, 'ACC-truck': 39.58686087765875, 'ACC-tvmonitor': 81.2091339406313, 'ACC-wall': 70.70857516525929, 'ACC-water': 78.74448692836663, 'ACC-window': 31.960994083443843, 'ACC-wood': 14.526016121034052})])
[12/13 00:36:54 d2.engine.defaults]: Evaluation results for pcontext_sem_seg_val in csv format:
[12/13 00:36:54 d2.evaluation.testing]: copypaste: Task: sem_seg
[12/13 00:36:54 d2.evaluation.testing]: copypaste: mIoU,fwIoU,mACC,pACC
[12/13 00:36:54 d2.evaluation.testing]: copypaste: 37.0066,54.1593,52.3831,67.2750
[12/13 00:36:55 d2.data.datasets.coco]: Loaded 5104 images with semantic segmentation from datasets/pcontext-full/val/image
[12/13 00:36:55 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=2560, sample_style='choice')]
[12/13 00:36:55 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[12/13 00:36:55 d2.data.common]: Serializing 5104 elements to byte tensors and concatenating them all ...
[12/13 00:36:55 d2.data.common]: Serialized dataset takes 0.99 MiB
[12/13 00:36:55 d2.data.datasets.coco]: Loaded 5104 images with semantic segmentation from datasets/pcontext-full/val/image
WARNING [12/13 00:36:55 d2.evaluation.sem_seg_evaluation]: SemSegEvaluator(num_classes) is more than supported value for Boundary IoU calculation!
                B-IoU metrics are not going to be computed. Max allowed value (exclusive)
                for num_classes for calculating Boundary IoU is 255.
                The number of classes of dataset pcontext_full_sem_seg_val is 459
[12/13 00:36:55 d2.evaluation.evaluator]: Start inference on 2552 batches
[12/13 00:37:03 d2.evaluation.evaluator]: Inference done 11/2552. Dataloading: 0.0013 s/iter. Inference: 0.0617 s/iter. Eval: 0.0090 s/iter. Total: 0.0719 s/iter. ETA=0:03:02
[12/13 00:37:08 d2.evaluation.evaluator]: Inference done 77/2552. Dataloading: 0.0019 s/iter. Inference: 0.0653 s/iter. Eval: 0.0091 s/iter. Total: 0.0763 s/iter. ETA=0:03:08
[12/13 00:37:13 d2.evaluation.evaluator]: Inference done 144/2552. Dataloading: 0.0018 s/iter. Inference: 0.0646 s/iter. Eval: 0.0091 s/iter. Total: 0.0756 s/iter. ETA=0:03:01
[12/13 00:37:18 d2.evaluation.evaluator]: Inference done 211/2552. Dataloading: 0.0018 s/iter. Inference: 0.0646 s/iter. Eval: 0.0088 s/iter. Total: 0.0753 s/iter. ETA=0:02:56
[12/13 00:37:30 d2.evaluation.evaluator]: Inference done 223/2552. Dataloading: 0.0018 s/iter. Inference: 0.1171 s/iter. Eval: 0.0087 s/iter. Total: 0.1277 s/iter. ETA=0:04:57
[12/13 00:37:35 d2.evaluation.evaluator]: Inference done 282/2552. Dataloading: 0.0019 s/iter. Inference: 0.1079 s/iter. Eval: 0.0089 s/iter. Total: 0.1187 s/iter. ETA=0:04:29
[12/13 00:37:40 d2.evaluation.evaluator]: Inference done 344/2552. Dataloading: 0.0019 s/iter. Inference: 0.1010 s/iter. Eval: 0.0088 s/iter. Total: 0.1118 s/iter. ETA=0:04:06
[12/13 00:37:45 d2.evaluation.evaluator]: Inference done 411/2552. Dataloading: 0.0019 s/iter. Inference: 0.0950 s/iter. Eval: 0.0088 s/iter. Total: 0.1057 s/iter. ETA=0:03:46
[12/13 00:37:50 d2.evaluation.evaluator]: Inference done 479/2552. Dataloading: 0.0019 s/iter. Inference: 0.0905 s/iter. Eval: 0.0088 s/iter. Total: 0.1011 s/iter. ETA=0:03:29
[12/13 00:37:55 d2.evaluation.evaluator]: Inference done 548/2552. Dataloading: 0.0019 s/iter. Inference: 0.0870 s/iter. Eval: 0.0087 s/iter. Total: 0.0976 s/iter. ETA=0:03:15
[12/13 00:38:00 d2.evaluation.evaluator]: Inference done 616/2552. Dataloading: 0.0019 s/iter. Inference: 0.0843 s/iter. Eval: 0.0087 s/iter. Total: 0.0949 s/iter. ETA=0:03:03
[12/13 00:38:05 d2.evaluation.evaluator]: Inference done 683/2552. Dataloading: 0.0018 s/iter. Inference: 0.0824 s/iter. Eval: 0.0087 s/iter. Total: 0.0929 s/iter. ETA=0:02:53
[12/13 00:38:10 d2.evaluation.evaluator]: Inference done 751/2552. Dataloading: 0.0018 s/iter. Inference: 0.0807 s/iter. Eval: 0.0087 s/iter. Total: 0.0913 s/iter. ETA=0:02:44
[12/13 00:38:16 d2.evaluation.evaluator]: Inference done 818/2552. Dataloading: 0.0018 s/iter. Inference: 0.0793 s/iter. Eval: 0.0087 s/iter. Total: 0.0899 s/iter. ETA=0:02:35
[12/13 00:38:21 d2.evaluation.evaluator]: Inference done 884/2552. Dataloading: 0.0018 s/iter. Inference: 0.0783 s/iter. Eval: 0.0087 s/iter. Total: 0.0889 s/iter. ETA=0:02:28
[12/13 00:38:26 d2.evaluation.evaluator]: Inference done 951/2552. Dataloading: 0.0019 s/iter. Inference: 0.0773 s/iter. Eval: 0.0087 s/iter. Total: 0.0879 s/iter. ETA=0:02:20
[12/13 00:38:31 d2.evaluation.evaluator]: Inference done 1020/2552. Dataloading: 0.0018 s/iter. Inference: 0.0764 s/iter. Eval: 0.0087 s/iter. Total: 0.0869 s/iter. ETA=0:02:13
[12/13 00:38:36 d2.evaluation.evaluator]: Inference done 1087/2552. Dataloading: 0.0018 s/iter. Inference: 0.0756 s/iter. Eval: 0.0087 s/iter. Total: 0.0862 s/iter. ETA=0:02:06
[12/13 00:38:41 d2.evaluation.evaluator]: Inference done 1155/2552. Dataloading: 0.0018 s/iter. Inference: 0.0750 s/iter. Eval: 0.0087 s/iter. Total: 0.0855 s/iter. ETA=0:01:59
[12/13 00:38:58 d2.evaluation.evaluator]: Inference done 1223/2552. Dataloading: 0.0018 s/iter. Inference: 0.0843 s/iter. Eval: 0.0087 s/iter. Total: 0.0949 s/iter. ETA=0:02:06
[12/13 00:39:03 d2.evaluation.evaluator]: Inference done 1290/2552. Dataloading: 0.0019 s/iter. Inference: 0.0833 s/iter. Eval: 0.0087 s/iter. Total: 0.0938 s/iter. ETA=0:01:58
[12/13 00:39:08 d2.evaluation.evaluator]: Inference done 1356/2552. Dataloading: 0.0019 s/iter. Inference: 0.0824 s/iter. Eval: 0.0087 s/iter. Total: 0.0930 s/iter. ETA=0:01:51
[12/13 00:39:13 d2.evaluation.evaluator]: Inference done 1424/2552. Dataloading: 0.0019 s/iter. Inference: 0.0815 s/iter. Eval: 0.0087 s/iter. Total: 0.0921 s/iter. ETA=0:01:43
[12/13 00:39:18 d2.evaluation.evaluator]: Inference done 1489/2552. Dataloading: 0.0019 s/iter. Inference: 0.0808 s/iter. Eval: 0.0087 s/iter. Total: 0.0914 s/iter. ETA=0:01:37
[12/13 00:39:23 d2.evaluation.evaluator]: Inference done 1556/2552. Dataloading: 0.0019 s/iter. Inference: 0.0801 s/iter. Eval: 0.0087 s/iter. Total: 0.0907 s/iter. ETA=0:01:30
[12/13 00:39:28 d2.evaluation.evaluator]: Inference done 1624/2552. Dataloading: 0.0019 s/iter. Inference: 0.0794 s/iter. Eval: 0.0087 s/iter. Total: 0.0900 s/iter. ETA=0:01:23
[12/13 00:39:33 d2.evaluation.evaluator]: Inference done 1691/2552. Dataloading: 0.0019 s/iter. Inference: 0.0788 s/iter. Eval: 0.0087 s/iter. Total: 0.0894 s/iter. ETA=0:01:16
[12/13 00:39:38 d2.evaluation.evaluator]: Inference done 1758/2552. Dataloading: 0.0019 s/iter. Inference: 0.0783 s/iter. Eval: 0.0087 s/iter. Total: 0.0889 s/iter. ETA=0:01:10
[12/13 00:39:43 d2.evaluation.evaluator]: Inference done 1825/2552. Dataloading: 0.0019 s/iter. Inference: 0.0778 s/iter. Eval: 0.0087 s/iter. Total: 0.0883 s/iter. ETA=0:01:04
[12/13 00:39:48 d2.evaluation.evaluator]: Inference done 1892/2552. Dataloading: 0.0019 s/iter. Inference: 0.0773 s/iter. Eval: 0.0087 s/iter. Total: 0.0879 s/iter. ETA=0:00:57
[12/13 00:39:53 d2.evaluation.evaluator]: Inference done 1960/2552. Dataloading: 0.0019 s/iter. Inference: 0.0768 s/iter. Eval: 0.0087 s/iter. Total: 0.0874 s/iter. ETA=0:00:51
[12/13 00:39:58 d2.evaluation.evaluator]: Inference done 2028/2552. Dataloading: 0.0019 s/iter. Inference: 0.0764 s/iter. Eval: 0.0087 s/iter. Total: 0.0870 s/iter. ETA=0:00:45
[12/13 00:40:03 d2.evaluation.evaluator]: Inference done 2094/2552. Dataloading: 0.0019 s/iter. Inference: 0.0760 s/iter. Eval: 0.0087 s/iter. Total: 0.0866 s/iter. ETA=0:00:39
[12/13 00:40:08 d2.evaluation.evaluator]: Inference done 2159/2552. Dataloading: 0.0019 s/iter. Inference: 0.0758 s/iter. Eval: 0.0087 s/iter. Total: 0.0864 s/iter. ETA=0:00:33
[12/13 00:40:25 d2.evaluation.evaluator]: Inference done 2223/2552. Dataloading: 0.0019 s/iter. Inference: 0.0807 s/iter. Eval: 0.0087 s/iter. Total: 0.0913 s/iter. ETA=0:00:30
[12/13 00:40:30 d2.evaluation.evaluator]: Inference done 2290/2552. Dataloading: 0.0019 s/iter. Inference: 0.0802 s/iter. Eval: 0.0087 s/iter. Total: 0.0908 s/iter. ETA=0:00:23
[12/13 00:40:35 d2.evaluation.evaluator]: Inference done 2356/2552. Dataloading: 0.0019 s/iter. Inference: 0.0798 s/iter. Eval: 0.0087 s/iter. Total: 0.0904 s/iter. ETA=0:00:17
[12/13 00:40:40 d2.evaluation.evaluator]: Inference done 2424/2552. Dataloading: 0.0019 s/iter. Inference: 0.0793 s/iter. Eval: 0.0087 s/iter. Total: 0.0899 s/iter. ETA=0:00:11
[12/13 00:40:45 d2.evaluation.evaluator]: Inference done 2490/2552. Dataloading: 0.0019 s/iter. Inference: 0.0790 s/iter. Eval: 0.0086 s/iter. Total: 0.0896 s/iter. ETA=0:00:05
[12/13 00:40:50 d2.evaluation.evaluator]: Total inference time: 0:03:47.959681 (0.089501 s / iter per device, on 2 devices)
[12/13 00:40:50 d2.evaluation.evaluator]: Total inference pure compute time: 0:03:20 (0.078695 s / iter per device, on 2 devices)
[12/13 00:40:51 d2.evaluation.sem_seg_evaluation]: OrderedDict([('sem_seg', {'mIoU': 7.047368644133906, 'fwIoU': 44.05544371774778, 'IoU-accordion': nan, 'IoU-aeroplane': 62.27451356138306, 'IoU-air conditioner': 0.0, 'IoU-antenna': 0.0, 'IoU-artillery': 0.0, 'IoU-ashtray': 0.0, 'IoU-atrium': nan, 'IoU-baby carriage': 5.873839068744367, 'IoU-bag': 6.996392970735088, 'IoU-ball': 22.5731484303566, 'IoU-balloon': 8.648935464614976, 'IoU-bamboo weaving': 0.0, 'IoU-barrel': 0.0, 'IoU-baseball bat': nan, 'IoU-basket': 1.1932176060063995, 'IoU-basketball backboard': 0.0, 'IoU-bathtub': 6.635853787032437, 'IoU-bed': 5.8053919522528865, 'IoU-bedclothes': 13.168918931059329, 'IoU-beer': 0.1777961338155151, 'IoU-bell': 0.0, 'IoU-bench': 11.631017130766205, 'IoU-bicycle': 44.64034527551782, 'IoU-binoculars': nan, 'IoU-bird': 65.11651306260367, 'IoU-bird cage': 25.56129762975387, 'IoU-bird feeder': 6.123803356053271, 'IoU-bird nest': 0.0, 'IoU-blackboard': 0.0, 'IoU-board': 0.0, 'IoU-boat': 54.83163622661937, 'IoU-bone': 0.0, 'IoU-book': 17.178377924314333, 'IoU-bottle': 37.00696784365583, 'IoU-bottle opener': 0.0, 'IoU-bowl': 6.888697382938984, 'IoU-box': 4.234945291226636, 'IoU-bracelet': nan, 'IoU-brick': 0.005566758545075214, 'IoU-bridge': 2.2820774774277273, 'IoU-broom': 0.0, 'IoU-brush': 0.0, 'IoU-bucket': 5.44379831375278, 'IoU-building': 26.582563350157358, 'IoU-bus': 74.06562848317655, 'IoU-cabinet': 3.4211562691925366, 'IoU-cabinet door': nan, 'IoU-cage': 16.011133491620193, 'IoU-cake': 5.1593534129289615, 'IoU-calculator': 0.0, 'IoU-calendar': 0.0, 'IoU-camel': nan, 'IoU-camera': 0.0, 'IoU-camera lens': nan, 'IoU-can': 0.0, 'IoU-candle': 1.6884466291012268, 'IoU-candle holder': 0.0, 'IoU-cap': 0.0, 'IoU-car': 63.05894705661994, 'IoU-card': 0.0, 'IoU-cart': 0.0, 'IoU-case': 0.0, 'IoU-casette recorder': 0.0, 'IoU-cash register': 0.0, 'IoU-cat': 66.30169052473974, 'IoU-cd': 0.0, 'IoU-cd player': 0.0, 'IoU-ceiling': 31.760065814347872, 'IoU-cell phone': 4.517749497655727, 'IoU-cello': 48.64343770204119, 'IoU-chain': 0.0, 'IoU-chair': 21.538820479087494, 'IoU-chessboard': nan, 'IoU-chicken': nan, 'IoU-chopstick': 0.732486558092418, 'IoU-clip': 0.0, 'IoU-clippers': 0.0, 'IoU-clock': 1.5753144616272636, 'IoU-closet': nan, 'IoU-cloth': 0.0, 'IoU-clothes tree': nan, 'IoU-coffee': 0.0, 'IoU-coffee machine': nan, 'IoU-comb': 0.0, 'IoU-computer': 0.0, 'IoU-concrete': 0.031486146095717885, 'IoU-cone': 0.0, 'IoU-container': 0.0, 'IoU-control booth': nan, 'IoU-controller': 0.0, 'IoU-cooker': nan, 'IoU-copying machine': nan, 'IoU-coral': nan, 'IoU-cork': nan, 'IoU-corkscrew': nan, 'IoU-counter': 0.0, 'IoU-court': nan, 'IoU-cow': 58.92470973629973, 'IoU-crabstick': nan, 'IoU-crane': 0.0, 'IoU-crate': 0.0, 'IoU-cross': 0.0, 'IoU-crutch': 0.0, 'IoU-cup': 17.846130090079047, 'IoU-curtain': 21.97251155572497, 'IoU-cushion': 1.6916825242934868, 'IoU-cutting board': 0.29607420920285, 'IoU-dais': 0.0, 'IoU-disc': 0.0, 'IoU-disc case': 0.0, 'IoU-dishwasher': nan, 'IoU-dock': nan, 'IoU-dog': 62.21155318241567, 'IoU-dolphin': nan, 'IoU-door': 4.549233453253181, 'IoU-drainer': nan, 'IoU-dray': nan, 'IoU-drink dispenser': nan, 'IoU-drinking machine': 0.0, 'IoU-drop': nan, 'IoU-drug': 0.0, 'IoU-drum': 0.03241142953582614, 'IoU-drum kit': 0.0, 'IoU-duck': 0.0, 'IoU-dumbbell': nan, 'IoU-earphone': 0.0, 'IoU-earrings': nan, 'IoU-egg': 0.0, 'IoU-electric fan': 0.0, 'IoU-electric iron': 0.0, 'IoU-electric pot': 0.0, 'IoU-electric saw': nan, 'IoU-electronic keyboard': nan, 'IoU-engine': 0.0, 'IoU-envelope': nan, 'IoU-equipment': 0.0, 'IoU-escalator': nan, 'IoU-exhibition booth': 0.0, 'IoU-extinguisher': 0.0, 'IoU-eyeglass': 0.0, 'IoU-fan': 0.0, 'IoU-faucet': 0.0, 'IoU-fax machine': nan, 'IoU-fence': 21.86632470136938, 'IoU-ferris wheel': 1.3906282761082809, 'IoU-fire extinguisher': nan, 'IoU-fire hydrant': nan, 'IoU-fire place': 14.828388009907496, 'IoU-fish': 0.0, 'IoU-fish tank': 0.0, 'IoU-fishbowl': 0.0, 'IoU-fishing net': 0.0, 'IoU-fishing pole': 0.0, 'IoU-flag': 37.67071629499776, 'IoU-flagstaff': 0.0, 'IoU-flame': nan, 'IoU-flashlight': 0.0, 'IoU-floor': 33.499817311378685, 'IoU-flower': 19.143844675052314, 'IoU-fly': 0.0, 'IoU-foam': nan, 'IoU-food': 15.54627347096126, 'IoU-footbridge': nan, 'IoU-forceps': nan, 'IoU-fork': 7.649918046685129, 'IoU-forklift': nan, 'IoU-fountain': 0.0, 'IoU-fox': nan, 'IoU-frame': 0.0, 'IoU-fridge': 9.298469299847687, 'IoU-frog': nan, 'IoU-fruit': 0.0, 'IoU-funnel': nan, 'IoU-furnace': 0.0, 'IoU-game controller': 0.0, 'IoU-game machine': 0.0, 'IoU-gas cylinder': nan, 'IoU-gas hood': nan, 'IoU-gas stove': nan, 'IoU-gift box': 17.9535345157067, 'IoU-glass': 0.0, 'IoU-glass marble': 0.0, 'IoU-globe': nan, 'IoU-glove': 0.0, 'IoU-goal': 0.0, 'IoU-grandstand': 3.3216226150466737, 'IoU-grass': 69.62634343154737, 'IoU-gravestone': nan, 'IoU-ground': 5.967216859819683, 'IoU-guardrail': 2.881327051028536, 'IoU-guitar': 18.98173768677366, 'IoU-gun': 0.0, 'IoU-hammer': 0.0, 'IoU-hand cart': 0.0, 'IoU-handle': 0.0, 'IoU-handrail': 0.0, 'IoU-hanger': 0.0, 'IoU-hard disk drive': nan, 'IoU-hat': 18.161289406687427, 'IoU-hay': 0.0, 'IoU-headphone': 0.0, 'IoU-heater': 0.0, 'IoU-helicopter': 0.0, 'IoU-helmet': 2.604044054037956, 'IoU-holder': 0.0, 'IoU-hook': nan, 'IoU-horse': 42.30735851513813, 'IoU-horse-drawn carriage': 7.9590275927851435, 'IoU-hot-air balloon': nan, 'IoU-hydrovalve': nan, 'IoU-ice': 0.0, 'IoU-inflator pump': nan, 'IoU-ipod': 0.0, 'IoU-iron': 0.0, 'IoU-ironing board': nan, 'IoU-jar': 0.0, 'IoU-kart': nan, 'IoU-kettle': 0.0, 'IoU-key': 0.0, 'IoU-keyboard': 19.359110169491526, 'IoU-kitchen range': 0.21050663773900863, 'IoU-kite': nan, 'IoU-knife': 0.0, 'IoU-knife block': 0.0, 'IoU-ladder': 0.0, 'IoU-ladder truck': 0.0, 'IoU-ladle': nan, 'IoU-laptop': 8.038163012059556, 'IoU-leaves': nan, 'IoU-lid': 0.0, 'IoU-life buoy': 11.5532241555783, 'IoU-light': 11.26767130952838, 'IoU-light bulb': 0.0, 'IoU-lighter': nan, 'IoU-line': 0.0, 'IoU-lion': nan, 'IoU-lobster': nan, 'IoU-lock': 0.0, 'IoU-machine': nan, 'IoU-mailbox': 0.0, 'IoU-mannequin': nan, 'IoU-map': 0.0, 'IoU-mask': nan, 'IoU-mat': 0.0, 'IoU-match book': 0.0, 'IoU-mattress': 0.0, 'IoU-menu': 0.0, 'IoU-metal': 0.0, 'IoU-meter box': nan, 'IoU-microphone': 7.9195406449749015, 'IoU-microwave': 11.16056271496686, 'IoU-mirror': 0.5249732133650739, 'IoU-missile': nan, 'IoU-model': 0.0, 'IoU-money': 0.0, 'IoU-monkey': 0.0, 'IoU-mop': 0.0, 'IoU-motorbike': 61.953319201043776, 'IoU-mountain': 30.322191756591927, 'IoU-mouse': 2.8144210543480033, 'IoU-mouse pad': 0.0, 'IoU-musical instrument': 0.0, 'IoU-napkin': 10.443375786080432, 'IoU-net': 0.0, 'IoU-newspaper': 0.0, 'IoU-oar': 4.649478563151796, 'IoU-ornament': 0.0, 'IoU-outlet': 0.0, 'IoU-oven': 23.209570826123997, 'IoU-oxygen bottle': 0.0, 'IoU-pack': 0.0, 'IoU-pan': 0.0, 'IoU-paper': 13.008151579120558, 'IoU-paper box': 0.0, 'IoU-paper cutter': 0.0, 'IoU-parachute': 0.0, 'IoU-parasol': 2.3516050637736865, 'IoU-parterre': 0.0, 'IoU-patio': 0.0, 'IoU-pelage': nan, 'IoU-pen': 0.0, 'IoU-pen container': 0.0, 'IoU-pencil': 0.0, 'IoU-person': 72.5841153532716, 'IoU-photo': nan, 'IoU-piano': 0.0, 'IoU-picture': 4.586376323913073, 'IoU-pig': nan, 'IoU-pillar': 0.0, 'IoU-pillow': 0.0, 'IoU-pipe': 0.0, 'IoU-pitcher': 0.0, 'IoU-plant': 12.097981054390587, 'IoU-plastic': 0.0, 'IoU-plate': 0.0, 'IoU-platform': 15.881889869418092, 'IoU-player': 0.0, 'IoU-playground': 7.031002847200253, 'IoU-pliers': 0.0, 'IoU-plume': 0.0, 'IoU-poker': 0.0, 'IoU-poker chip': 0.0, 'IoU-pole': 2.545551256327893, 'IoU-pool table': nan, 'IoU-postcard': 0.0, 'IoU-poster': 11.19986418452979, 'IoU-pot': 1.2862954070006882, 'IoU-pottedplant': 25.40991902515079, 'IoU-printer': 0.0, 'IoU-projector': nan, 'IoU-pumpkin': 9.515994874446418, 'IoU-rabbit': nan, 'IoU-racket': 0.0, 'IoU-radiator': 0.0, 'IoU-radio': 0.0, 'IoU-rail': 0.0, 'IoU-rake': nan, 'IoU-ramp': 2.8181072805055583, 'IoU-range hood': 0.0, 'IoU-receiver': 0.0, 'IoU-recorder': nan, 'IoU-recreational machines': nan, 'IoU-remote control': 0.0, 'IoU-road': 37.72223104910322, 'IoU-robot': nan, 'IoU-rock': 24.53763983049384, 'IoU-rocket': nan, 'IoU-rocking horse': 0.0, 'IoU-rope': 0.0, 'IoU-rug': 10.701448240635427, 'IoU-ruler': nan, 'IoU-runway': 0.4206391846841285, 'IoU-saddle': 0.0, 'IoU-sand': 10.213916861992251, 'IoU-saw': 0.0, 'IoU-scale': 0.0, 'IoU-scanner': 0.0, 'IoU-scissors': 0.0, 'IoU-scoop': 0.0, 'IoU-screen': nan, 'IoU-screwdriver': nan, 'IoU-sculpture': 0.0, 'IoU-scythe': nan, 'IoU-sewer': 0.0, 'IoU-sewing machine': 0.0, 'IoU-shed': 0.0, 'IoU-sheep': 63.30916096877645, 'IoU-shell': 0.0, 'IoU-shelves': 6.414639829106809, 'IoU-shoe': 2.8524070498152714, 'IoU-shopping cart': nan, 'IoU-shovel': nan, 'IoU-sidecar': 0.0, 'IoU-sidewalk': 7.978165590067181, 'IoU-sign': 25.70595624574139, 'IoU-signal light': 9.731535381819075, 'IoU-sink': 0.49008909666624545, 'IoU-skateboard': nan, 'IoU-ski': 10.03669917164727, 'IoU-sky': 84.24683478067442, 'IoU-sled': 0.0, 'IoU-slippers': nan, 'IoU-smoke': 5.94504820899354, 'IoU-snail': nan, 'IoU-snake': nan, 'IoU-snow': 43.59612112429979, 'IoU-snowmobiles': 16.0188586152075, 'IoU-sofa': 24.522156236100678, 'IoU-spanner': nan, 'IoU-spatula': 0.0, 'IoU-speaker': 0.10603763163516801, 'IoU-speed bump': nan, 'IoU-spice container': 0.0, 'IoU-spoon': 0.4432535310027046, 'IoU-sprayer': nan, 'IoU-squirrel': 0.0, 'IoU-stage': 0.0, 'IoU-stair': 14.793681372423942, 'IoU-stapler': 0.0, 'IoU-stick': 0.0, 'IoU-sticky note': 0.0, 'IoU-stone': nan, 'IoU-stool': 0.0, 'IoU-stove': 0.0, 'IoU-straw': 0.0, 'IoU-stretcher': nan, 'IoU-sun': 0.0, 'IoU-sunglass': 0.0, 'IoU-sunshade': 0.05215123859191656, 'IoU-surveillance camera': 0.0, 'IoU-swan': nan, 'IoU-sweeper': nan, 'IoU-swim ring': 0.0, 'IoU-swimming pool': nan, 'IoU-swing': 0.0, 'IoU-switch': 0.0, 'IoU-table': 23.268145631700406, 'IoU-tableware': 0.003367116737937304, 'IoU-tank': 0.0, 'IoU-tap': 0.0, 'IoU-tape': 0.0, 'IoU-tarp': 0.0, 'IoU-telephone': 0.0, 'IoU-telephone booth': nan, 'IoU-tent': 7.847793488947763, 'IoU-tire': 0.0, 'IoU-toaster': 0.0, 'IoU-toilet': nan, 'IoU-tong': nan, 'IoU-tool': 0.0, 'IoU-toothbrush': nan, 'IoU-towel': 0.0, 'IoU-toy': 7.138237872710181, 'IoU-toy car': 0.0, 'IoU-track': 4.536933721648496, 'IoU-train': 62.20432007105775, 'IoU-trampoline': nan, 'IoU-trash bin': 0.0, 'IoU-tray': 0.0, 'IoU-tree': 64.34888152592465, 'IoU-tricycle': nan, 'IoU-tripod': 26.568713633890074, 'IoU-trophy': 0.0, 'IoU-truck': 4.333920248067796, 'IoU-tube': 0.0, 'IoU-turtle': nan, 'IoU-tvmonitor': 34.15715753732577, 'IoU-tweezers': nan, 'IoU-typewriter': nan, 'IoU-umbrella': 2.8605786644644384, 'IoU-unknown': 3.9860783556044946e-05, 'IoU-vacuum cleaner': 0.0, 'IoU-vending machine': nan, 'IoU-video camera': 0.0, 'IoU-video game console': 0.0, 'IoU-video player': 0.0, 'IoU-video tape': 0.0, 'IoU-violin': 0.47381770893687153, 'IoU-wakeboard': nan, 'IoU-wall': 44.35608638374041, 'IoU-wallet': 0.0, 'IoU-wardrobe': nan, 'IoU-washing machine': 0.35537954911660113, 'IoU-watch': 0.0, 'IoU-water': 39.49318993502388, 'IoU-water dispenser': 0.0, 'IoU-water pipe': 0.0, 'IoU-water skate board': nan, 'IoU-watermelon': nan, 'IoU-whale': nan, 'IoU-wharf': nan, 'IoU-wheel': 0.0, 'IoU-wheelchair': 0.6071640266079554, 'IoU-window': 14.961433622334186, 'IoU-window blinds': nan, 'IoU-wineglass': 5.647897866260507, 'IoU-wire': 0.0, 'IoU-wood': 7.033969906003137, 'IoU-wool': 0.0, 'mACC': 13.115100304046774, 'pACC': 55.77693384604275, 'ACC-accordion': nan, 'ACC-aeroplane': 70.83775974232049, 'ACC-air conditioner': 0.0, 'ACC-antenna': 0.0, 'ACC-artillery': 0.0, 'ACC-ashtray': 0.0, 'ACC-atrium': nan, 'ACC-baby carriage': 24.86960522610355, 'ACC-bag': 8.78452584856238, 'ACC-ball': 22.600701861458653, 'ACC-balloon': 8.955551892753146, 'ACC-bamboo weaving': 0.0, 'ACC-barrel': 0.0, 'ACC-baseball bat': nan, 'ACC-basket': 1.1940178094210425, 'ACC-basketball backboard': 0.0, 'ACC-bathtub': 97.6922491050801, 'ACC-bed': 40.69242664191271, 'ACC-bedclothes': 19.929033235199668, 'ACC-beer': 15.598762704374725, 'ACC-bell': 0.0, 'ACC-bench': 30.376281618934804, 'ACC-bicycle': 53.98139668243223, 'ACC-binoculars': nan, 'ACC-bird': 77.02045310170878, 'ACC-bird cage': 38.18021427988513, 'ACC-bird feeder': 6.410419910862912, 'ACC-bird nest': 0.0, 'ACC-blackboard': 0.0, 'ACC-board': 0.0, 'ACC-boat': 68.221589411063, 'ACC-bone': 0.0, 'ACC-book': 27.722716091612487, 'ACC-bottle': 49.79206310455798, 'ACC-bottle opener': 0.0, 'ACC-bowl': 48.76621205275666, 'ACC-box': 4.48799011825425, 'ACC-bracelet': nan, 'ACC-brick': 0.3469603258410016, 'ACC-bridge': 2.5137434704258768, 'ACC-broom': 0.0, 'ACC-brush': 0.0, 'ACC-bucket': 6.781112223381823, 'ACC-building': 28.873825277458458, 'ACC-bus': 87.05522342847846, 'ACC-cabinet': 3.800554819360157, 'ACC-cabinet door': nan, 'ACC-cage': 19.1971222793934, 'ACC-cake': 96.95884174782641, 'ACC-calculator': 0.0, 'ACC-calendar': 0.0, 'ACC-camel': nan, 'ACC-camera': 0.0, 'ACC-camera lens': nan, 'ACC-can': 0.0, 'ACC-candle': 13.9482100484886, 'ACC-candle holder': 0.0, 'ACC-cap': 0.0, 'ACC-car': 73.7157209120155, 'ACC-card': 0.0, 'ACC-cart': 0.0, 'ACC-case': 0.0, 'ACC-casette recorder': 0.0, 'ACC-cash register': 0.0, 'ACC-cat': 91.04521582026653, 'ACC-cd': 0.0, 'ACC-cd player': 0.0, 'ACC-ceiling': 47.27431678041668, 'ACC-cell phone': 7.200042698548249, 'ACC-cello': 73.68678786606854, 'ACC-chain': 0.0, 'ACC-chair': 44.09918077274889, 'ACC-chessboard': nan, 'ACC-chicken': nan, 'ACC-chopstick': 0.7879956408751781, 'ACC-clip': 0.0, 'ACC-clippers': 0.0, 'ACC-clock': 1.6618882094740315, 'ACC-closet': nan, 'ACC-cloth': 0.0, 'ACC-clothes tree': nan, 'ACC-coffee': 0.0, 'ACC-coffee machine': nan, 'ACC-comb': 0.0, 'ACC-computer': 0.0, 'ACC-concrete': 0.08144080416976918, 'ACC-cone': 0.0, 'ACC-container': 0.0, 'ACC-control booth': nan, 'ACC-controller': 0.0, 'ACC-cooker': nan, 'ACC-copying machine': nan, 'ACC-coral': nan, 'ACC-cork': nan, 'ACC-corkscrew': nan, 'ACC-counter': 0.0, 'ACC-court': nan, 'ACC-cow': 73.49940668344338, 'ACC-crabstick': nan, 'ACC-crane': 0.0, 'ACC-crate': 0.0, 'ACC-cross': 0.0, 'ACC-crutch': 0.0, 'ACC-cup': 35.330033696433404, 'ACC-curtain': 43.552793843664986, 'ACC-cushion': 6.824678885951791, 'ACC-cutting board': 92.18051226453449, 'ACC-dais': 0.0, 'ACC-disc': 0.0, 'ACC-disc case': 0.0, 'ACC-dishwasher': nan, 'ACC-dock': nan, 'ACC-dog': 75.59236548241995, 'ACC-dolphin': nan, 'ACC-door': 11.850753642012704, 'ACC-drainer': nan, 'ACC-dray': nan, 'ACC-drink dispenser': nan, 'ACC-drinking machine': 0.0, 'ACC-drop': nan, 'ACC-drug': 0.0, 'ACC-drum': 0.3188919918484414, 'ACC-drum kit': 0.0, 'ACC-duck': 0.0, 'ACC-dumbbell': nan, 'ACC-earphone': 0.0, 'ACC-earrings': nan, 'ACC-egg': 0.0, 'ACC-electric fan': 0.0, 'ACC-electric iron': 0.0, 'ACC-electric pot': 0.0, 'ACC-electric saw': nan, 'ACC-electronic keyboard': nan, 'ACC-engine': 0.0, 'ACC-envelope': nan, 'ACC-equipment': 0.0, 'ACC-escalator': nan, 'ACC-exhibition booth': 0.0, 'ACC-extinguisher': 0.0, 'ACC-eyeglass': 0.0, 'ACC-fan': 0.0, 'ACC-faucet': 0.0, 'ACC-fax machine': nan, 'ACC-fence': 44.394888528189284, 'ACC-ferris wheel': 12.967660114140775, 'ACC-fire extinguisher': nan, 'ACC-fire hydrant': nan, 'ACC-fire place': 16.507076068913126, 'ACC-fish': 0.0, 'ACC-fish tank': 0.0, 'ACC-fishbowl': 0.0, 'ACC-fishing net': 0.0, 'ACC-fishing pole': 0.0, 'ACC-flag': 47.122094258637546, 'ACC-flagstaff': 0.0, 'ACC-flame': nan, 'ACC-flashlight': 0.0, 'ACC-floor': 40.21707684225218, 'ACC-flower': 29.031486883598994, 'ACC-fly': 0.0, 'ACC-foam': nan, 'ACC-food': 15.94774352998202, 'ACC-footbridge': nan, 'ACC-forceps': nan, 'ACC-fork': 15.286300493167188, 'ACC-forklift': nan, 'ACC-fountain': 0.0, 'ACC-fox': nan, 'ACC-frame': 0.0, 'ACC-fridge': 10.734187286180283, 'ACC-frog': nan, 'ACC-fruit': 0.0, 'ACC-funnel': nan, 'ACC-furnace': 0.0, 'ACC-game controller': 0.0, 'ACC-game machine': 0.0, 'ACC-gas cylinder': nan, 'ACC-gas hood': nan, 'ACC-gas stove': nan, 'ACC-gift box': 72.44864474634115, 'ACC-glass': 0.0, 'ACC-glass marble': 0.0, 'ACC-globe': nan, 'ACC-glove': 0.0, 'ACC-goal': 0.0, 'ACC-grandstand': 20.609904180710043, 'ACC-grass': 84.33253143440872, 'ACC-gravestone': nan, 'ACC-ground': 6.0780628194313495, 'ACC-guardrail': 2.9635214998981048, 'ACC-guitar': 28.364533956617667, 'ACC-gun': 0.0, 'ACC-hammer': 0.0, 'ACC-hand cart': 0.0, 'ACC-handle': 0.0, 'ACC-handrail': 0.0, 'ACC-hanger': 0.0, 'ACC-hard disk drive': nan, 'ACC-hat': 75.70738712579103, 'ACC-hay': 0.0, 'ACC-headphone': 0.0, 'ACC-heater': 0.0, 'ACC-helicopter': 0.0, 'ACC-helmet': 11.682668142747165, 'ACC-holder': 0.0, 'ACC-hook': nan, 'ACC-horse': 45.31781190703716, 'ACC-horse-drawn carriage': 49.38179452865498, 'ACC-hot-air balloon': nan, 'ACC-hydrovalve': nan, 'ACC-ice': 0.0, 'ACC-inflator pump': nan, 'ACC-ipod': 0.0, 'ACC-iron': 0.0, 'ACC-ironing board': nan, 'ACC-jar': 0.0, 'ACC-kart': nan, 'ACC-kettle': 0.0, 'ACC-key': 0.0, 'ACC-keyboard': 23.01078000397623, 'ACC-kitchen range': 1.6897032716205933, 'ACC-kite': nan, 'ACC-knife': 0.0, 'ACC-knife block': 0.0, 'ACC-ladder': 0.0, 'ACC-ladder truck': 0.0, 'ACC-ladle': nan, 'ACC-laptop': 12.690603581048038, 'ACC-leaves': nan, 'ACC-lid': 0.0, 'ACC-life buoy': 98.61667273389152, 'ACC-light': 16.67561426351806, 'ACC-light bulb': 0.0, 'ACC-lighter': nan, 'ACC-line': 0.0, 'ACC-lion': nan, 'ACC-lobster': nan, 'ACC-lock': 0.0, 'ACC-machine': nan, 'ACC-mailbox': 0.0, 'ACC-mannequin': nan, 'ACC-map': 0.0, 'ACC-mask': nan, 'ACC-mat': 0.0, 'ACC-match book': 0.0, 'ACC-mattress': 0.0, 'ACC-menu': 0.0, 'ACC-metal': 0.0, 'ACC-meter box': nan, 'ACC-microphone': 9.222811001766338, 'ACC-microwave': 24.51961277140865, 'ACC-mirror': 2.1859949117014867, 'ACC-missile': nan, 'ACC-model': 0.0, 'ACC-money': 0.0, 'ACC-monkey': 0.0, 'ACC-mop': 0.0, 'ACC-motorbike': 79.31545261580354, 'ACC-mountain': 36.35962091712984, 'ACC-mouse': 4.297273745798581, 'ACC-mouse pad': 0.0, 'ACC-musical instrument': 0.0, 'ACC-napkin': 12.272907937664575, 'ACC-net': 0.0, 'ACC-newspaper': 0.0, 'ACC-oar': 56.778691083133914, 'ACC-ornament': 0.0, 'ACC-outlet': 0.0, 'ACC-oven': 67.57196003974458, 'ACC-oxygen bottle': 0.0, 'ACC-pack': 0.0, 'ACC-pan': 0.0, 'ACC-paper': 16.17831776554685, 'ACC-paper box': 0.0, 'ACC-paper cutter': 0.0, 'ACC-parachute': 0.0, 'ACC-parasol': 2.497996372379466, 'ACC-parterre': 0.0, 'ACC-patio': 0.0, 'ACC-pelage': nan, 'ACC-pen': 0.0, 'ACC-pen container': 0.0, 'ACC-pencil': 0.0, 'ACC-person': 88.89824144057481, 'ACC-photo': nan, 'ACC-piano': 0.0, 'ACC-picture': 4.61252702002268, 'ACC-pig': nan, 'ACC-pillar': 0.0, 'ACC-pillow': 0.0, 'ACC-pipe': 0.0, 'ACC-pitcher': 0.0, 'ACC-plant': 53.78544268805921, 'ACC-plastic': 0.0, 'ACC-plate': 0.0, 'ACC-platform': 17.63348871358891, 'ACC-player': 0.0, 'ACC-playground': 8.309964479341932, 'ACC-pliers': 0.0, 'ACC-plume': 0.0, 'ACC-poker': 0.0, 'ACC-poker chip': 0.0, 'ACC-pole': 2.6186753254424278, 'ACC-pool table': nan, 'ACC-postcard': 0.0, 'ACC-poster': 13.283543341210333, 'ACC-pot': 5.379381555806466, 'ACC-pottedplant': 28.42602582808761, 'ACC-printer': 0.0, 'ACC-projector': nan, 'ACC-pumpkin': 14.544392523364486, 'ACC-rabbit': nan, 'ACC-racket': 0.0, 'ACC-radiator': 0.0, 'ACC-radio': 0.0, 'ACC-rail': 0.0, 'ACC-rake': nan, 'ACC-ramp': 85.36791416744107, 'ACC-range hood': 0.0, 'ACC-receiver': 0.0, 'ACC-recorder': nan, 'ACC-recreational machines': nan, 'ACC-remote control': 0.0, 'ACC-road': 59.261052569605354, 'ACC-robot': nan, 'ACC-rock': 46.80295547591481, 'ACC-rocket': nan, 'ACC-rocking horse': 0.0, 'ACC-rope': 0.0, 'ACC-rug': 24.96599205072705, 'ACC-ruler': nan, 'ACC-runway': 98.0298120544394, 'ACC-saddle': 0.0, 'ACC-sand': 83.18812389614634, 'ACC-saw': 0.0, 'ACC-scale': 0.0, 'ACC-scanner': 0.0, 'ACC-scissors': 0.0, 'ACC-scoop': 0.0, 'ACC-screen': nan, 'ACC-screwdriver': nan, 'ACC-sculpture': 0.0, 'ACC-scythe': nan, 'ACC-sewer': 0.0, 'ACC-sewing machine': 0.0, 'ACC-shed': 0.0, 'ACC-sheep': 69.71821078060499, 'ACC-shell': 0.0, 'ACC-shelves': 8.822933837257775, 'ACC-shoe': 5.385158414902697, 'ACC-shopping cart': nan, 'ACC-shovel': nan, 'ACC-sidecar': 0.0, 'ACC-sidewalk': 79.96903916102777, 'ACC-sign': 29.681796309816157, 'ACC-signal light': 18.244192204084452, 'ACC-sink': 0.5943094866651809, 'ACC-skateboard': nan, 'ACC-ski': 15.885027714162433, 'ACC-sky': 92.8340320879357, 'ACC-sled': 0.0, 'ACC-slippers': nan, 'ACC-smoke': 6.062246567926474, 'ACC-snail': nan, 'ACC-snake': nan, 'ACC-snow': 71.32418395664612, 'ACC-snowmobiles': 66.2006020001942, 'ACC-sofa': 29.85693605074063, 'ACC-spanner': nan, 'ACC-spatula': 0.0, 'ACC-speaker': 0.10676894099376438, 'ACC-speed bump': nan, 'ACC-spice container': 0.0, 'ACC-spoon': 0.5812044394824982, 'ACC-sprayer': nan, 'ACC-squirrel': 0.0, 'ACC-stage': 0.0, 'ACC-stair': 20.79163833872498, 'ACC-stapler': 0.0, 'ACC-stick': 0.0, 'ACC-sticky note': 0.0, 'ACC-stone': nan, 'ACC-stool': 0.0, 'ACC-stove': 0.0, 'ACC-straw': 0.0, 'ACC-stretcher': nan, 'ACC-sun': 0.0, 'ACC-sunglass': 0.0, 'ACC-sunshade': 0.08214901831923109, 'ACC-surveillance camera': 0.0, 'ACC-swan': nan, 'ACC-sweeper': nan, 'ACC-swim ring': 0.0, 'ACC-swimming pool': nan, 'ACC-swing': 0.0, 'ACC-switch': 0.0, 'ACC-table': 33.00140390531311, 'ACC-tableware': 0.906344410876133, 'ACC-tank': 0.0, 'ACC-tap': 0.0, 'ACC-tape': 0.0, 'ACC-tarp': 0.0, 'ACC-telephone': 0.0, 'ACC-telephone booth': nan, 'ACC-tent': 9.431321854887507, 'ACC-tire': 0.0, 'ACC-toaster': 0.0, 'ACC-toilet': nan, 'ACC-tong': nan, 'ACC-tool': 0.0, 'ACC-toothbrush': nan, 'ACC-towel': 0.0, 'ACC-toy': 7.598937308793142, 'ACC-toy car': 0.0, 'ACC-track': 6.6018551441651905, 'ACC-train': 77.45837611722374, 'ACC-trampoline': nan, 'ACC-trash bin': 0.0, 'ACC-tray': 0.0, 'ACC-tree': 79.4676157759717, 'ACC-tricycle': nan, 'ACC-tripod': 46.193595342066956, 'ACC-trophy': 0.0, 'ACC-truck': 24.202945945344375, 'ACC-tube': 0.0, 'ACC-turtle': nan, 'ACC-tvmonitor': 73.88483823706252, 'ACC-tweezers': nan, 'ACC-typewriter': nan, 'ACC-umbrella': 28.691835963612057, 'ACC-unknown': 3.9860783556044946e-05, 'ACC-vacuum cleaner': 0.0, 'ACC-vending machine': nan, 'ACC-video camera': 0.0, 'ACC-video game console': 0.0, 'ACC-video player': 0.0, 'ACC-video tape': 0.0, 'ACC-violin': 5.209513023782559, 'ACC-wakeboard': nan, 'ACC-wall': 69.30561845685162, 'ACC-wallet': 0.0, 'ACC-wardrobe': nan, 'ACC-washing machine': 0.35537954911660113, 'ACC-watch': 0.0, 'ACC-water': 42.10521062366916, 'ACC-water dispenser': 0.0, 'ACC-water pipe': 0.0, 'ACC-water skate board': nan, 'ACC-watermelon': nan, 'ACC-whale': nan, 'ACC-wharf': nan, 'ACC-wheel': 0.0, 'ACC-wheelchair': 84.00812457684495, 'ACC-window': 23.03144177199735, 'ACC-window blinds': nan, 'ACC-wineglass': 5.95603390992623, 'ACC-wire': 0.0, 'ACC-wood': 8.780233260958461, 'ACC-wool': 0.0})])
[12/13 00:40:51 d2.engine.defaults]: Evaluation results for pcontext_full_sem_seg_val in csv format:
[12/13 00:40:51 d2.evaluation.testing]: copypaste: Task: sem_seg
[12/13 00:40:51 d2.evaluation.testing]: copypaste: mIoU,fwIoU,mACC,pACC
[12/13 00:40:51 d2.evaluation.testing]: copypaste: 7.0474,44.0554,13.1151,55.7769
[12/13 00:40:51 d2.data.datasets.coco]: Loaded 2000 images with semantic segmentation from datasets/ADEChallengeData2016/images/validation
[12/13 00:40:51 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=2560, sample_style='choice')]
[12/13 00:40:51 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[12/13 00:40:51 d2.data.common]: Serializing 2000 elements to byte tensors and concatenating them all ...
[12/13 00:40:51 d2.data.common]: Serialized dataset takes 0.48 MiB
[12/13 00:40:51 d2.data.datasets.coco]: Loaded 2000 images with semantic segmentation from datasets/ADEChallengeData2016/images/validation
[12/13 00:40:51 d2.evaluation.evaluator]: Start inference on 1000 batches
[12/13 00:40:57 d2.evaluation.evaluator]: Inference done 11/1000. Dataloading: 0.0013 s/iter. Inference: 0.0674 s/iter. Eval: 0.0163 s/iter. Total: 0.0850 s/iter. ETA=0:01:24
[12/13 00:41:02 d2.evaluation.evaluator]: Inference done 72/1000. Dataloading: 0.0018 s/iter. Inference: 0.0678 s/iter. Eval: 0.0137 s/iter. Total: 0.0834 s/iter. ETA=0:01:17
[12/13 00:41:07 d2.evaluation.evaluator]: Inference done 125/1000. Dataloading: 0.0018 s/iter. Inference: 0.0718 s/iter. Eval: 0.0147 s/iter. Total: 0.0884 s/iter. ETA=0:01:17
[12/13 00:41:12 d2.evaluation.evaluator]: Inference done 178/1000. Dataloading: 0.0018 s/iter. Inference: 0.0723 s/iter. Eval: 0.0160 s/iter. Total: 0.0902 s/iter. ETA=0:01:14
[12/13 00:41:17 d2.evaluation.evaluator]: Inference done 227/1000. Dataloading: 0.0018 s/iter. Inference: 0.0761 s/iter. Eval: 0.0150 s/iter. Total: 0.0930 s/iter. ETA=0:01:11
[12/13 00:41:22 d2.evaluation.evaluator]: Inference done 283/1000. Dataloading: 0.0018 s/iter. Inference: 0.0757 s/iter. Eval: 0.0148 s/iter. Total: 0.0924 s/iter. ETA=0:01:06
[12/13 00:41:27 d2.evaluation.evaluator]: Inference done 339/1000. Dataloading: 0.0018 s/iter. Inference: 0.0747 s/iter. Eval: 0.0154 s/iter. Total: 0.0920 s/iter. ETA=0:01:00
[12/13 00:41:32 d2.evaluation.evaluator]: Inference done 393/1000. Dataloading: 0.0018 s/iter. Inference: 0.0752 s/iter. Eval: 0.0151 s/iter. Total: 0.0922 s/iter. ETA=0:00:55
[12/13 00:41:37 d2.evaluation.evaluator]: Inference done 437/1000. Dataloading: 0.0018 s/iter. Inference: 0.0776 s/iter. Eval: 0.0149 s/iter. Total: 0.0944 s/iter. ETA=0:00:53
[12/13 00:41:42 d2.evaluation.evaluator]: Inference done 493/1000. Dataloading: 0.0018 s/iter. Inference: 0.0771 s/iter. Eval: 0.0149 s/iter. Total: 0.0939 s/iter. ETA=0:00:47
[12/13 00:41:47 d2.evaluation.evaluator]: Inference done 550/1000. Dataloading: 0.0019 s/iter. Inference: 0.0761 s/iter. Eval: 0.0152 s/iter. Total: 0.0933 s/iter. ETA=0:00:41
[12/13 00:41:52 d2.evaluation.evaluator]: Inference done 604/1000. Dataloading: 0.0019 s/iter. Inference: 0.0761 s/iter. Eval: 0.0153 s/iter. Total: 0.0933 s/iter. ETA=0:00:36
[12/13 00:41:57 d2.evaluation.evaluator]: Inference done 660/1000. Dataloading: 0.0019 s/iter. Inference: 0.0761 s/iter. Eval: 0.0149 s/iter. Total: 0.0930 s/iter. ETA=0:00:31
[12/13 00:42:10 d2.evaluation.evaluator]: Inference done 671/1000. Dataloading: 0.0019 s/iter. Inference: 0.0936 s/iter. Eval: 0.0149 s/iter. Total: 0.1103 s/iter. ETA=0:00:36
[12/13 00:42:15 d2.evaluation.evaluator]: Inference done 732/1000. Dataloading: 0.0019 s/iter. Inference: 0.0914 s/iter. Eval: 0.0147 s/iter. Total: 0.1081 s/iter. ETA=0:00:28
[12/13 00:42:20 d2.evaluation.evaluator]: Inference done 782/1000. Dataloading: 0.0019 s/iter. Inference: 0.0912 s/iter. Eval: 0.0145 s/iter. Total: 0.1076 s/iter. ETA=0:00:23
[12/13 00:42:25 d2.evaluation.evaluator]: Inference done 842/1000. Dataloading: 0.0019 s/iter. Inference: 0.0891 s/iter. Eval: 0.0149 s/iter. Total: 0.1059 s/iter. ETA=0:00:16
[12/13 00:42:30 d2.evaluation.evaluator]: Inference done 893/1000. Dataloading: 0.0019 s/iter. Inference: 0.0889 s/iter. Eval: 0.0147 s/iter. Total: 0.1055 s/iter. ETA=0:00:11
[12/13 00:42:35 d2.evaluation.evaluator]: Inference done 949/1000. Dataloading: 0.0019 s/iter. Inference: 0.0881 s/iter. Eval: 0.0146 s/iter. Total: 0.1046 s/iter. ETA=0:00:05
[12/13 00:42:40 d2.evaluation.evaluator]: Inference done 997/1000. Dataloading: 0.0019 s/iter. Inference: 0.0881 s/iter. Eval: 0.0146 s/iter. Total: 0.1046 s/iter. ETA=0:00:00
[12/13 00:42:41 d2.evaluation.evaluator]: Total inference time: 0:01:44.746013 (0.105272 s / iter per device, on 2 devices)
[12/13 00:42:41 d2.evaluation.evaluator]: Total inference pure compute time: 0:01:27 (0.088097 s / iter per device, on 2 devices)
[12/13 00:42:43 d2.evaluation.sem_seg_evaluation]: OrderedDict([('sem_seg', {'mIoU': 13.175018806509186, 'fwIoU': 42.59473865593388, 'IoU-wall': 48.19956876698346, 'BoundaryIoU-wall': 68.68214708399476, 'min(IoU, B-Iou)-wall': 48.19956876698346, 'IoU-building': 61.62473717485889, 'BoundaryIoU-building': 8.254846561200518, 'min(IoU, B-Iou)-building': 8.254846561200518, 'IoU-sky': 90.23217893111305, 'BoundaryIoU-sky': 0.0, 'min(IoU, B-Iou)-sky': 0.0, 'IoU-floor': 42.49115243864552, 'BoundaryIoU-floor': 0.0, 'min(IoU, B-Iou)-floor': 0.0, 'IoU-tree': 61.92369619839118, 'BoundaryIoU-tree': 0.0, 'min(IoU, B-Iou)-tree': 0.0, 'IoU-ceiling': 50.67550122403206, 'BoundaryIoU-ceiling': 0.0, 'min(IoU, B-Iou)-ceiling': 0.0, 'IoU-road, route': 39.51161880429677, 'BoundaryIoU-road, route': 0.0, 'min(IoU, B-Iou)-road, route': 0.0, 'IoU-bed': 50.617782926345754, 'BoundaryIoU-bed': 0.0, 'min(IoU, B-Iou)-bed': 0.0, 'IoU-window ': 29.417752287152293, 'BoundaryIoU-window ': 0.0, 'min(IoU, B-Iou)-window ': 0.0, 'IoU-grass': 54.38397003616734, 'BoundaryIoU-grass': 0.0, 'min(IoU, B-Iou)-grass': 0.0, 'IoU-cabinet': 13.674165614155239, 'BoundaryIoU-cabinet': 0.0, 'min(IoU, B-Iou)-cabinet': 0.0, 'IoU-sidewalk, pavement': 31.705523336115704, 'BoundaryIoU-sidewalk, pavement': 0.0, 'min(IoU, B-Iou)-sidewalk, pavement': 0.0, 'IoU-person': 64.72920710760832, 'BoundaryIoU-person': 0.0, 'min(IoU, B-Iou)-person': 0.0, 'IoU-earth, ground': 0.0, 'BoundaryIoU-earth, ground': 0.0, 'min(IoU, B-Iou)-earth, ground': 0.0, 'IoU-door': 11.483079806788817, 'BoundaryIoU-door': 0.0, 'min(IoU, B-Iou)-door': 0.0, 'IoU-table': 8.34257978927436, 'BoundaryIoU-table': 0.0, 'min(IoU, B-Iou)-table': 0.0, 'IoU-mountain, mount': 18.43782594988132, 'BoundaryIoU-mountain, mount': 0.0, 'min(IoU, B-Iou)-mountain, mount': 0.0, 'IoU-plant': 32.52560141141079, 'BoundaryIoU-plant': 0.0, 'min(IoU, B-Iou)-plant': 0.0, 'IoU-curtain': 26.55170156657636, 'BoundaryIoU-curtain': 0.0, 'min(IoU, B-Iou)-curtain': 0.0, 'IoU-chair': 19.757230715180835, 'BoundaryIoU-chair': 0.0, 'min(IoU, B-Iou)-chair': 0.0, 'IoU-car': 61.08744002020672, 'BoundaryIoU-car': 0.0, 'min(IoU, B-Iou)-car': 0.0, 'IoU-water': 7.845225298844932, 'BoundaryIoU-water': 0.0, 'min(IoU, B-Iou)-water': 0.0, 'IoU-painting, picture': 0.5498445429451844, 'BoundaryIoU-painting, picture': 0.0, 'min(IoU, B-Iou)-painting, picture': 0.0, 'IoU-sofa': 7.918577207658773, 'BoundaryIoU-sofa': 0.0, 'min(IoU, B-Iou)-sofa': 0.0, 'IoU-shelf': 11.010075439575784, 'BoundaryIoU-shelf': 0.0, 'min(IoU, B-Iou)-shelf': 0.0, 'IoU-house': 18.660365094282376, 'BoundaryIoU-house': 0.0, 'min(IoU, B-Iou)-house': 0.0, 'IoU-sea': 33.43051814749683, 'BoundaryIoU-sea': 0.0, 'min(IoU, B-Iou)-sea': 0.0, 'IoU-mirror': 6.8886444898678425, 'BoundaryIoU-mirror': 0.0, 'min(IoU, B-Iou)-mirror': 0.0, 'IoU-rug': 18.607746298196744, 'BoundaryIoU-rug': 0.0, 'min(IoU, B-Iou)-rug': 0.0, 'IoU-field': 2.0375573508705234, 'BoundaryIoU-field': 0.0, 'min(IoU, B-Iou)-field': 0.0, 'IoU-armchair': 8.407163596910278, 'BoundaryIoU-armchair': 0.0, 'min(IoU, B-Iou)-armchair': 0.0, 'IoU-seat': 11.21313186862035, 'BoundaryIoU-seat': 0.0, 'min(IoU, B-Iou)-seat': 0.0, 'IoU-fence': 22.77216701201094, 'BoundaryIoU-fence': 0.0, 'min(IoU, B-Iou)-fence': 0.0, 'IoU-desk': 9.330691536562776, 'BoundaryIoU-desk': 0.0, 'min(IoU, B-Iou)-desk': 0.0, 'IoU-rock, stone': 20.544188193746244, 'BoundaryIoU-rock, stone': 0.0, 'min(IoU, B-Iou)-rock, stone': 0.0, 'IoU-wardrobe, closet, press': 6.140421950571826, 'BoundaryIoU-wardrobe, closet, press': 0.0, 'min(IoU, B-Iou)-wardrobe, closet, press': 0.0, 'IoU-lamp': 1.2659462964303587, 'BoundaryIoU-lamp': 0.0, 'min(IoU, B-Iou)-lamp': 0.0, 'IoU-tub': 8.750056186714401, 'BoundaryIoU-tub': 0.0, 'min(IoU, B-Iou)-tub': 0.0, 'IoU-rail': 0.9804836780536188, 'BoundaryIoU-rail': 0.0, 'min(IoU, B-Iou)-rail': 0.0, 'IoU-cushion': 0.9029034131503849, 'BoundaryIoU-cushion': 0.0, 'min(IoU, B-Iou)-cushion': 0.0, 'IoU-base, pedestal, stand': 0.0, 'BoundaryIoU-base, pedestal, stand': 0.0, 'min(IoU, B-Iou)-base, pedestal, stand': 0.0, 'IoU-box': 0.41010906596049373, 'BoundaryIoU-box': 0.0, 'min(IoU, B-Iou)-box': 0.0, 'IoU-column, pillar': 10.614420039633222, 'BoundaryIoU-column, pillar': 0.0, 'min(IoU, B-Iou)-column, pillar': 0.0, 'IoU-signboard, sign': 8.233157284784435, 'BoundaryIoU-signboard, sign': 0.0, 'min(IoU, B-Iou)-signboard, sign': 0.0, 'IoU-chest of drawers, chest, bureau, dresser': 6.289479177804594, 'BoundaryIoU-chest of drawers, chest, bureau, dresser': 0.0, 'min(IoU, B-Iou)-chest of drawers, chest, bureau, dresser': 0.0, 'IoU-counter': 11.824481863839909, 'BoundaryIoU-counter': 0.0, 'min(IoU, B-Iou)-counter': 0.0, 'IoU-sand': 43.54910474942525, 'BoundaryIoU-sand': 0.0, 'min(IoU, B-Iou)-sand': 0.0, 'IoU-sink': 13.451382223459682, 'BoundaryIoU-sink': 0.0, 'min(IoU, B-Iou)-sink': 0.0, 'IoU-skyscraper': 1.430444116073428, 'BoundaryIoU-skyscraper': 0.0, 'min(IoU, B-Iou)-skyscraper': 0.0, 'IoU-fireplace': 13.315006281094464, 'BoundaryIoU-fireplace': 0.0, 'min(IoU, B-Iou)-fireplace': 0.0, 'IoU-refrigerator, icebox': 0.7977433457210087, 'BoundaryIoU-refrigerator, icebox': 0.0, 'min(IoU, B-Iou)-refrigerator, icebox': 0.0, 'IoU-grandstand, covered stand': 22.463729904637983, 'BoundaryIoU-grandstand, covered stand': 0.0, 'min(IoU, B-Iou)-grandstand, covered stand': 0.0, 'IoU-path': 0.005589262228792457, 'BoundaryIoU-path': 0.0, 'min(IoU, B-Iou)-path': 0.0, 'IoU-stairs': 0.1045151947114126, 'BoundaryIoU-stairs': 0.0, 'min(IoU, B-Iou)-stairs': 0.0, 'IoU-runway': 40.61479428466655, 'BoundaryIoU-runway': 0.0, 'min(IoU, B-Iou)-runway': 0.0, 'IoU-case, display case, showcase, vitrine': 0.0, 'BoundaryIoU-case, display case, showcase, vitrine': 0.0, 'min(IoU, B-Iou)-case, display case, showcase, vitrine': 0.0, 'IoU-pool table, billiard table, snooker table': 0.0, 'BoundaryIoU-pool table, billiard table, snooker table': 0.0, 'min(IoU, B-Iou)-pool table, billiard table, snooker table': 0.0, 'IoU-pillow': 0.0, 'BoundaryIoU-pillow': 0.0, 'min(IoU, B-Iou)-pillow': 0.0, 'IoU-screen door, screen': 0.0, 'BoundaryIoU-screen door, screen': 0.0, 'min(IoU, B-Iou)-screen door, screen': 0.0, 'IoU-stairway, staircase': 0.0, 'BoundaryIoU-stairway, staircase': 0.0, 'min(IoU, B-Iou)-stairway, staircase': 0.0, 'IoU-river': 9.03012372370664, 'BoundaryIoU-river': 0.0, 'min(IoU, B-Iou)-river': 0.0, 'IoU-bridge, span': 7.485751588038866, 'BoundaryIoU-bridge, span': 0.0, 'min(IoU, B-Iou)-bridge, span': 0.0, 'IoU-bookcase': 3.747559531240479, 'BoundaryIoU-bookcase': 0.0, 'min(IoU, B-Iou)-bookcase': 0.0, 'IoU-blind, screen': 0.0, 'BoundaryIoU-blind, screen': 0.0, 'min(IoU, B-Iou)-blind, screen': 0.0, 'IoU-coffee table': 4.296110564128235, 'BoundaryIoU-coffee table': 0.0, 'min(IoU, B-Iou)-coffee table': 0.0, 'IoU-toilet, can, commode, crapper, pot, potty, stool, throne': 9.11663384316849, 'BoundaryIoU-toilet, can, commode, crapper, pot, potty, stool, throne': 0.0, 'min(IoU, B-Iou)-toilet, can, commode, crapper, pot, potty, stool, throne': 0.0, 'IoU-flower': 14.7217537292823, 'BoundaryIoU-flower': 0.0, 'min(IoU, B-Iou)-flower': 0.0, 'IoU-book': 18.809620469831795, 'BoundaryIoU-book': 0.0, 'min(IoU, B-Iou)-book': 0.0, 'IoU-hill': 5.513238589261801, 'BoundaryIoU-hill': 0.0, 'min(IoU, B-Iou)-hill': 0.0, 'IoU-bench': 10.813764648422868, 'BoundaryIoU-bench': 0.0, 'min(IoU, B-Iou)-bench': 0.0, 'IoU-countertop': 1.2119528119811118, 'BoundaryIoU-countertop': 0.0, 'min(IoU, B-Iou)-countertop': 0.0, 'IoU-stove': 0.09301227301261857, 'BoundaryIoU-stove': 0.0, 'min(IoU, B-Iou)-stove': 0.0, 'IoU-palm, palm tree': 21.080122665179815, 'BoundaryIoU-palm, palm tree': 0.0, 'min(IoU, B-Iou)-palm, palm tree': 0.0, 'IoU-kitchen island': 2.3624984634354274, 'BoundaryIoU-kitchen island': 0.0, 'min(IoU, B-Iou)-kitchen island': 0.0, 'IoU-computer': 0.0, 'BoundaryIoU-computer': 0.0, 'min(IoU, B-Iou)-computer': 0.0, 'IoU-swivel chair': 9.381776248745316, 'BoundaryIoU-swivel chair': 0.0, 'min(IoU, B-Iou)-swivel chair': 0.0, 'IoU-boat': 50.33052434130474, 'BoundaryIoU-boat': 0.0, 'min(IoU, B-Iou)-boat': 0.0, 'IoU-bar': 2.1489346830102116, 'BoundaryIoU-bar': 0.0, 'min(IoU, B-Iou)-bar': 0.0, 'IoU-arcade machine': 0.0, 'BoundaryIoU-arcade machine': 0.0, 'min(IoU, B-Iou)-arcade machine': 0.0, 'IoU-hovel, hut, hutch, shack, shanty': 17.48120280049913, 'BoundaryIoU-hovel, hut, hutch, shack, shanty': 0.0, 'min(IoU, B-Iou)-hovel, hut, hutch, shack, shanty': 0.0, 'IoU-bus': 36.071427000541014, 'BoundaryIoU-bus': 0.0, 'min(IoU, B-Iou)-bus': 0.0, 'IoU-towel': 6.360480788296033, 'BoundaryIoU-towel': 0.0, 'min(IoU, B-Iou)-towel': 0.0, 'IoU-light': 1.6886096410042497, 'BoundaryIoU-light': 0.0, 'min(IoU, B-Iou)-light': 0.0, 'IoU-truck': 0.9768507627834846, 'BoundaryIoU-truck': 0.0, 'min(IoU, B-Iou)-truck': 0.0, 'IoU-tower': 7.966692402748063, 'BoundaryIoU-tower': 0.0, 'min(IoU, B-Iou)-tower': 0.0, 'IoU-chandelier': 14.27090251884586, 'BoundaryIoU-chandelier': 0.0, 'min(IoU, B-Iou)-chandelier': 0.0, 'IoU-awning, sunshade, sunblind': 0.0, 'BoundaryIoU-awning, sunshade, sunblind': 0.0, 'min(IoU, B-Iou)-awning, sunshade, sunblind': 0.0, 'IoU-street lamp': 3.2487936996279205, 'BoundaryIoU-street lamp': 0.0, 'min(IoU, B-Iou)-street lamp': 0.0, 'IoU-booth': 1.0488273378935977, 'BoundaryIoU-booth': 0.0, 'min(IoU, B-Iou)-booth': 0.0, 'IoU-tv': 10.389142403736543, 'BoundaryIoU-tv': 0.0, 'min(IoU, B-Iou)-tv': 0.0, 'IoU-plane': 19.753362555951675, 'BoundaryIoU-plane': 0.0, 'min(IoU, B-Iou)-plane': 0.0, 'IoU-dirt track': 0.0, 'BoundaryIoU-dirt track': 0.0, 'min(IoU, B-Iou)-dirt track': 0.0, 'IoU-clothes': 1.931403301280403, 'BoundaryIoU-clothes': 0.0, 'min(IoU, B-Iou)-clothes': 0.0, 'IoU-pole': 0.43396174788628344, 'BoundaryIoU-pole': 0.0, 'min(IoU, B-Iou)-pole': 0.0, 'IoU-land, ground, soil': 0.16077988018555547, 'BoundaryIoU-land, ground, soil': 0.0, 'min(IoU, B-Iou)-land, ground, soil': 0.0, 'IoU-bannister, banister, balustrade, balusters, handrail': 0.0, 'BoundaryIoU-bannister, banister, balustrade, balusters, handrail': 0.0, 'min(IoU, B-Iou)-bannister, banister, balustrade, balusters, handrail': 0.0, 'IoU-escalator, moving staircase, moving stairway': 32.87287421272162, 'BoundaryIoU-escalator, moving staircase, moving stairway': 0.0, 'min(IoU, B-Iou)-escalator, moving staircase, moving stairway': 0.0, 'IoU-ottoman, pouf, pouffe, puff, hassock': 0.15688405341909872, 'BoundaryIoU-ottoman, pouf, pouffe, puff, hassock': 0.0, 'min(IoU, B-Iou)-ottoman, pouf, pouffe, puff, hassock': 0.0, 'IoU-bottle': 9.356615513716667, 'BoundaryIoU-bottle': 0.0, 'min(IoU, B-Iou)-bottle': 0.0, 'IoU-buffet, counter, sideboard': 0.0, 'BoundaryIoU-buffet, counter, sideboard': 0.0, 'min(IoU, B-Iou)-buffet, counter, sideboard': 0.0, 'IoU-poster, posting, placard, notice, bill, card': 0.0, 'BoundaryIoU-poster, posting, placard, notice, bill, card': 0.0, 'min(IoU, B-Iou)-poster, posting, placard, notice, bill, card': 0.0, 'IoU-stage': 0.0, 'BoundaryIoU-stage': 0.0, 'min(IoU, B-Iou)-stage': 0.0, 'IoU-van': 14.466461057719693, 'BoundaryIoU-van': 0.0, 'min(IoU, B-Iou)-van': 0.0, 'IoU-ship': 0.0, 'BoundaryIoU-ship': 0.0, 'min(IoU, B-Iou)-ship': 0.0, 'IoU-fountain': 34.60964067336113, 'BoundaryIoU-fountain': 0.0, 'min(IoU, B-Iou)-fountain': 0.0, 'IoU-conveyer belt, conveyor belt, conveyer, conveyor, transporter': 0.0, 'BoundaryIoU-conveyer belt, conveyor belt, conveyer, conveyor, transporter': 0.0, 'min(IoU, B-Iou)-conveyer belt, conveyor belt, conveyer, conveyor, transporter': 0.0, 'IoU-canopy': 1.2516824461904819, 'BoundaryIoU-canopy': 0.0, 'min(IoU, B-Iou)-canopy': 0.0, 'IoU-washer, automatic washer, washing machine': 4.809374946907015, 'BoundaryIoU-washer, automatic washer, washing machine': 0.0, 'min(IoU, B-Iou)-washer, automatic washer, washing machine': 0.0, 'IoU-plaything, toy': 3.237647872669811, 'BoundaryIoU-plaything, toy': 0.0, 'min(IoU, B-Iou)-plaything, toy': 0.0, 'IoU-pool': 14.032050118454183, 'BoundaryIoU-pool': 0.0, 'min(IoU, B-Iou)-pool': 0.0, 'IoU-stool': 2.3167809188162694, 'BoundaryIoU-stool': 0.0, 'min(IoU, B-Iou)-stool': 0.0, 'IoU-barrel, cask': 0.0, 'BoundaryIoU-barrel, cask': 0.0, 'min(IoU, B-Iou)-barrel, cask': 0.0, 'IoU-basket, handbasket': 0.03557544194234578, 'BoundaryIoU-basket, handbasket': 0.0, 'min(IoU, B-Iou)-basket, handbasket': 0.0, 'IoU-falls': 0.0, 'BoundaryIoU-falls': 0.0, 'min(IoU, B-Iou)-falls': 0.0, 'IoU-tent': 18.09665490712798, 'BoundaryIoU-tent': 0.0, 'min(IoU, B-Iou)-tent': 0.0, 'IoU-bag': 0.8363945248757516, 'BoundaryIoU-bag': 0.0, 'min(IoU, B-Iou)-bag': 0.0, 'IoU-minibike, motorbike': 29.647773814242306, 'BoundaryIoU-minibike, motorbike': 0.0, 'min(IoU, B-Iou)-minibike, motorbike': 0.0, 'IoU-cradle': 28.367117953287295, 'BoundaryIoU-cradle': 0.0, 'min(IoU, B-Iou)-cradle': 0.0, 'IoU-oven': 5.001848647205918, 'BoundaryIoU-oven': 0.0, 'min(IoU, B-Iou)-oven': 0.0, 'IoU-ball': 19.84084006309891, 'BoundaryIoU-ball': 0.0, 'min(IoU, B-Iou)-ball': 0.0, 'IoU-food, solid food': 21.486096289245896, 'BoundaryIoU-food, solid food': 0.0, 'min(IoU, B-Iou)-food, solid food': 0.0, 'IoU-step, stair': 0.0, 'BoundaryIoU-step, stair': 0.0, 'min(IoU, B-Iou)-step, stair': 0.0, 'IoU-tank, storage tank': 0.0, 'BoundaryIoU-tank, storage tank': 0.0, 'min(IoU, B-Iou)-tank, storage tank': 0.0, 'IoU-trade name': 0.0, 'BoundaryIoU-trade name': 0.0, 'min(IoU, B-Iou)-trade name': 0.0, 'IoU-microwave': 38.10253424812464, 'BoundaryIoU-microwave': 0.0, 'min(IoU, B-Iou)-microwave': 0.0, 'IoU-pot': 5.686940661532825, 'BoundaryIoU-pot': 0.0, 'min(IoU, B-Iou)-pot': 0.0, 'IoU-animal': 53.92475278466037, 'BoundaryIoU-animal': 0.0, 'min(IoU, B-Iou)-animal': 0.0, 'IoU-bicycle': 31.286262372975806, 'BoundaryIoU-bicycle': 0.0, 'min(IoU, B-Iou)-bicycle': 0.0, 'IoU-lake': 4.249690494299928, 'BoundaryIoU-lake': 0.0, 'min(IoU, B-Iou)-lake': 0.0, 'IoU-dishwasher': 0.0, 'BoundaryIoU-dishwasher': 0.0, 'min(IoU, B-Iou)-dishwasher': 0.0, 'IoU-screen': 14.578408195429471, 'BoundaryIoU-screen': 0.0, 'min(IoU, B-Iou)-screen': 0.0, 'IoU-blanket, cover': 0.0, 'BoundaryIoU-blanket, cover': 0.0, 'min(IoU, B-Iou)-blanket, cover': 0.0, 'IoU-sculpture': 15.29499457164617, 'BoundaryIoU-sculpture': 0.0, 'min(IoU, B-Iou)-sculpture': 0.0, 'IoU-hood, exhaust hood': 0.0, 'BoundaryIoU-hood, exhaust hood': 0.0, 'min(IoU, B-Iou)-hood, exhaust hood': 0.0, 'IoU-sconce': 2.353572367809928, 'BoundaryIoU-sconce': 0.0, 'min(IoU, B-Iou)-sconce': 0.0, 'IoU-vase': 3.123771853091444, 'BoundaryIoU-vase': 0.0, 'min(IoU, B-Iou)-vase': 0.0, 'IoU-traffic light': 8.835882910841136, 'BoundaryIoU-traffic light': 0.0, 'min(IoU, B-Iou)-traffic light': 0.0, 'IoU-tray': 4.440430790565553, 'BoundaryIoU-tray': 0.0, 'min(IoU, B-Iou)-tray': 0.0, 'IoU-trash can': 2.046846489269629, 'BoundaryIoU-trash can': 0.0, 'min(IoU, B-Iou)-trash can': 0.0, 'IoU-fan': 0.0, 'BoundaryIoU-fan': 0.0, 'min(IoU, B-Iou)-fan': 0.0, 'IoU-pier': 3.3308841276520305, 'BoundaryIoU-pier': 0.0, 'min(IoU, B-Iou)-pier': 0.0, 'IoU-crt screen': 0.0, 'BoundaryIoU-crt screen': 0.0, 'min(IoU, B-Iou)-crt screen': 0.0, 'IoU-plate': 22.432241972423896, 'BoundaryIoU-plate': 0.0, 'min(IoU, B-Iou)-plate': 0.0, 'IoU-monitor': 17.20568393686752, 'BoundaryIoU-monitor': 0.0, 'min(IoU, B-Iou)-monitor': 0.0, 'IoU-bulletin board': 0.0, 'BoundaryIoU-bulletin board': 0.0, 'min(IoU, B-Iou)-bulletin board': 0.0, 'IoU-shower': 0.0, 'BoundaryIoU-shower': 0.0, 'min(IoU, B-Iou)-shower': 0.0, 'IoU-radiator': 8.856030175119818, 'BoundaryIoU-radiator': 0.0, 'min(IoU, B-Iou)-radiator': 0.0, 'IoU-glass, drinking glass': 0.0, 'BoundaryIoU-glass, drinking glass': 0.0, 'min(IoU, B-Iou)-glass, drinking glass': 0.0, 'IoU-clock': 2.774365380049345, 'BoundaryIoU-clock': 0.0, 'min(IoU, B-Iou)-clock': 0.0, 'IoU-flag': 17.649420672249626, 'BoundaryIoU-flag': 0.0, 'min(IoU, B-Iou)-flag': 0.0, 'mACC': 25.155159415678824, 'pACC': 53.361260841205315, 'ACC-wall': 58.04897602865711, 'ACC-building': 71.3773976542026, 'ACC-sky': 93.6430236303021, 'ACC-floor': 44.96271125667402, 'ACC-tree': 87.85875539734741, 'ACC-ceiling': 61.68962025502793, 'ACC-road, route': 40.896046472188, 'ACC-bed': 64.36393997856695, 'ACC-window ': 41.81879415163622, 'ACC-grass': 68.78330239514207, 'ACC-cabinet': 15.960380965830279, 'ACC-sidewalk, pavement': 87.71850072271334, 'ACC-person': 87.49186075823306, 'ACC-earth, ground': 0.0, 'ACC-door': 24.832584948478203, 'ACC-table': 9.424648794693944, 'ACC-mountain, mount': 19.1606400741864, 'ACC-plant': 37.884571533066364, 'ACC-curtain': 55.4834677837962, 'ACC-chair': 34.4585733302443, 'ACC-car': 81.5514021669626, 'ACC-water': 8.275126877815515, 'ACC-painting, picture': 0.5586873098720765, 'ACC-sofa': 8.410352145674867, 'ACC-shelf': 12.176243592031296, 'ACC-house': 81.86795662147179, 'ACC-sea': 49.547070026549875, 'ACC-mirror': 13.185142644055633, 'ACC-rug': 41.02072617355736, 'ACC-field': 2.0378209334331503, 'ACC-armchair': 69.49456985100659, 'ACC-seat': 11.584182578951305, 'ACC-fence': 54.34757895309153, 'ACC-desk': 30.063503508377654, 'ACC-rock, stone': 79.81917567220238, 'ACC-wardrobe, closet, press': 7.033918219011842, 'ACC-lamp': 1.2833040452634292, 'ACC-tub': 20.442253200458527, 'ACC-rail': 1.3119159124744038, 'ACC-cushion': 0.9466403248627788, 'ACC-base, pedestal, stand': 0.0, 'ACC-box': 0.41414831073495517, 'ACC-column, pillar': 17.11232166457691, 'ACC-signboard, sign': 8.423191892680082, 'ACC-chest of drawers, chest, bureau, dresser': 16.417357003020953, 'ACC-counter': 12.48089472729799, 'ACC-sand': 60.83565387332624, 'ACC-sink': 19.41975494143226, 'ACC-skyscraper': 1.4460958443452974, 'ACC-fireplace': 15.267587133646263, 'ACC-refrigerator, icebox': 1.0251167824577325, 'ACC-grandstand, covered stand': 67.97827321371581, 'ACC-path': 0.0059726016043139245, 'ACC-stairs': 0.11011725718520307, 'ACC-runway': 73.73501764474601, 'ACC-case, display case, showcase, vitrine': 0.0, 'ACC-pool table, billiard table, snooker table': 0.0, 'ACC-pillow': 0.0, 'ACC-screen door, screen': 0.0, 'ACC-stairway, staircase': 0.0, 'ACC-river': 16.276019133931108, 'ACC-bridge, span': 14.466253437559025, 'ACC-bookcase': 69.37746436927445, 'ACC-blind, screen': 0.0, 'ACC-coffee table': 21.22754310792989, 'ACC-toilet, can, commode, crapper, pot, potty, stool, throne': 67.75657154919557, 'ACC-flower': 22.76775338062668, 'ACC-book': 30.73272786596057, 'ACC-hill': 10.165234472399092, 'ACC-bench': 21.7709778608916, 'ACC-countertop': 13.301002249150335, 'ACC-stove': 0.09819046822869563, 'ACC-palm, palm tree': 25.520298949141925, 'ACC-kitchen island': 69.95986133917168, 'ACC-computer': 0.0, 'ACC-swivel chair': 25.183113220401733, 'ACC-boat': 84.11452111945647, 'ACC-bar': 2.7269765701604993, 'ACC-arcade machine': 0.0, 'ACC-hovel, hut, hutch, shack, shanty': 39.298730366232896, 'ACC-bus': 77.47583271729297, 'ACC-towel': 6.835536590431543, 'ACC-light': 3.0024684490491254, 'ACC-truck': 3.164549816539656, 'ACC-tower': 22.96709115983768, 'ACC-chandelier': 34.289355942201496, 'ACC-awning, sunshade, sunblind': 0.0, 'ACC-street lamp': 3.7777483335711524, 'ACC-booth': 13.947232390577364, 'ACC-tv': 41.11880900269335, 'ACC-plane': 61.8769518650324, 'ACC-dirt track': 0.0, 'ACC-clothes': 2.2828247220922244, 'ACC-pole': 0.43783610684746965, 'ACC-land, ground, soil': 10.344381283715922, 'ACC-bannister, banister, balustrade, balusters, handrail': 0.0, 'ACC-escalator, moving staircase, moving stairway': 58.45370540122414, 'ACC-ottoman, pouf, pouffe, puff, hassock': 0.3631327561012846, 'ACC-bottle': 20.702637359164388, 'ACC-buffet, counter, sideboard': 0.0, 'ACC-poster, posting, placard, notice, bill, card': 0.0, 'ACC-stage': 0.0, 'ACC-van': 42.61101337002219, 'ACC-ship': 0.0, 'ACC-fountain': 62.11528787366617, 'ACC-conveyer belt, conveyor belt, conveyer, conveyor, transporter': 0.0, 'ACC-canopy': 6.411646503515048, 'ACC-washer, automatic washer, washing machine': 4.809374946907015, 'ACC-plaything, toy': 8.361669019969455, 'ACC-pool': 91.55733722060253, 'ACC-stool': 17.067223794935433, 'ACC-barrel, cask': 0.0, 'ACC-basket, handbasket': 0.035712839317995224, 'ACC-falls': 0.0, 'ACC-tent': 19.42743458937551, 'ACC-bag': 1.3180064931633917, 'ACC-minibike, motorbike': 30.738421245842716, 'ACC-cradle': 35.29444974799577, 'ACC-oven': 28.857950672758943, 'ACC-ball': 20.197977086429223, 'ACC-food, solid food': 25.981751351016193, 'ACC-step, stair': 0.0, 'ACC-tank, storage tank': 0.0, 'ACC-trade name': 0.0, 'ACC-microwave': 63.151715578426874, 'ACC-pot': 23.158012614859384, 'ACC-animal': 59.1267227014161, 'ACC-bicycle': 72.45269857877757, 'ACC-lake': 33.692476723951785, 'ACC-dishwasher': 0.0, 'ACC-screen': 20.51865095851386, 'ACC-blanket, cover': 0.0, 'ACC-sculpture': 15.453756610291588, 'ACC-hood, exhaust hood': 0.0, 'ACC-sconce': 54.12685797385731, 'ACC-vase': 13.072311528463048, 'ACC-traffic light': 16.610066707095207, 'ACC-tray': 11.090627225876734, 'ACC-trash can': 2.0479641702794233, 'ACC-fan': 0.0, 'ACC-pier': 86.80127464759335, 'ACC-crt screen': 0.0, 'ACC-plate': 23.459052716808966, 'ACC-monitor': 76.28481156680496, 'ACC-bulletin board': 0.0, 'ACC-shower': 0.0, 'ACC-radiator': 8.982941161243561, 'ACC-glass, drinking glass': 0.0, 'ACC-clock': 5.096719135217144, 'ACC-flag': 22.09179186186348})])
[12/13 00:42:43 d2.engine.defaults]: Evaluation results for ade20k_sem_seg_val in csv format:
[12/13 00:42:43 d2.evaluation.testing]: copypaste: Task: sem_seg
[12/13 00:42:43 d2.evaluation.testing]: copypaste: mIoU,fwIoU,mACC,pACC
[12/13 00:42:43 d2.evaluation.testing]: copypaste: 13.1750,42.5947,25.1552,53.3613
[12/13 00:42:43 d2.data.datasets.coco]: Loaded 2000 images with semantic segmentation from datasets/ADE20K_2021_17_01/images_detectron2/validation
[12/13 00:42:43 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=2560, sample_style='choice')]
[12/13 00:42:43 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[12/13 00:42:43 d2.data.common]: Serializing 2000 elements to byte tensors and concatenating them all ...
[12/13 00:42:43 d2.data.common]: Serialized dataset takes 0.50 MiB
[12/13 00:42:43 d2.data.datasets.coco]: Loaded 2000 images with semantic segmentation from datasets/ADE20K_2021_17_01/images_detectron2/validation
WARNING [12/13 00:42:43 d2.evaluation.sem_seg_evaluation]: SemSegEvaluator(num_classes) is more than supported value for Boundary IoU calculation!
                B-IoU metrics are not going to be computed. Max allowed value (exclusive)
                for num_classes for calculating Boundary IoU is 255.
                The number of classes of dataset ade20k_full_sem_seg_val is 847
[12/13 00:42:43 d2.evaluation.evaluator]: Start inference on 1000 batches
[12/13 00:42:54 d2.evaluation.evaluator]: Inference done 1/1000. Dataloading: 3.0938 s/iter. Inference: 7.6248 s/iter. Eval: 0.0274 s/iter. Total: 10.7494 s/iter. ETA=2:58:58
[12/13 00:42:59 d2.evaluation.evaluator]: Inference done 58/1000. Dataloading: 0.0019 s/iter. Inference: 0.0724 s/iter. Eval: 0.0150 s/iter. Total: 0.0894 s/iter. ETA=0:01:24
[12/13 00:43:04 d2.evaluation.evaluator]: Inference done 113/1000. Dataloading: 0.0019 s/iter. Inference: 0.0741 s/iter. Eval: 0.0148 s/iter. Total: 0.0909 s/iter. ETA=0:01:20
[12/13 00:43:09 d2.evaluation.evaluator]: Inference done 160/1000. Dataloading: 0.0019 s/iter. Inference: 0.0778 s/iter. Eval: 0.0160 s/iter. Total: 0.0957 s/iter. ETA=0:01:20
[12/13 00:43:14 d2.evaluation.evaluator]: Inference done 207/1000. Dataloading: 0.0019 s/iter. Inference: 0.0813 s/iter. Eval: 0.0157 s/iter. Total: 0.0990 s/iter. ETA=0:01:18
[12/13 00:43:19 d2.evaluation.evaluator]: Inference done 259/1000. Dataloading: 0.0019 s/iter. Inference: 0.0813 s/iter. Eval: 0.0152 s/iter. Total: 0.0985 s/iter. ETA=0:01:12
[12/13 00:43:24 d2.evaluation.evaluator]: Inference done 311/1000. Dataloading: 0.0019 s/iter. Inference: 0.0808 s/iter. Eval: 0.0156 s/iter. Total: 0.0983 s/iter. ETA=0:01:07
[12/13 00:43:29 d2.evaluation.evaluator]: Inference done 364/1000. Dataloading: 0.0019 s/iter. Inference: 0.0804 s/iter. Eval: 0.0155 s/iter. Total: 0.0979 s/iter. ETA=0:01:02
[12/13 00:43:34 d2.evaluation.evaluator]: Inference done 413/1000. Dataloading: 0.0019 s/iter. Inference: 0.0812 s/iter. Eval: 0.0152 s/iter. Total: 0.0984 s/iter. ETA=0:00:57
[12/13 00:43:39 d2.evaluation.evaluator]: Inference done 465/1000. Dataloading: 0.0019 s/iter. Inference: 0.0812 s/iter. Eval: 0.0151 s/iter. Total: 0.0982 s/iter. ETA=0:00:52
[12/13 00:43:44 d2.evaluation.evaluator]: Inference done 518/1000. Dataloading: 0.0019 s/iter. Inference: 0.0807 s/iter. Eval: 0.0153 s/iter. Total: 0.0980 s/iter. ETA=0:00:47
[12/13 00:43:49 d2.evaluation.evaluator]: Inference done 570/1000. Dataloading: 0.0019 s/iter. Inference: 0.0806 s/iter. Eval: 0.0154 s/iter. Total: 0.0980 s/iter. ETA=0:00:42
[12/13 00:43:54 d2.evaluation.evaluator]: Inference done 625/1000. Dataloading: 0.0019 s/iter. Inference: 0.0799 s/iter. Eval: 0.0155 s/iter. Total: 0.0973 s/iter. ETA=0:00:36
[12/13 00:44:10 d2.evaluation.evaluator]: Inference done 671/1000. Dataloading: 0.0019 s/iter. Inference: 0.0966 s/iter. Eval: 0.0152 s/iter. Total: 0.1138 s/iter. ETA=0:00:37
[12/13 00:44:15 d2.evaluation.evaluator]: Inference done 730/1000. Dataloading: 0.0019 s/iter. Inference: 0.0944 s/iter. Eval: 0.0151 s/iter. Total: 0.1115 s/iter. ETA=0:00:30
[12/13 00:44:20 d2.evaluation.evaluator]: Inference done 778/1000. Dataloading: 0.0019 s/iter. Inference: 0.0943 s/iter. Eval: 0.0148 s/iter. Total: 0.1111 s/iter. ETA=0:00:24
[12/13 00:44:25 d2.evaluation.evaluator]: Inference done 835/1000. Dataloading: 0.0019 s/iter. Inference: 0.0923 s/iter. Eval: 0.0152 s/iter. Total: 0.1095 s/iter. ETA=0:00:18
[12/13 00:44:30 d2.evaluation.evaluator]: Inference done 883/1000. Dataloading: 0.0019 s/iter. Inference: 0.0921 s/iter. Eval: 0.0152 s/iter. Total: 0.1093 s/iter. ETA=0:00:12
[12/13 00:44:35 d2.evaluation.evaluator]: Inference done 938/1000. Dataloading: 0.0019 s/iter. Inference: 0.0912 s/iter. Eval: 0.0150 s/iter. Total: 0.1082 s/iter. ETA=0:00:06
[12/13 00:44:40 d2.evaluation.evaluator]: Inference done 988/1000. Dataloading: 0.0019 s/iter. Inference: 0.0909 s/iter. Eval: 0.0150 s/iter. Total: 0.1079 s/iter. ETA=0:00:01
[12/13 00:44:42 d2.evaluation.evaluator]: Total inference time: 0:01:47.893561 (0.108436 s / iter per device, on 2 devices)
[12/13 00:44:42 d2.evaluation.evaluator]: Total inference pure compute time: 0:01:30 (0.090820 s / iter per device, on 2 devices)
[12/13 00:44:43 d2.evaluation.sem_seg_evaluation]: OrderedDict([('sem_seg', {'mIoU': 3.259816343825651, 'fwIoU': 31.867016525272284, 'IoU-wall': 42.519565285101905, 'IoU-building, edifice': 22.928519076762104, 'IoU-sky': 89.66484910786777, 'IoU-tree': 60.362575240999035, 'IoU-road, route': 41.469224423883475, 'IoU-floor, flooring': 43.96236132624512, 'IoU-ceiling': 48.4041971417864, 'IoU-bed': 28.861962327590373, 'IoU-sidewalk, pavement': 31.816981364675634, 'IoU-earth, ground': 0.0, 'IoU-cabinet': 10.546444020821898, 'IoU-person, individual, someone, somebody, mortal, soul': 45.83582212513538, 'IoU-grass': 54.93217986017027, 'IoU-windowpane, window': 0.1526037032524855, 'IoU-car, auto, automobile, machine, motorcar': 3.780859800871425, 'IoU-mountain, mount': 15.91565046080507, 'IoU-plant, flora, plant life': 12.369889731557112, 'IoU-table': 7.249654118699827, 'IoU-chair': 18.54455800288302, 'IoU-curtain, drape, drapery, mantle, pall': 0.002398058730112134, 'IoU-door': 0.7709013375800761, 'IoU-sofa, couch, lounge': 10.80925515081073, 'IoU-sea': 19.55577087852461, 'IoU-painting, picture': 0.20716604930440444, 'IoU-water': 3.2882322772036114, 'IoU-mirror': 7.176481012893904, 'IoU-house': 8.406083236536874, 'IoU-rug, carpet, carpeting': 13.781637549921685, 'IoU-shelf': 10.097499858924147, 'IoU-armchair': 6.846058928768192, 'IoU-fence, fencing': 14.261457961207894, 'IoU-field': 1.993288722498993, 'IoU-lamp': 1.142787631401993, 'IoU-rock, stone': 22.206976261418813, 'IoU-seat': 6.152794694200569, 'IoU-river': 7.249936394268658, 'IoU-desk': 6.985371505111211, 'IoU-bathtub, bathing tub, bath, tub': 14.04575551524007, 'IoU-railing, rail': 4.698498458309819, 'IoU-signboard, sign': 2.720994927776341, 'IoU-cushion': 0.8157075888778327, 'IoU-path': 0.14841936872761896, 'IoU-work surface': 0.0, 'IoU-stairs, steps': 19.785094833134348, 'IoU-column, pillar': 0.5068028856601845, 'IoU-sink': 9.158359245235886, 'IoU-wardrobe, closet, press': 4.561478756659508, 'IoU-snow': 16.798346142939366, 'IoU-refrigerator, icebox': 0.4312302530088651, 'IoU-base, pedestal, stand': 0.0, 'IoU-bridge, span': 2.4855615241022013, 'IoU-blind, screen': 0.0, 'IoU-runway': 35.47486521152694, 'IoU-cliff, drop, drop-off': 0.9667605633802817, 'IoU-sand': 21.09101655219932, 'IoU-fireplace, hearth, open fireplace': 3.807759857381164, 'IoU-pillow': 0.0, 'IoU-screen door, screen': 0.0, 'IoU-toilet, can, commode, crapper, pot, potty, stool, throne': 11.221587795869596, 'IoU-skyscraper': 45.794688106520525, 'IoU-grandstand, covered stand': 35.434128321044426, 'IoU-box': 0.0, 'IoU-pool table, billiard table, snooker table': 0.0, 'IoU-palm, palm tree': 19.69245186573522, 'IoU-double door': 1.4659429831125363, 'IoU-coffee table, cocktail table': 0.022764322236569365, 'IoU-counter': 7.481362852019354, 'IoU-countertop': 1.0962573650449499, 'IoU-chest of drawers, chest, bureau, dresser': 9.946483005202724, 'IoU-kitchen island': 2.3802514645938415, 'IoU-boat': 35.57682009485742, 'IoU-waterfall, falls': 4.433180395977562, 'IoU-stove, kitchen stove, range, kitchen range, cooking stove': 0.0, 'IoU-flower': 8.912537467837343, 'IoU-bookcase': 4.712572310852589, 'IoU-controls': 0.0, 'IoU-book': 13.160106893599357, 'IoU-stairway, staircase': 0.0, 'IoU-streetlight, street lamp': 1.9519655242334444, 'IoU-computer, computing machine, computing device, data processor, electronic computer, information processing system': 0.0, 'IoU-bus, autobus, coach, charabanc, double-decker, jitney, motorbus, motorcoach, omnibus, passenger vehicle': 34.062579378824616, 'IoU-swivel chair': 5.919677845027094, 'IoU-light, light source': 0.0, 'IoU-bench': 4.551099484539707, 'IoU-case, display case, showcase, vitrine': 0.0, 'IoU-towel': 0.02186169911284685, 'IoU-fountain': 48.353065106991814, 'IoU-embankment': 0.0, 'IoU-television receiver, television, television set, tv, tv set, idiot box, boob tube, telly, goggle box': 3.924210484448334, 'IoU-van': 3.9431188532750285, 'IoU-hill': 5.106466288560231, 'IoU-awning, sunshade, sunblind': 0.0, 'IoU-poster, posting, placard, notice, bill, card': 0.0, 'IoU-truck, motortruck': 0.014995324986915843, 'IoU-airplane, aeroplane, plane': 46.773579551353485, 'IoU-pole': 0.3438054745885292, 'IoU-tower': 4.4575717300535285, 'IoU-court': 28.389683027558682, 'IoU-ball': 0.0, 'IoU-aircraft carrier, carrier, flattop, attack aircraft carrier': 0.0, 'IoU-buffet, counter, sideboard': 0.0, 'IoU-hovel, hut, hutch, shack, shanty': 0.0, 'IoU-apparel, wearing apparel, dress, clothes': 0.0, 'IoU-minibike, motorbike': 32.684458235281866, 'IoU-animal, animate being, beast, brute, creature, fauna': 26.58296162791868, 'IoU-chandelier, pendant, pendent': 16.75357375572163, 'IoU-step, stair': 0.0, 'IoU-booth, cubicle, stall, kiosk': 1.072431429161557, 'IoU-bicycle, bike, wheel, cycle': 36.44741061650259, 'IoU-doorframe, doorcase': 0.22093912957972398, 'IoU-sconce': 3.280867545490241, 'IoU-pond': 4.967678098422702, 'IoU-trade name, brand name, brand, marque': 0.0, 'IoU-bannister, banister, balustrade, balusters, handrail': 0.0, 'IoU-bag': 0.0, 'IoU-traffic light, traffic signal, stoplight': 12.346262669675156, 'IoU-gazebo': 0.4650879746906678, 'IoU-escalator, moving staircase, moving stairway': 3.5120762560022936, 'IoU-land, ground, soil': 0.15393019850778827, 'IoU-board, plank': 0.0, 'IoU-arcade machine': 0.0, 'IoU-eiderdown, duvet, continental quilt': 1.7941253899140344, 'IoU-bar': 2.2257241018662737, 'IoU-stall, stand, sales booth': 0.0, 'IoU-playground': 0.0, 'IoU-ship': 0.0, 'IoU-ottoman, pouf, pouffe, puff, hassock': 1.008379974643619, 'IoU-ashcan, trash can, garbage can, wastebin, ash bin, ash-bin, ashbin, dustbin, trash barrel, trash bin': 0.0, 'IoU-bottle': 8.633852313931706, 'IoU-cradle': 13.556964531374529, 'IoU-pot, flowerpot': 3.7469782319191216, 'IoU-conveyer belt, conveyor belt, conveyer, conveyor, transporter': 0.0, 'IoU-train, railroad train': 41.38214987014632, 'IoU-stool': 2.426137516623985, 'IoU-lake': 1.667763264154183, 'IoU-tank, storage tank': 0.0, 'IoU-ice, water ice': 0.0, 'IoU-basket, handbasket': 0.0, 'IoU-manhole': 0.0, 'IoU-tent, collapsible shelter': 13.957024763554978, 'IoU-canopy': 0.0, 'IoU-microwave, microwave oven': 51.679960925162874, 'IoU-barrel, cask': 0.0, 'IoU-dirt track': 0.0, 'IoU-beam': 0.0, 'IoU-dishwasher, dish washer, dishwashing machine': 0.0, 'IoU-plate': 0.0, 'IoU-screen, crt screen': 0.0, 'IoU-ruins': 0.0, 'IoU-washer, automatic washer, washing machine': 0.0, 'IoU-blanket, cover': 0.0, 'IoU-plaything, toy': 0.4049394082769615, 'IoU-food, solid food': 3.322181313601828, 'IoU-screen, silver screen, projection screen': 19.343908580145985, 'IoU-oven': 4.029642590450532, 'IoU-stage': 0.0, 'IoU-beacon, lighthouse, beacon light, pharos': 22.181163102221813, 'IoU-umbrella': 17.016997082516006, 'IoU-sculpture': 0.0, 'IoU-aqueduct': 0.0, 'IoU-container': 0.0, 'IoU-scaffolding, staging': 0.0, 'IoU-hood, exhaust hood': 0.0, 'IoU-curb, curbing, kerb': 0.0, 'IoU-roller coaster': 0.0, 'IoU-horse, equus caballus': 0.0, 'IoU-catwalk': 0.0, 'IoU-glass, drinking glass': 0.0, 'IoU-vase': 0.0005743693424619768, 'IoU-central reservation': 0.0, 'IoU-carousel': 59.195557963163594, 'IoU-radiator': 8.81359932680664, 'IoU-closet': 0.0, 'IoU-machine': 0.0, 'IoU-pier, wharf, wharfage, dock': 0.0, 'IoU-fan': 0.0, 'IoU-inflatable bounce game': 0.0, 'IoU-pitch': 10.065543587312439, 'IoU-paper': 0.0, 'IoU-arcade, colonnade': 0.0, 'IoU-hot tub': 0.0, 'IoU-helicopter': 75.9595761930055, 'IoU-tray': 4.2390217792453155, 'IoU-partition, divider': 0.0, 'IoU-vineyard': 7.645151075051595, 'IoU-bowl': 0.49017466113243663, 'IoU-bullring': 0.0, 'IoU-flag': 13.86295224542266, 'IoU-pot': 0.24232137744877508, 'IoU-footbridge, overcrossing, pedestrian bridge': 0.0, 'IoU-shower': 0.0, 'IoU-bag, traveling bag, travelling bag, grip, suitcase': 27.115564609370697, 'IoU-bulletin board, notice board': 0.0, 'IoU-confessional booth': 0.0, 'IoU-trunk, tree trunk, bole': 0.0, 'IoU-forest': 0.0, 'IoU-elevator door': 0.0, 'IoU-laptop, laptop computer': 0.0, 'IoU-instrument panel': 0.0, 'IoU-bucket, pail': 0.0, 'IoU-tapestry, tapis': 0.0, 'IoU-platform': 0.0, 'IoU-jacket': 0.0, 'IoU-gate': 0.0010939281517934702, 'IoU-monitor, monitoring device': 0.0, 'IoU-telephone booth, phone booth, call box, telephone box, telephone kiosk': 34.44976076555024, 'IoU-spotlight, spot': 1.5542873628503684, 'IoU-ring': 0.0, 'IoU-control panel': 0.0, 'IoU-blackboard, chalkboard': 0.0, 'IoU-air conditioner, air conditioning': 0.0, 'IoU-chest': 0.0, 'IoU-clock': 3.8421708386595683, 'IoU-sand dune': 0.0, 'IoU-pipe, pipage, piping': 0.0, 'IoU-vault': 0.0, 'IoU-table football': 0.0, 'IoU-cannon': 0.0, 'IoU-swimming pool, swimming bath, natatorium': 0.0, 'IoU-fluorescent, fluorescent fixture': 0.0, 'IoU-statue': 0.0, 'IoU-loudspeaker, speaker, speaker unit, loudspeaker system, speaker system': 0.0, 'IoU-exhibitor': 0.0, 'IoU-ladder': 0.0, 'IoU-carport': 2.334263160121613, 'IoU-dam': 0.0, 'IoU-pulpit': 10.389160752059382, 'IoU-skylight, fanlight': 5.639066575679692, 'IoU-water tower': 20.57952257693414, 'IoU-grill, grille, grillwork': 0.0, 'IoU-display board': 0.0, 'IoU-pane, pane of glass, window glass': 0.0, 'IoU-rubbish, trash, scrap': 0.0, 'IoU-ice rink': 0.0, 'IoU-fruit': 0.7518719285644155, 'IoU-patio': 0.0, 'IoU-vending machine': 0.0, 'IoU-telephone, phone, telephone set': 0.0, 'IoU-net': 0.0, 'IoU-backpack, back pack, knapsack, packsack, rucksack, haversack': 10.96544570038632, 'IoU-jar': 0.0, 'IoU-track': 0.0, 'IoU-magazine': 0.0, 'IoU-shutter': 0.0, 'IoU-roof': 0.0, 'IoU-banner, streamer': 0.0, 'IoU-landfill': 0.0, 'IoU-post': 0.0, 'IoU-altarpiece, reredos': 0.0, 'IoU-hat, chapeau, lid': 2.922354772213622, 'IoU-arch, archway': 0.0, 'IoU-table game': 0.0, 'IoU-bag, handbag, pocketbook, purse': 2.435569968303892, 'IoU-document, written document, papers': 0.0, 'IoU-dome': 0.0, 'IoU-pier': 1.468160973858863, 'IoU-shanties': 0.0, 'IoU-forecourt': 0.0, 'IoU-crane': 0.0, 'IoU-dog, domestic dog, canis familiaris': 39.796482689967924, 'IoU-piano, pianoforte, forte-piano': 0.0, 'IoU-drawing': 0.0, 'IoU-cabin': 0.0, 'IoU-ad, advertisement, advertizement, advertising, advertizing, advert': 0.0, 'IoU-amphitheater, amphitheatre, coliseum': 0.0, 'IoU-monument': 0.0, 'IoU-henhouse': 0.0, 'IoU-cockpit': 18.121961351356436, 'IoU-heater, warmer': 0.0, 'IoU-windmill, aerogenerator, wind generator': 12.15173904372307, 'IoU-pool': 0.0, 'IoU-elevator, lift': 0.0, 'IoU-decoration, ornament, ornamentation': 0.0, 'IoU-labyrinth': 95.43185060303463, 'IoU-text, textual matter': 0.0, 'IoU-printer': 0.0, 'IoU-mezzanine, first balcony': 0.0, 'IoU-mattress': 0.0, 'IoU-straw': 0.0, 'IoU-stalls': 0.0, 'IoU-patio, terrace': 0.0, 'IoU-billboard, hoarding': 0.0, 'IoU-bus stop': 0.12071457487074268, 'IoU-trouser, pant': 0.0, 'IoU-console table, console': 0.0, 'IoU-rack': 0.0, 'IoU-notebook': 0.0, 'IoU-shrine': 26.514932779933233, 'IoU-pantry': 24.860381200497088, 'IoU-cart': 0.0, 'IoU-steam shovel': 72.32260907888937, 'IoU-porch': 0.0, 'IoU-postbox, mailbox, letter box': 0.0, 'IoU-figurine, statuette': 0.0, 'IoU-recycling bin': 0.0, 'IoU-folding screen': 0.0, 'IoU-telescope': 0.0, 'IoU-deck chair, beach chair': 2.7678857621900748, 'IoU-kennel': 0.0, 'IoU-coffee maker': 0.0, "IoU-altar, communion table, lord's table": 0.1985876667337884, 'IoU-fish': 4.748286768581972, 'IoU-easel': 0.009086572317757433, 'IoU-artificial golf green': 6.4386627880633265, 'IoU-iceberg': 0.0, 'IoU-candlestick, candle holder': 0.4867614363673112, 'IoU-shower stall, shower bath': 0.0, 'IoU-television stand': 0.0, 'IoU-wall socket, wall plug, electric outlet, electrical outlet, outlet, electric receptacle': 0.0, 'IoU-skeleton': 0.0, 'IoU-grand piano, grand': 0.0, 'IoU-candy, confect': 0.0, 'IoU-grille door': 0.0, 'IoU-pedestal, plinth, footstall': 0.0, 'IoU-jersey, t-shirt, tee shirt': 0.0, 'IoU-shoe': 16.01429608959902, 'IoU-gravestone, headstone, tombstone': 0.0, 'IoU-shanty': 2.4441143845531967, 'IoU-structure': 0.0, 'IoU-rocking chair, rocker': 0.0, 'IoU-bird': 0.0, 'IoU-place mat': 0.0, 'IoU-tomb': 0.0, 'IoU-big top': 0.0, 'IoU-gas pump, gasoline pump, petrol pump, island dispenser': 0.0, 'IoU-lockers': 22.844125038164353, 'IoU-cage': 0.0, 'IoU-finger': 0.0, 'IoU-bleachers': 0.0, 'IoU-ferris wheel': 0.0, 'IoU-hairdresser chair': 0.0, 'IoU-mat': 0.0, 'IoU-stands': 0.0, 'IoU-aquarium, fish tank, marine museum': 0.0, 'IoU-streetcar, tram, tramcar, trolley, trolley car': 0.0, 'IoU-napkin, table napkin, serviette': 2.553449139802906, 'IoU-dummy': 0.0, 'IoU-booklet, brochure, folder, leaflet, pamphlet': 0.0, 'IoU-sand trap': 0.0, 'IoU-shop, store': 0.0, 'IoU-table cloth': 0.0, 'IoU-service station': 0.0, 'IoU-coffin': 0.0, 'IoU-drawer': 0.0, 'IoU-cages': 0.0, 'IoU-slot machine, coin machine': 0.0, 'IoU-balcony': 0.0, 'IoU-volleyball court': 0.0, 'IoU-table tennis': 0.0, 'IoU-control table': 0.0, 'IoU-shirt': 0.0, 'IoU-merchandise, ware, product': 0.0, 'IoU-railway': 30.699866288360568, 'IoU-parterre': 0.0, 'IoU-chimney': 3.095693284390519, 'IoU-can, tin, tin can': 2.4588832487309644, 'IoU-tanks': 0.0, 'IoU-fabric, cloth, material, textile': 0.0, 'IoU-alga, algae': 0.0, 'IoU-system': 0.0, 'IoU-map': 0.0, 'IoU-greenhouse': 2.427066009437964, 'IoU-mug': 1.1143127732887341, 'IoU-barbecue': 0.0, 'IoU-trailer': 0.0, 'IoU-toilet tissue, toilet paper, bathroom tissue': 1.1020031316477334, 'IoU-organ': 0.0, 'IoU-dishrag, dishcloth': 0.0, 'IoU-island': 2.815207296091597, 'IoU-keyboard': 11.48010652893229, 'IoU-trench': 0.0, 'IoU-basket, basketball hoop, hoop': 0.0, 'IoU-steering wheel, wheel': 21.70822919444565, 'IoU-pitcher, ewer': 0.0, 'IoU-goal': 0.0, 'IoU-bread, breadstuff, staff of life': 0.0, 'IoU-beds': 0.0, 'IoU-wood': 0.0, 'IoU-file cabinet': 0.0, 'IoU-newspaper, paper': 0.0, 'IoU-motorboat': 0.0, 'IoU-rope': 0.0, 'IoU-guitar': 13.14808539478143, 'IoU-rubble': 0.0, 'IoU-scarf': 0.0, 'IoU-barrels': 0.0, 'IoU-cap': 0.0, 'IoU-leaves': 0.0, 'IoU-control tower': 0.0, 'IoU-dashboard': 0.0, 'IoU-bandstand': 0.006612867685589416, 'IoU-lectern': 0.0, 'IoU-switch, electric switch, electrical switch': 0.0, 'IoU-baseboard, mopboard, skirting board': 0.0, 'IoU-shower room': 0.0, 'IoU-smoke': 0.0, 'IoU-faucet, spigot': 0.0, 'IoU-bulldozer': 86.13735668670874, 'IoU-saucepan': 0.0, 'IoU-shops': 0.0, 'IoU-meter': 0.0, 'IoU-crevasse': 0.0, 'IoU-gear': 0.0, 'IoU-candelabrum, candelabra': 0.0, 'IoU-sofa bed': 0.0, 'IoU-tunnel': 0.0, 'IoU-pallet': 0.0, 'IoU-wire, conducting wire': 0.0, 'IoU-kettle, boiler': 0.0, 'IoU-bidet': 0.0, 'IoU-baby buggy, baby carriage, carriage, perambulator, pram, stroller, go-cart, pushchair, pusher': 0.0, 'IoU-music stand': 0.0, 'IoU-pipe, tube': 0.0, 'IoU-cup': 0.0, 'IoU-parking meter': 0.0, 'IoU-ice hockey rink': 0.0, 'IoU-shelter': 0.0, 'IoU-weeds': 0.0, 'IoU-temple': 0.0, 'IoU-patty, cake': 11.436786199185368, 'IoU-ski slope': 0.0034476814342354768, 'IoU-panel': 0.0, 'IoU-wallet': 0.0, 'IoU-wheel': 0.0, 'IoU-towel rack, towel horse': 0.0, 'IoU-roundabout': 0.0, 'IoU-canister, cannister, tin': 0.0, 'IoU-rod': 0.0, 'IoU-soap dispenser': 0.0, 'IoU-bell': 0.0, 'IoU-canvas': 0.0, 'IoU-box office, ticket office, ticket booth': 0.0, 'IoU-teacup': 0.03379722833465987, 'IoU-trellis': 0.002921765955843438, 'IoU-workbench': 0.0, 'IoU-valley, vale': 0.0, 'IoU-toaster': 0.0, 'IoU-knife': 0.0, 'IoU-podium': 0.0, 'IoU-ramp': 1.0812875109046047, 'IoU-tumble dryer': 0.0, 'IoU-fireplug, fire hydrant, plug': 0.0, 'IoU-gym shoe, sneaker, tennis shoe': 0.0, 'IoU-lab bench': 0.0, 'IoU-equipment': 0.0, 'IoU-rocky formation': 0.0, 'IoU-plastic': 0.0, 'IoU-calendar': 0.0, 'IoU-caravan': 0.0, 'IoU-check-in-desk': 0.0, 'IoU-ticket counter': 0.0, 'IoU-brush': 0.0, 'IoU-mill': 0.0, 'IoU-covered bridge': 0.0, 'IoU-bowling alley': 0.0, 'IoU-hanger': 0.0, 'IoU-excavator': 0.0, 'IoU-trestle': 0.0, 'IoU-revolving door': 0.0, 'IoU-blast furnace': 0.0, 'IoU-scale, weighing machine': 0.0, 'IoU-projector': 0.0, 'IoU-soap': 0.0, 'IoU-locker': 0.0, 'IoU-tractor': 0.0, 'IoU-stretcher': 0.0, 'IoU-frame': 0.0, 'IoU-grating': 0.0, 'IoU-alembic': 0.0, 'IoU-candle, taper, wax light': 37.793597015493546, 'IoU-barrier': 0.0, 'IoU-cardboard': 0.0, 'IoU-cave': 0.0, 'IoU-puddle': 0.0, 'IoU-tarp': 0.0, 'IoU-price tag': 0.0, 'IoU-watchtower': 5.935880373508185, 'IoU-meters': 0.0, 'IoU-light bulb, lightbulb, bulb, incandescent lamp, electric light, electric-light bulb': 0.0, 'IoU-tracks': 0.0, 'IoU-hair dryer': 0.0, 'IoU-skirt': 0.0, 'IoU-viaduct': 0.0, 'IoU-paper towel': 0.0, 'IoU-coat': 0.0, 'IoU-sheet': 0.0, 'IoU-fire extinguisher, extinguisher, asphyxiator': 0.0, 'IoU-water wheel': 0.0, 'IoU-pottery, clayware': 0.0, 'IoU-magazine rack': 0.0, 'IoU-teapot': 0.0, 'IoU-microphone, mike': 0.0, 'IoU-support': 0.0, 'IoU-forklift': 38.45447978289307, 'IoU-canyon': 0.0, 'IoU-cash register, register': 0.0, 'IoU-leaf, leafage, foliage': 0.0, 'IoU-remote control, remote': 9.767499077377291, 'IoU-soap dish': 0.0, 'IoU-windshield, windscreen': 0.0, 'IoU-cat': 1.204867133607849, 'IoU-cue, cue stick, pool cue, pool stick': 0.0, 'IoU-vent, venthole, vent-hole, blowhole': 0.0, 'IoU-videos': 0.0, 'IoU-shovel': 0.0, 'IoU-eaves': 0.0, 'IoU-antenna, aerial, transmitting aerial': 0.0, 'IoU-shipyard': 0.0, 'IoU-hen, biddy': 21.57596698339572, 'IoU-traffic cone': 2.3357253412128887, 'IoU-washing machines': 0.0, 'IoU-truck crane': 0.0, 'IoU-cds': 0.0, 'IoU-niche': 0.0, 'IoU-scoreboard': 0.0, 'IoU-briefcase': 0.0, 'IoU-boot': 0.0, 'IoU-sweater, jumper': 0.0, 'IoU-hay': 0.0, 'IoU-pack': 0.0, 'IoU-bottle rack': 0.0, 'IoU-glacier': 0.0, 'IoU-pergola': 0.0, 'IoU-building materials': 0.0, 'IoU-television camera': 0.0, 'IoU-first floor': 0.0, 'IoU-rifle': 0.0, 'IoU-tennis table': 0.0, 'IoU-stadium': 0.0, 'IoU-safety belt': 0.0, 'IoU-cover': 0.0, 'IoU-dish rack': 0.0, 'IoU-synthesizer': 0.0, 'IoU-pumpkin': 0.0, 'IoU-gutter': 0.0, 'IoU-fruit stand': 6.052294942921898, 'IoU-ice floe, floe': 0.0, 'IoU-handle, grip, handgrip, hold': 0.0, 'IoU-wheelchair': 0.0, 'IoU-mousepad, mouse mat': 0.0, 'IoU-diploma': 0.0, 'IoU-fairground ride': 29.19819653544968, 'IoU-radio': 0.0, 'IoU-hotplate': 0.0, 'IoU-junk': 0.0, 'IoU-wheelbarrow': 0.0, 'IoU-stream': 0.0, 'IoU-toll plaza': 0.0, 'IoU-punching bag': 0.0, 'IoU-trough': 0.0, 'IoU-throne': 0.0, 'IoU-chair desk': 0.9264300198375373, 'IoU-weighbridge': 12.747568170945623, 'IoU-extractor fan': 0.0, 'IoU-hanging clothes': 0.0, 'IoU-dish, dish aerial, dish antenna, saucer': 0.0, 'IoU-alarm clock, alarm': 0.0, 'IoU-ski lift': 4.43661971830986, 'IoU-chain': 0.0, 'IoU-garage': 0.0, 'IoU-mechanical shovel': 0.0, 'IoU-wine rack': 0.0, 'IoU-tramway': 0.7229546843621758, 'IoU-treadmill': 0.0, 'IoU-menu': 0.0, 'IoU-block': 0.0, 'IoU-well': 0.0, 'IoU-witness stand': 0.0, 'IoU-branch': 0.0, 'IoU-duck': 0.0, 'IoU-casserole': 0.0, 'IoU-frying pan': 0.0, 'IoU-desk organizer': 0.0, 'IoU-mast': 0.0, 'IoU-spectacles, specs, eyeglasses, glasses': 0.0, 'IoU-service elevator': 0.0, 'IoU-dollhouse': 0.0, 'IoU-hammock': 0.0, 'IoU-clothes hanging': 0.0, 'IoU-photocopier': 0.0, 'IoU-notepad': 0.0, 'IoU-golf cart': 0.0, 'IoU-footpath': 0.0, 'IoU-cross': 0.0, 'IoU-baptismal font': 13.807947393991435, 'IoU-boiler': 0.0, 'IoU-skip': 0.0, 'IoU-rotisserie': 0.0, 'IoU-tables': 0.0, 'IoU-water mill': 0.0, 'IoU-helmet': 0.0, 'IoU-cover curtain': 0.0, 'IoU-brick': 0.0, 'IoU-table runner': 0.0, 'IoU-ashtray': 0.0, 'IoU-street box': 0.0, 'IoU-stick': 0.0, 'IoU-hangers': 0.0, 'IoU-cells': 0.0, 'IoU-urinal': 0.0, 'IoU-centerpiece': 0.0, 'IoU-portable fridge': 0.0, 'IoU-dvds': 0.0, 'IoU-golf club': 0.0, 'IoU-skirting board': 0.0, 'IoU-water cooler': 0.0, 'IoU-clipboard': 0.0, 'IoU-camera, photographic camera': 0.0, 'IoU-pigeonhole': 0.0, 'IoU-chips': 0.0, 'IoU-food processor': 0.0, 'IoU-post box': 9.699228107532607, 'IoU-lid': 0.0, 'IoU-drum': 0.0, 'IoU-blender': 0.0, 'IoU-cave entrance': 0.0, 'IoU-dental chair': 0.0, 'IoU-obelisk': 0.0, 'IoU-canoe': 0.0, 'IoU-mobile': 0.0, 'IoU-monitors': 0.0, 'IoU-pool ball': 0.0, 'IoU-cue rack': 0.0, 'IoU-baggage carts': 0.0, 'IoU-shore': 0.0, 'IoU-fork': 0.0, 'IoU-paper filer': 0.0, 'IoU-bicycle rack': 4.500156841927467, 'IoU-coat rack': 0.0, 'IoU-garland': 0.0, 'IoU-sports bag': 0.0, 'IoU-fish tank': 0.0, 'IoU-towel dispenser': 0.0, 'IoU-carriage': 0.0, 'IoU-brochure': 0.0, 'IoU-plaque': 0.0, 'IoU-stringer': 0.0, 'IoU-iron': 0.0, 'IoU-spoon': 0.0, 'IoU-flag pole': 0.0, 'IoU-toilet brush': 0.0, 'IoU-book stand': 0.0, 'IoU-water faucet, water tap, tap, hydrant': 0.0, 'IoU-ticket office': 0.0, 'IoU-broom': 0.0, 'IoU-dvd': 0.0, 'IoU-ice bucket': 0.0, 'IoU-carapace, shell, cuticle, shield': 0.0, 'IoU-tureen': 0.0, 'IoU-folders': 0.0, 'IoU-chess': 0.0, 'IoU-root': 0.0, 'IoU-sewing machine': 0.0, 'IoU-model': 0.0, 'IoU-pen': 0.0, 'IoU-violin': 0.0, 'IoU-sweatshirt': 0.0, 'IoU-recycling materials': 0.0, 'IoU-mitten': 0.0, 'IoU-chopping board, cutting board': 0.0, 'IoU-mask': 0.0, 'IoU-log': 0.0, 'IoU-mouse, computer mouse': 0.0, 'IoU-grill': 0.0, 'IoU-hole': 0.0, 'IoU-target': 0.0, 'IoU-trash bag': 0.0, 'IoU-chalk': 0.0, 'IoU-sticks': 0.0, 'IoU-balloon': 38.814190831038395, 'IoU-score': 0.0, 'IoU-hair spray': 0.0, 'IoU-roll': 0.0, 'IoU-runner': 0.0, 'IoU-engine': 0.0, 'IoU-inflatable glove': 0.0, 'IoU-games': 0.0, 'IoU-pallets': 23.819737431352678, 'IoU-baskets': 0.0, 'IoU-coop': 0.0, 'IoU-dvd player': 0.0, 'IoU-rocking horse': 0.0, 'IoU-buckets': 0.0, 'IoU-bread rolls': 0.0, 'IoU-shawl': 0.0, 'IoU-watering can': 0.0, 'IoU-spotlights': 0.0, 'IoU-post-it': 0.0, 'IoU-bowls': 0.0, 'IoU-security camera': 0.0, 'IoU-runner cloth': 0.0, 'IoU-lock': 0.0, 'IoU-alarm, warning device, alarm system': 0.0, 'IoU-side': 0.0, 'IoU-roulette': 0.0, 'IoU-bone': 3.9557899553558333, 'IoU-cutlery': 0.0, 'IoU-pool balls': 0.0, 'IoU-wheels': 7.76999213304305, 'IoU-spice rack': 0.0, 'IoU-plant pots': 0.0, 'IoU-towel ring': 0.0, 'IoU-bread box': 0.0, 'IoU-video': 0.0, 'IoU-funfair': 0.0, 'IoU-breads': 0.0, 'IoU-tripod': 12.146964315914087, 'IoU-ironing board': 0.0, 'IoU-skimmer': 0.0, 'IoU-hollow': 0.0, 'IoU-scratching post': 0.0, 'IoU-tricycle': 0.0, 'IoU-file box': 0.0, 'IoU-mountain pass': 0.0, 'IoU-tombstones': 0.0, 'IoU-cooker': 0.0, 'IoU-card game, cards': 0.0, 'IoU-golf bag': 0.09287320363671914, 'IoU-towel paper': 0.0, 'IoU-chaise lounge': 0.21678300908819928, 'IoU-sun': 5.263349337989233, 'IoU-toilet paper holder': 0.0, 'IoU-rake': 0.0, 'IoU-key': 0.0, 'IoU-umbrella stand': 0.0, 'IoU-dartboard': 0.0, 'IoU-transformer': 0.0, 'IoU-fireplace utensils': 0.0, 'IoU-sweatshirts': 0.0, 'IoU-cellular telephone, cellular phone, cellphone, cell, mobile phone': 0.0, 'IoU-tallboy': 0.0, 'IoU-stapler': 0.0, 'IoU-sauna': 0.0, 'IoU-test tube': 0.0, 'IoU-palette': 0.0, 'IoU-shopping carts': 0.0, 'IoU-tools': 0.0, 'IoU-push button, push, button': 0.0, 'IoU-star': 0.0, 'IoU-roof rack': 0.0, 'IoU-barbed wire': 0.0, 'IoU-spray': 0.0, 'IoU-ear': 0.0, 'IoU-sponge': 0.0, 'IoU-racket': 0.0, 'IoU-tins': 0.0, 'IoU-eyeglasses': 0.0, 'IoU-file': 0.0, 'IoU-scarfs': 0.0, 'IoU-sugar bowl': 0.0, 'IoU-flip flop': 0.0, 'IoU-headstones': 16.720473012188044, 'IoU-laptop bag': 0.0, 'IoU-leash': 0.0, 'IoU-climbing frame': 0.0, 'IoU-suit hanger': 0.0, 'IoU-floor spotlight': 0.0, 'IoU-plate rack': 0.0, 'IoU-sewer': 0.0, 'IoU-hard drive': 0.0, 'IoU-sprinkler': 0.0, 'IoU-tools box': 0.0, 'IoU-necklace': 0.0, 'IoU-bulbs': 0.0, 'IoU-steel industry': 0.0, 'IoU-club': 0.0, 'IoU-jack': 0.0, 'IoU-door bars': 17.80548949026162, 'IoU-control panel, instrument panel, control board, board, panel': 0.0, 'IoU-hairbrush': 0.0, 'IoU-napkin holder': 0.0, 'IoU-office': 0.0, 'IoU-smoke detector': 0.0, 'IoU-utensils': 0.0, 'IoU-apron': 0.0, 'IoU-scissors': 0.0, 'IoU-terminal': 0.0, 'IoU-grinder': 0.0, 'IoU-entry phone': 0.0, 'IoU-newspaper stand': 0.0, 'IoU-pepper shaker': 0.0, 'IoU-onions': 0.0, 'IoU-central processing unit, cpu, c p u , central processor, processor, mainframe': 0.0, 'IoU-tape': 0.0, 'IoU-bat': 0.0, 'IoU-coaster': 0.0, 'IoU-calculator': 0.0, 'IoU-potatoes': 0.0, 'IoU-luggage rack': 0.0, 'IoU-salt': 0.0, 'IoU-street number': 0.0, 'IoU-viewpoint': 0.0, 'IoU-sword': 0.0, 'IoU-cd': 0.0, 'IoU-rowing machine': 0.0, 'IoU-plug': 0.0, 'IoU-andiron, firedog, dog, dog-iron': 0.0, 'IoU-pepper': 0.0, 'IoU-tongs': 0.0, 'IoU-bonfire': 0.0, 'IoU-dog dish': 0.0, 'IoU-belt': 0.0, 'IoU-dumbbells': 0.0, 'IoU-videocassette recorder, vcr': 0.0, 'IoU-hook': 0.0, 'IoU-envelopes': 0.0, 'IoU-shower faucet': 0.0, 'IoU-watch': 0.0, 'IoU-padlock': 0.0, 'IoU-swimming pool ladder': 0.0, 'IoU-spanners': 0.0, 'IoU-gravy boat': 0.0, 'IoU-notice board': 0.0, 'IoU-trash bags': 0.0, 'IoU-fire alarm': 0.0, 'IoU-ladle': 0.0, 'IoU-stethoscope': 0.0, 'IoU-rocket': 0.0, 'IoU-funnel': 0.0, 'IoU-bowling pins': 0.0, 'IoU-valve': 0.0, 'IoU-thermometer': 0.0, 'IoU-cups': 0.0, 'IoU-spice jar': 0.0, 'IoU-night light': 0.0, 'IoU-soaps': 0.0, 'IoU-games table': 0.0, 'IoU-slotted spoon': 0.0, 'IoU-reel': 0.0, 'IoU-scourer': 0.0, 'IoU-sleeping robe': 0.0, 'IoU-desk mat': 0.0, 'IoU-dumbbell': 0.0, 'IoU-hammer': 0.0, 'IoU-tie': 0.0, 'IoU-typewriter': 0.0, 'IoU-shaker': 0.0, 'IoU-cheese dish': 0.0, 'IoU-sea star': 0.0, 'IoU-racquet': 0.0, 'IoU-butane gas cylinder': 0.0, 'IoU-paper weight': 0.0, 'IoU-shaving brush': 0.0, 'IoU-sunglasses': 0.0, 'IoU-gear shift': 0.0, 'IoU-towel rail': 0.0, 'IoU-adding machine, totalizer, totaliser': 0.0, 'mACC': 7.169848689984444, 'pACC': 39.02581112871845, 'ACC-wall': 50.3750265460717, 'ACC-building, edifice': 23.364461705878742, 'ACC-sky': 94.07553831468458, 'ACC-tree': 86.37077382568918, 'ACC-road, route': 43.328009975786976, 'ACC-floor, flooring': 47.746540733687304, 'ACC-ceiling': 59.393196085595434, 'ACC-bed': 33.081539056317524, 'ACC-sidewalk, pavement': 87.25700957910428, 'ACC-earth, ground': 0.0, 'ACC-cabinet': 11.681500760496242, 'ACC-person, individual, someone, somebody, mortal, soul': 52.68167690621872, 'ACC-grass': 69.99551381734719, 'ACC-windowpane, window': 0.1526130965249253, 'ACC-car, auto, automobile, machine, motorcar': 3.7876600410523285, 'ACC-mountain, mount': 16.623641911704283, 'ACC-plant, flora, plant life': 12.767695552409128, 'ACC-table': 7.9503319841050395, 'ACC-chair': 27.8453406155078, 'ACC-curtain, drape, drapery, mantle, pall': 0.0024009966619936924, 'ACC-door': 0.7930545275104861, 'ACC-sofa, couch, lounge': 14.578740959109057, 'ACC-sea': 25.26475636214362, 'ACC-painting, picture': 0.21370409891939934, 'ACC-water': 3.3662774929533983, 'ACC-mirror': 9.161243412209298, 'ACC-house': 58.93918184953423, 'ACC-rug, carpet, carpeting': 50.907181846501125, 'ACC-shelf': 11.387925366351139, 'ACC-armchair': 30.840638323818858, 'ACC-fence, fencing': 14.64514963539878, 'ACC-field': 1.993425836756353, 'ACC-lamp': 1.159006667543975, 'ACC-rock, stone': 74.61636907023896, 'ACC-seat': 6.177822728344125, 'ACC-river': 12.49168696366214, 'ACC-desk': 16.71644237755215, 'ACC-bathtub, bathing tub, bath, tub': 66.6823682172389, 'ACC-railing, rail': 6.198019477146341, 'ACC-signboard, sign': 2.7235907552267227, 'ACC-cushion': 0.825503943908852, 'ACC-path': 0.1553878159827119, 'ACC-work surface': 0.0, 'ACC-stairs, steps': 26.946351518053724, 'ACC-column, pillar': 0.5235433549810322, 'ACC-sink': 11.686400419524333, 'ACC-wardrobe, closet, press': 5.3158902989742, 'ACC-snow': 61.23666084477151, 'ACC-refrigerator, icebox': 0.45895520816219926, 'ACC-base, pedestal, stand': 0.0, 'ACC-bridge, span': 2.7518120210097425, 'ACC-blind, screen': 0.0, 'ACC-runway': 61.98049396767402, 'ACC-cliff, drop, drop-off': 1.8740089375810869, 'ACC-sand': 32.06724797028288, 'ACC-fireplace, hearth, open fireplace': 4.021551297790759, 'ACC-pillow': 0.0, 'ACC-screen door, screen': 0.0, 'ACC-toilet, can, commode, crapper, pot, potty, stool, throne': 33.35270214459643, 'ACC-skyscraper': 63.04337560138949, 'ACC-grandstand, covered stand': 53.757205066397496, 'ACC-box': 0.0, 'ACC-pool table, billiard table, snooker table': 0.0, 'ACC-palm, palm tree': 24.97089969238747, 'ACC-double door': 58.17910874265384, 'ACC-coffee table, cocktail table': 0.024641905202590686, 'ACC-counter': 7.809189026285305, 'ACC-countertop': 9.15546879236484, 'ACC-chest of drawers, chest, bureau, dresser': 16.15136261711808, 'ACC-kitchen island': 66.57803728355876, 'ACC-boat': 78.4091736970174, 'ACC-waterfall, falls': 9.677691370748619, 'ACC-stove, kitchen stove, range, kitchen range, cooking stove': 0.0, 'ACC-flower': 10.69152120345492, 'ACC-bookcase': 69.07087659490777, 'ACC-controls': 0.0, 'ACC-book': 18.22922469281332, 'ACC-stairway, staircase': 0.0, 'ACC-streetlight, street lamp': 2.035165831628871, 'ACC-computer, computing machine, computing device, data processor, electronic computer, information processing system': 0.0, 'ACC-bus, autobus, coach, charabanc, double-decker, jitney, motorbus, motorcoach, omnibus, passenger vehicle': 34.84797656453023, 'ACC-swivel chair': 12.311067365119616, 'ACC-light, light source': 0.0, 'ACC-bench': 4.878890907583171, 'ACC-case, display case, showcase, vitrine': 0.0, 'ACC-towel': 0.02186234817813765, 'ACC-fountain': 57.3255293766776, 'ACC-embankment': 0.0, 'ACC-television receiver, television, television set, tv, tv set, idiot box, boob tube, telly, goggle box': 4.322989122695556, 'ACC-van': 80.50798648441099, 'ACC-hill': 8.674386064526596, 'ACC-awning, sunshade, sunblind': 0.0, 'ACC-poster, posting, placard, notice, bill, card': 0.0, 'ACC-truck, motortruck': 0.02875653365360218, 'ACC-airplane, aeroplane, plane': 57.65893364504322, 'ACC-pole': 0.345876763144695, 'ACC-tower': 11.065721263602073, 'ACC-court': 35.80407332509292, 'ACC-ball': 0.0, 'ACC-aircraft carrier, carrier, flattop, attack aircraft carrier': 0.0, 'ACC-buffet, counter, sideboard': 0.0, 'ACC-hovel, hut, hutch, shack, shanty': 0.0, 'ACC-apparel, wearing apparel, dress, clothes': 0.0, 'ACC-minibike, motorbike': 34.430203414556566, 'ACC-animal, animate being, beast, brute, creature, fauna': 26.913455402487727, 'ACC-chandelier, pendant, pendent': 24.9005232096569, 'ACC-step, stair': 0.0, 'ACC-booth, cubicle, stall, kiosk': 17.172310049837975, 'ACC-bicycle, bike, wheel, cycle': 52.535780008547086, 'ACC-doorframe, doorcase': 0.6371537747151861, 'ACC-sconce': 41.49401757667737, 'ACC-pond': 96.33162837270982, 'ACC-trade name, brand name, brand, marque': 0.0, 'ACC-bannister, banister, balustrade, balusters, handrail': 0.0, 'ACC-bag': 0.0, 'ACC-traffic light, traffic signal, stoplight': 20.879340524890825, 'ACC-gazebo': 24.59917868205713, 'ACC-escalator, moving staircase, moving stairway': 3.9378354922696155, 'ACC-land, ground, soil': 9.380911830544946, 'ACC-board, plank': 0.0, 'ACC-arcade machine': 0.0, 'ACC-eiderdown, duvet, continental quilt': 2.068105804581139, 'ACC-bar': 2.5506078092126674, 'ACC-stall, stand, sales booth': 0.0, 'ACC-playground': 0.0, 'ACC-ship': 0.0, 'ACC-ottoman, pouf, pouffe, puff, hassock': 1.1871434656143403, 'ACC-ashcan, trash can, garbage can, wastebin, ash bin, ash-bin, ashbin, dustbin, trash barrel, trash bin': 0.0, 'ACC-bottle': 15.859230732808282, 'ACC-cradle': 13.696227460151395, 'ACC-pot, flowerpot': 40.95657568238214, 'ACC-conveyer belt, conveyor belt, conveyer, conveyor, transporter': 0.0, 'ACC-train, railroad train': 95.62633566556397, 'ACC-stool': 14.065629557608167, 'ACC-lake': 6.2323297140352105, 'ACC-tank, storage tank': 0.0, 'ACC-ice, water ice': 0.0, 'ACC-basket, handbasket': 0.0, 'ACC-manhole': 0.0, 'ACC-tent, collapsible shelter': 14.117426904855362, 'ACC-canopy': 0.0, 'ACC-microwave, microwave oven': 55.56505395662148, 'ACC-barrel, cask': 0.0, 'ACC-dirt track': 0.0, 'ACC-beam': 0.0, 'ACC-dishwasher, dish washer, dishwashing machine': 0.0, 'ACC-plate': 0.0, 'ACC-screen, crt screen': 0.0, 'ACC-ruins': 0.0, 'ACC-washer, automatic washer, washing machine': 0.0, 'ACC-blanket, cover': 0.0, 'ACC-plaything, toy': 0.6790855933778432, 'ACC-food, solid food': 3.600707001407026, 'ACC-screen, silver screen, projection screen': 40.67263641696181, 'ACC-oven': 27.77802310104024, 'ACC-stage': 0.0, 'ACC-beacon, lighthouse, beacon light, pharos': 25.217939292091167, 'ACC-umbrella': 23.235893949694088, 'ACC-sculpture': 0.0, 'ACC-aqueduct': 0.0, 'ACC-container': 0.0, 'ACC-scaffolding, staging': 0.0, 'ACC-hood, exhaust hood': 0.0, 'ACC-curb, curbing, kerb': 0.0, 'ACC-roller coaster': 0.0, 'ACC-horse, equus caballus': 0.0, 'ACC-catwalk': 0.0, 'ACC-glass, drinking glass': 0.0, 'ACC-vase': 0.0007698466465480077, 'ACC-central reservation': 0.0, 'ACC-carousel': 95.67025488986609, 'ACC-radiator': 8.890464631198663, 'ACC-closet': 0.0, 'ACC-machine': 0.0, 'ACC-pier, wharf, wharfage, dock': 0.0, 'ACC-fan': 0.0, 'ACC-inflatable bounce game': 0.0, 'ACC-pitch': 23.851635109627782, 'ACC-paper': 0.0, 'ACC-arcade, colonnade': 0.0, 'ACC-hot tub': 0.0, 'ACC-helicopter': 89.36891008510463, 'ACC-tray': 12.10268863349313, 'ACC-partition, divider': 0.0, 'ACC-vineyard': 100.0, 'ACC-bowl': 2.7842775768748966, 'ACC-bullring': 0.0, 'ACC-flag': 15.696410280984013, 'ACC-pot': 0.2790631954502102, 'ACC-footbridge, overcrossing, pedestrian bridge': 0.0, 'ACC-shower': 0.0, 'ACC-bag, traveling bag, travelling bag, grip, suitcase': 33.045770428948, 'ACC-bulletin board, notice board': 0.0, 'ACC-confessional booth': 0.0, 'ACC-trunk, tree trunk, bole': 0.0, 'ACC-forest': 0.0, 'ACC-elevator door': 0.0, 'ACC-laptop, laptop computer': 0.0, 'ACC-instrument panel': 0.0, 'ACC-bucket, pail': 0.0, 'ACC-tapestry, tapis': 0.0, 'ACC-platform': 0.0, 'ACC-jacket': 0.0, 'ACC-gate': 0.058332228556277343, 'ACC-monitor, monitoring device': 0.0, 'ACC-telephone booth, phone booth, call box, telephone box, telephone kiosk': 58.009207810763606, 'ACC-spotlight, spot': 1.6753153363263562, 'ACC-ring': 0.0, 'ACC-control panel': 0.0, 'ACC-blackboard, chalkboard': 0.0, 'ACC-air conditioner, air conditioning': 0.0, 'ACC-chest': 0.0, 'ACC-clock': 4.789809174163876, 'ACC-sand dune': 0.0, 'ACC-pipe, pipage, piping': 0.0, 'ACC-vault': 0.0, 'ACC-table football': 0.0, 'ACC-cannon': 0.0, 'ACC-swimming pool, swimming bath, natatorium': 0.0, 'ACC-fluorescent, fluorescent fixture': 0.0, 'ACC-statue': 0.0, 'ACC-loudspeaker, speaker, speaker unit, loudspeaker system, speaker system': 0.0, 'ACC-exhibitor': 0.0, 'ACC-ladder': 0.0, 'ACC-carport': 62.012002970634875, 'ACC-dam': 0.0, 'ACC-pulpit': 40.529055211490316, 'ACC-skylight, fanlight': 14.904591733531117, 'ACC-water tower': 56.6547901821061, 'ACC-grill, grille, grillwork': 0.0, 'ACC-display board': 0.0, 'ACC-pane, pane of glass, window glass': 0.0, 'ACC-rubbish, trash, scrap': 0.0, 'ACC-ice rink': 0.0, 'ACC-fruit': 0.7719856744926382, 'ACC-patio': 0.0, 'ACC-vending machine': 0.0, 'ACC-telephone, phone, telephone set': 0.0, 'ACC-net': 0.0, 'ACC-backpack, back pack, knapsack, packsack, rucksack, haversack': 14.370429401837615, 'ACC-jar': 0.0, 'ACC-track': 0.0, 'ACC-magazine': 0.0, 'ACC-shutter': 0.0, 'ACC-roof': 0.0, 'ACC-banner, streamer': 0.0, 'ACC-landfill': 0.0, 'ACC-post': 0.0, 'ACC-altarpiece, reredos': 0.0, 'ACC-hat, chapeau, lid': 8.66534109040921, 'ACC-arch, archway': 0.0, 'ACC-table game': 0.0, 'ACC-bag, handbag, pocketbook, purse': 25.639663416222515, 'ACC-document, written document, papers': 0.0, 'ACC-dome': 0.0, 'ACC-pier': 22.382084191623093, 'ACC-shanties': 0.0, 'ACC-forecourt': 0.0, 'ACC-crane': 0.0, 'ACC-dog, domestic dog, canis familiaris': 64.31635814729482, 'ACC-piano, pianoforte, forte-piano': 0.0, 'ACC-drawing': 0.0, 'ACC-cabin': 0.0, 'ACC-ad, advertisement, advertizement, advertising, advertizing, advert': 0.0, 'ACC-amphitheater, amphitheatre, coliseum': 0.0, 'ACC-monument': 0.0, 'ACC-henhouse': 0.0, 'ACC-cockpit': 100.0, 'ACC-heater, warmer': 0.0, 'ACC-windmill, aerogenerator, wind generator': 33.20364479703956, 'ACC-pool': 0.0, 'ACC-elevator, lift': 0.0, 'ACC-decoration, ornament, ornamentation': 0.0, 'ACC-labyrinth': 98.83486669800551, 'ACC-text, textual matter': 0.0, 'ACC-printer': 0.0, 'ACC-mezzanine, first balcony': 0.0, 'ACC-mattress': 0.0, 'ACC-straw': 0.0, 'ACC-stalls': 0.0, 'ACC-patio, terrace': 0.0, 'ACC-billboard, hoarding': 0.0, 'ACC-bus stop': 3.609356482919701, 'ACC-trouser, pant': 0.0, 'ACC-console table, console': 0.0, 'ACC-rack': 0.0, 'ACC-notebook': 0.0, 'ACC-shrine': 69.5616666962558, 'ACC-pantry': 37.711508324059146, 'ACC-cart': 0.0, 'ACC-steam shovel': 79.89642809719825, 'ACC-porch': 0.0, 'ACC-postbox, mailbox, letter box': 0.0, 'ACC-figurine, statuette': 0.0, 'ACC-recycling bin': 0.0, 'ACC-folding screen': 0.0, 'ACC-telescope': 0.0, 'ACC-deck chair, beach chair': 39.86808726534754, 'ACC-kennel': 0.0, 'ACC-coffee maker': 0.0, "ACC-altar, communion table, lord's table": 0.24874107445707477, 'ACC-fish': 6.8309792397383635, 'ACC-easel': 0.013230794674605145, 'ACC-artificial golf green': 6.510404735506217, 'ACC-iceberg': 0.0, 'ACC-candlestick, candle holder': 0.8374748250431054, 'ACC-shower stall, shower bath': 0.0, 'ACC-television stand': 0.0, 'ACC-wall socket, wall plug, electric outlet, electrical outlet, outlet, electric receptacle': 0.0, 'ACC-skeleton': 0.0, 'ACC-grand piano, grand': 0.0, 'ACC-candy, confect': 0.0, 'ACC-grille door': 0.0, 'ACC-pedestal, plinth, footstall': 0.0, 'ACC-jersey, t-shirt, tee shirt': 0.0, 'ACC-shoe': 25.636789205562437, 'ACC-gravestone, headstone, tombstone': 0.0, 'ACC-shanty': 79.94968201831016, 'ACC-structure': 0.0, 'ACC-rocking chair, rocker': 0.0, 'ACC-bird': 0.0, 'ACC-place mat': 0.0, 'ACC-tomb': 0.0, 'ACC-big top': 0.0, 'ACC-gas pump, gasoline pump, petrol pump, island dispenser': 0.0, 'ACC-lockers': 35.499788318077634, 'ACC-cage': 0.0, 'ACC-finger': 0.0, 'ACC-bleachers': 0.0, 'ACC-ferris wheel': 0.0, 'ACC-hairdresser chair': 0.0, 'ACC-mat': 0.0, 'ACC-stands': 0.0, 'ACC-aquarium, fish tank, marine museum': 0.0, 'ACC-streetcar, tram, tramcar, trolley, trolley car': 0.0, 'ACC-napkin, table napkin, serviette': 4.042173453199365, 'ACC-dummy': 0.0, 'ACC-booklet, brochure, folder, leaflet, pamphlet': 0.0, 'ACC-sand trap': 0.0, 'ACC-shop, store': 0.0, 'ACC-table cloth': 0.0, 'ACC-service station': 0.0, 'ACC-coffin': 0.0, 'ACC-drawer': 0.0, 'ACC-cages': 0.0, 'ACC-slot machine, coin machine': 0.0, 'ACC-balcony': 0.0, 'ACC-volleyball court': 0.0, 'ACC-table tennis': 0.0, 'ACC-control table': 0.0, 'ACC-shirt': 0.0, 'ACC-merchandise, ware, product': 0.0, 'ACC-railway': 37.79990764350393, 'ACC-parterre': 0.0, 'ACC-chimney': 43.67954724683398, 'ACC-can, tin, tin can': 10.070127782243535, 'ACC-tanks': 0.0, 'ACC-fabric, cloth, material, textile': 0.0, 'ACC-alga, algae': 0.0, 'ACC-system': 0.0, 'ACC-map': 0.0, 'ACC-greenhouse': 62.289237884189234, 'ACC-mug': 1.4027700268885395, 'ACC-barbecue': 0.0, 'ACC-trailer': 0.0, 'ACC-toilet tissue, toilet paper, bathroom tissue': 14.177936514306353, 'ACC-organ': 0.0, 'ACC-dishrag, dishcloth': 0.0, 'ACC-island': 6.1204899040052965, 'ACC-keyboard': 70.46265107984941, 'ACC-trench': 0.0, 'ACC-basket, basketball hoop, hoop': 0.0, 'ACC-steering wheel, wheel': 56.67492430498211, 'ACC-pitcher, ewer': 0.0, 'ACC-goal': 0.0, 'ACC-bread, breadstuff, staff of life': 0.0, 'ACC-beds': 0.0, 'ACC-wood': 0.0, 'ACC-file cabinet': 0.0, 'ACC-newspaper, paper': 0.0, 'ACC-motorboat': 0.0, 'ACC-rope': 0.0, 'ACC-guitar': 13.195034858017344, 'ACC-rubble': 0.0, 'ACC-scarf': 0.0, 'ACC-barrels': 0.0, 'ACC-cap': 0.0, 'ACC-leaves': 0.0, 'ACC-control tower': 0.0, 'ACC-dashboard': 0.0, 'ACC-bandstand': 0.14800012823115802, 'ACC-lectern': 0.0, 'ACC-switch, electric switch, electrical switch': 0.0, 'ACC-baseboard, mopboard, skirting board': 0.0, 'ACC-shower room': 0.0, 'ACC-smoke': 0.0, 'ACC-faucet, spigot': 0.0, 'ACC-bulldozer': 96.71062286421099, 'ACC-saucepan': 0.0, 'ACC-shops': 0.0, 'ACC-meter': 0.0, 'ACC-crevasse': 0.0, 'ACC-gear': 0.0, 'ACC-candelabrum, candelabra': 0.0, 'ACC-sofa bed': 0.0, 'ACC-tunnel': 0.0, 'ACC-pallet': 0.0, 'ACC-wire, conducting wire': 0.0, 'ACC-kettle, boiler': 0.0, 'ACC-bidet': 0.0, 'ACC-baby buggy, baby carriage, carriage, perambulator, pram, stroller, go-cart, pushchair, pusher': 0.0, 'ACC-music stand': 0.0, 'ACC-pipe, tube': 0.0, 'ACC-cup': 0.0, 'ACC-parking meter': 0.0, 'ACC-ice hockey rink': 0.0, 'ACC-shelter': 0.0, 'ACC-weeds': 0.0, 'ACC-temple': 0.0, 'ACC-patty, cake': 11.904563970404855, 'ACC-ski slope': 0.003447708864855117, 'ACC-panel': 0.0, 'ACC-wallet': 0.0, 'ACC-wheel': 0.0, 'ACC-towel rack, towel horse': 0.0, 'ACC-roundabout': 0.0, 'ACC-canister, cannister, tin': 0.0, 'ACC-rod': 0.0, 'ACC-soap dispenser': 0.0, 'ACC-bell': 0.0, 'ACC-canvas': 0.0, 'ACC-box office, ticket office, ticket booth': 0.0, 'ACC-teacup': 70.42682926829268, 'ACC-trellis': 0.44892879367054844, 'ACC-workbench': 0.0, 'ACC-valley, vale': 0.0, 'ACC-toaster': 0.0, 'ACC-knife': 0.0, 'ACC-podium': 0.0, 'ACC-ramp': 2.949798273836883, 'ACC-tumble dryer': 0.0, 'ACC-fireplug, fire hydrant, plug': 0.0, 'ACC-gym shoe, sneaker, tennis shoe': 0.0, 'ACC-lab bench': 0.0, 'ACC-equipment': 0.0, 'ACC-rocky formation': 0.0, 'ACC-plastic': 0.0, 'ACC-calendar': 0.0, 'ACC-caravan': 0.0, 'ACC-check-in-desk': 0.0, 'ACC-ticket counter': 0.0, 'ACC-brush': 0.0, 'ACC-mill': 0.0, 'ACC-covered bridge': 0.0, 'ACC-bowling alley': 0.0, 'ACC-hanger': 0.0, 'ACC-excavator': 0.0, 'ACC-trestle': 0.0, 'ACC-revolving door': 0.0, 'ACC-blast furnace': 0.0, 'ACC-scale, weighing machine': 0.0, 'ACC-projector': 0.0, 'ACC-soap': 0.0, 'ACC-locker': 0.0, 'ACC-tractor': 0.0, 'ACC-stretcher': 0.0, 'ACC-frame': 0.0, 'ACC-grating': 0.0, 'ACC-alembic': 0.0, 'ACC-candle, taper, wax light': 39.14980874640167, 'ACC-barrier': 0.0, 'ACC-cardboard': 0.0, 'ACC-cave': 0.0, 'ACC-puddle': 0.0, 'ACC-tarp': 0.0, 'ACC-price tag': 0.0, 'ACC-watchtower': 95.2155047729245, 'ACC-meters': 0.0, 'ACC-light bulb, lightbulb, bulb, incandescent lamp, electric light, electric-light bulb': 0.0, 'ACC-tracks': 0.0, 'ACC-hair dryer': 0.0, 'ACC-skirt': 0.0, 'ACC-viaduct': 0.0, 'ACC-paper towel': 0.0, 'ACC-coat': 0.0, 'ACC-sheet': 0.0, 'ACC-fire extinguisher, extinguisher, asphyxiator': 0.0, 'ACC-water wheel': 0.0, 'ACC-pottery, clayware': 0.0, 'ACC-magazine rack': 0.0, 'ACC-teapot': 0.0, 'ACC-microphone, mike': 0.0, 'ACC-support': 0.0, 'ACC-forklift': 76.63515038325357, 'ACC-canyon': 0.0, 'ACC-cash register, register': 0.0, 'ACC-leaf, leafage, foliage': 0.0, 'ACC-remote control, remote': 18.008618734406895, 'ACC-soap dish': 0.0, 'ACC-windshield, windscreen': 0.0, 'ACC-cat': 4.963997381627755, 'ACC-cue, cue stick, pool cue, pool stick': 0.0, 'ACC-vent, venthole, vent-hole, blowhole': 0.0, 'ACC-videos': 0.0, 'ACC-shovel': 0.0, 'ACC-eaves': 0.0, 'ACC-antenna, aerial, transmitting aerial': 0.0, 'ACC-shipyard': 0.0, 'ACC-hen, biddy': 78.65181643244505, 'ACC-traffic cone': 17.075679647318147, 'ACC-washing machines': 0.0, 'ACC-truck crane': 0.0, 'ACC-cds': 0.0, 'ACC-niche': 0.0, 'ACC-scoreboard': 0.0, 'ACC-briefcase': 0.0, 'ACC-boot': 0.0, 'ACC-sweater, jumper': 0.0, 'ACC-hay': 0.0, 'ACC-pack': 0.0, 'ACC-bottle rack': 0.0, 'ACC-glacier': 0.0, 'ACC-pergola': 0.0, 'ACC-building materials': 0.0, 'ACC-television camera': 0.0, 'ACC-first floor': 0.0, 'ACC-rifle': 0.0, 'ACC-tennis table': 0.0, 'ACC-stadium': 0.0, 'ACC-safety belt': 0.0, 'ACC-cover': 0.0, 'ACC-dish rack': 0.0, 'ACC-synthesizer': 0.0, 'ACC-pumpkin': 0.0, 'ACC-gutter': 0.0, 'ACC-fruit stand': 99.34761107729763, 'ACC-ice floe, floe': 0.0, 'ACC-handle, grip, handgrip, hold': 0.0, 'ACC-wheelchair': 0.0, 'ACC-mousepad, mouse mat': 0.0, 'ACC-diploma': 0.0, 'ACC-fairground ride': 30.81332257436211, 'ACC-radio': 0.0, 'ACC-hotplate': 0.0, 'ACC-junk': 0.0, 'ACC-wheelbarrow': 0.0, 'ACC-stream': 0.0, 'ACC-toll plaza': 0.0, 'ACC-punching bag': 0.0, 'ACC-trough': 0.0, 'ACC-throne': 0.0, 'ACC-chair desk': 28.315944457137054, 'ACC-weighbridge': 13.41770452180335, 'ACC-extractor fan': 0.0, 'ACC-hanging clothes': 0.0, 'ACC-dish, dish aerial, dish antenna, saucer': 0.0, 'ACC-alarm clock, alarm': 0.0, 'ACC-ski lift': 4.9167533818938605, 'ACC-chain': 0.0, 'ACC-garage': 0.0, 'ACC-mechanical shovel': 0.0, 'ACC-wine rack': 0.0, 'ACC-tramway': 1.5918791094705274, 'ACC-treadmill': 0.0, 'ACC-menu': 0.0, 'ACC-block': 0.0, 'ACC-well': 0.0, 'ACC-witness stand': 0.0, 'ACC-branch': 0.0, 'ACC-duck': 0.0, 'ACC-casserole': 0.0, 'ACC-frying pan': 0.0, 'ACC-desk organizer': 0.0, 'ACC-mast': 0.0, 'ACC-spectacles, specs, eyeglasses, glasses': 0.0, 'ACC-service elevator': 0.0, 'ACC-dollhouse': 0.0, 'ACC-hammock': 0.0, 'ACC-clothes hanging': 0.0, 'ACC-photocopier': 0.0, 'ACC-notepad': 0.0, 'ACC-golf cart': 0.0, 'ACC-footpath': 0.0, 'ACC-cross': 0.0, 'ACC-baptismal font': 85.75939744099553, 'ACC-boiler': 0.0, 'ACC-skip': 0.0, 'ACC-rotisserie': 0.0, 'ACC-tables': 0.0, 'ACC-water mill': 0.0, 'ACC-helmet': 0.0, 'ACC-cover curtain': 0.0, 'ACC-brick': 0.0, 'ACC-table runner': 0.0, 'ACC-ashtray': 0.0, 'ACC-street box': 0.0, 'ACC-stick': 0.0, 'ACC-hangers': 0.0, 'ACC-cells': 0.0, 'ACC-urinal': 0.0, 'ACC-centerpiece': 0.0, 'ACC-portable fridge': 0.0, 'ACC-dvds': 0.0, 'ACC-golf club': 0.0, 'ACC-skirting board': 0.0, 'ACC-water cooler': 0.0, 'ACC-clipboard': 0.0, 'ACC-camera, photographic camera': 0.0, 'ACC-pigeonhole': 0.0, 'ACC-chips': 0.0, 'ACC-food processor': 0.0, 'ACC-post box': 71.04006238424799, 'ACC-lid': 0.0, 'ACC-drum': 0.0, 'ACC-blender': 0.0, 'ACC-cave entrance': 0.0, 'ACC-dental chair': 0.0, 'ACC-obelisk': 0.0, 'ACC-canoe': 0.0, 'ACC-mobile': 0.0, 'ACC-monitors': 0.0, 'ACC-pool ball': 0.0, 'ACC-cue rack': 0.0, 'ACC-baggage carts': 0.0, 'ACC-shore': 0.0, 'ACC-fork': 0.0, 'ACC-paper filer': 0.0, 'ACC-bicycle rack': 18.042857833889613, 'ACC-coat rack': 0.0, 'ACC-garland': 0.0, 'ACC-sports bag': 0.0, 'ACC-fish tank': 0.0, 'ACC-towel dispenser': 0.0, 'ACC-carriage': 0.0, 'ACC-brochure': 0.0, 'ACC-plaque': 0.0, 'ACC-stringer': 0.0, 'ACC-iron': 0.0, 'ACC-spoon': 0.0, 'ACC-flag pole': 0.0, 'ACC-toilet brush': 0.0, 'ACC-book stand': 0.0, 'ACC-water faucet, water tap, tap, hydrant': 0.0, 'ACC-ticket office': 0.0, 'ACC-broom': 0.0, 'ACC-dvd': 0.0, 'ACC-ice bucket': 0.0, 'ACC-carapace, shell, cuticle, shield': 0.0, 'ACC-tureen': 0.0, 'ACC-folders': 0.0, 'ACC-chess': 0.0, 'ACC-root': 0.0, 'ACC-sewing machine': 0.0, 'ACC-model': 0.0, 'ACC-pen': 0.0, 'ACC-violin': 0.0, 'ACC-sweatshirt': 0.0, 'ACC-recycling materials': 0.0, 'ACC-mitten': 0.0, 'ACC-chopping board, cutting board': 0.0, 'ACC-mask': 0.0, 'ACC-log': 0.0, 'ACC-mouse, computer mouse': 0.0, 'ACC-grill': 0.0, 'ACC-hole': 0.0, 'ACC-target': 0.0, 'ACC-trash bag': 0.0, 'ACC-chalk': 0.0, 'ACC-sticks': 0.0, 'ACC-balloon': 67.20897615708274, 'ACC-score': 0.0, 'ACC-hair spray': 0.0, 'ACC-roll': 0.0, 'ACC-runner': 0.0, 'ACC-engine': 0.0, 'ACC-inflatable glove': 0.0, 'ACC-games': 0.0, 'ACC-pallets': 73.2212722793798, 'ACC-baskets': 0.0, 'ACC-coop': 0.0, 'ACC-dvd player': 0.0, 'ACC-rocking horse': 0.0, 'ACC-buckets': 0.0, 'ACC-bread rolls': 0.0, 'ACC-shawl': 0.0, 'ACC-watering can': 0.0, 'ACC-spotlights': 0.0, 'ACC-post-it': 0.0, 'ACC-bowls': 0.0, 'ACC-security camera': 0.0, 'ACC-runner cloth': 0.0, 'ACC-lock': 0.0, 'ACC-alarm, warning device, alarm system': 0.0, 'ACC-side': 0.0, 'ACC-roulette': 0.0, 'ACC-bone': 62.76061057334326, 'ACC-cutlery': 0.0, 'ACC-pool balls': 0.0, 'ACC-wheels': 90.30022112604185, 'ACC-spice rack': 0.0, 'ACC-plant pots': 0.0, 'ACC-towel ring': 0.0, 'ACC-bread box': 0.0, 'ACC-video': 0.0, 'ACC-funfair': 0.0, 'ACC-breads': 0.0, 'ACC-tripod': 32.69726858877087, 'ACC-ironing board': 0.0, 'ACC-skimmer': 0.0, 'ACC-hollow': 0.0, 'ACC-scratching post': 0.0, 'ACC-tricycle': 0.0, 'ACC-file box': 0.0, 'ACC-mountain pass': 0.0, 'ACC-tombstones': 0.0, 'ACC-cooker': 0.0, 'ACC-card game, cards': 0.0, 'ACC-golf bag': 0.10012119934657744, 'ACC-towel paper': 0.0, 'ACC-chaise lounge': 70.70139267097176, 'ACC-sun': 82.26264923251848, 'ACC-toilet paper holder': 0.0, 'ACC-rake': 0.0, 'ACC-key': 0.0, 'ACC-umbrella stand': 0.0, 'ACC-dartboard': 0.0, 'ACC-transformer': 0.0, 'ACC-fireplace utensils': 0.0, 'ACC-sweatshirts': 0.0, 'ACC-cellular telephone, cellular phone, cellphone, cell, mobile phone': 0.0, 'ACC-tallboy': 0.0, 'ACC-stapler': 0.0, 'ACC-sauna': 0.0, 'ACC-test tube': 0.0, 'ACC-palette': 0.0, 'ACC-shopping carts': 0.0, 'ACC-tools': 0.0, 'ACC-push button, push, button': 0.0, 'ACC-star': 0.0, 'ACC-roof rack': 0.0, 'ACC-barbed wire': 0.0, 'ACC-spray': 0.0, 'ACC-ear': 0.0, 'ACC-sponge': 0.0, 'ACC-racket': 0.0, 'ACC-tins': 0.0, 'ACC-eyeglasses': 0.0, 'ACC-file': 0.0, 'ACC-scarfs': 0.0, 'ACC-sugar bowl': 0.0, 'ACC-flip flop': 0.0, 'ACC-headstones': 99.9457935819601, 'ACC-laptop bag': 0.0, 'ACC-leash': 0.0, 'ACC-climbing frame': 0.0, 'ACC-suit hanger': 0.0, 'ACC-floor spotlight': 0.0, 'ACC-plate rack': 0.0, 'ACC-sewer': 0.0, 'ACC-hard drive': 0.0, 'ACC-sprinkler': 0.0, 'ACC-tools box': 0.0, 'ACC-necklace': 0.0, 'ACC-bulbs': 0.0, 'ACC-steel industry': 0.0, 'ACC-club': 0.0, 'ACC-jack': 0.0, 'ACC-door bars': 21.096725057121095, 'ACC-control panel, instrument panel, control board, board, panel': 0.0, 'ACC-hairbrush': 0.0, 'ACC-napkin holder': 0.0, 'ACC-office': 0.0, 'ACC-smoke detector': 0.0, 'ACC-utensils': 0.0, 'ACC-apron': 0.0, 'ACC-scissors': 0.0, 'ACC-terminal': 0.0, 'ACC-grinder': 0.0, 'ACC-entry phone': 0.0, 'ACC-newspaper stand': 0.0, 'ACC-pepper shaker': 0.0, 'ACC-onions': 0.0, 'ACC-central processing unit, cpu, c p u , central processor, processor, mainframe': 0.0, 'ACC-tape': 0.0, 'ACC-bat': 0.0, 'ACC-coaster': 0.0, 'ACC-calculator': 0.0, 'ACC-potatoes': 0.0, 'ACC-luggage rack': 0.0, 'ACC-salt': 0.0, 'ACC-street number': 0.0, 'ACC-viewpoint': 0.0, 'ACC-sword': 0.0, 'ACC-cd': 0.0, 'ACC-rowing machine': 0.0, 'ACC-plug': 0.0, 'ACC-andiron, firedog, dog, dog-iron': 0.0, 'ACC-pepper': 0.0, 'ACC-tongs': 0.0, 'ACC-bonfire': 0.0, 'ACC-dog dish': 0.0, 'ACC-belt': 0.0, 'ACC-dumbbells': 0.0, 'ACC-videocassette recorder, vcr': 0.0, 'ACC-hook': 0.0, 'ACC-envelopes': 0.0, 'ACC-shower faucet': 0.0, 'ACC-watch': 0.0, 'ACC-padlock': 0.0, 'ACC-swimming pool ladder': 0.0, 'ACC-spanners': 0.0, 'ACC-gravy boat': 0.0, 'ACC-notice board': 0.0, 'ACC-trash bags': 0.0, 'ACC-fire alarm': 0.0, 'ACC-ladle': 0.0, 'ACC-stethoscope': 0.0, 'ACC-rocket': 0.0, 'ACC-funnel': 0.0, 'ACC-bowling pins': 0.0, 'ACC-valve': 0.0, 'ACC-thermometer': 0.0, 'ACC-cups': 0.0, 'ACC-spice jar': 0.0, 'ACC-night light': 0.0, 'ACC-soaps': 0.0, 'ACC-games table': 0.0, 'ACC-slotted spoon': 0.0, 'ACC-reel': 0.0, 'ACC-scourer': 0.0, 'ACC-sleeping robe': 0.0, 'ACC-desk mat': 0.0, 'ACC-dumbbell': 0.0, 'ACC-hammer': 0.0, 'ACC-tie': 0.0, 'ACC-typewriter': 0.0, 'ACC-shaker': 0.0, 'ACC-cheese dish': 0.0, 'ACC-sea star': 0.0, 'ACC-racquet': 0.0, 'ACC-butane gas cylinder': 0.0, 'ACC-paper weight': 0.0, 'ACC-shaving brush': 0.0, 'ACC-sunglasses': 0.0, 'ACC-gear shift': 0.0, 'ACC-towel rail': 0.0, 'ACC-adding machine, totalizer, totaliser': 0.0})])
[12/13 00:44:43 d2.engine.defaults]: Evaluation results for ade20k_full_sem_seg_val in csv format:
[12/13 00:44:43 d2.evaluation.testing]: copypaste: Task: sem_seg
[12/13 00:44:43 d2.evaluation.testing]: copypaste: mIoU,fwIoU,mACC,pACC
[12/13 00:44:43 d2.evaluation.testing]: copypaste: 3.2598,31.8670,7.1698,39.0258
